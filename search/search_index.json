{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Elesto Summary Elesto is a protocol designed to build a secure and resilient identity framework based on self-sovereign identity. Elesto was born from the research project Cosmos Cash : a regulatory compliant protocol that offers the same guarantees as traditional banking systems. Features that enable these guarantees are Know Your Customer (KYC), anti-money laundering (AML) tracking, Financial Action Task Force (FATF) travel rule, and identity management. Elesto uses a novel approach to identity management by leveraging W3C specifications for decentralized identifiers and verifiable credentials. Research paper For more information on the research behind the Elesto protocol, see the Cosmos Cash research paper: Cosmos Cash: Investigation into EU regulations affecting E-Money tokens Architecture The Elesto approach leverages open standards to reach its goals and offers an open model compatible with third-party projects that use the open standards. In particular, the Elesto project roadmap includes: Self-sovereign identity ( SSI ) Decentralized identifier ( DID ) Verifiable credentials ( VC ) Zero-knowledge proofs ( ZKP ) For a detailed architecture description and design choices, visit the ADR section. Do you have questions or want to get in touch? Please send us an email at cosmos-cash@tendermint.com .","title":"Elesto"},{"location":"#elesto","text":"","title":"Elesto"},{"location":"#summary","text":"Elesto is a protocol designed to build a secure and resilient identity framework based on self-sovereign identity. Elesto was born from the research project Cosmos Cash : a regulatory compliant protocol that offers the same guarantees as traditional banking systems. Features that enable these guarantees are Know Your Customer (KYC), anti-money laundering (AML) tracking, Financial Action Task Force (FATF) travel rule, and identity management. Elesto uses a novel approach to identity management by leveraging W3C specifications for decentralized identifiers and verifiable credentials.","title":"Summary"},{"location":"#research-paper","text":"For more information on the research behind the Elesto protocol, see the Cosmos Cash research paper: Cosmos Cash: Investigation into EU regulations affecting E-Money tokens","title":"Research paper"},{"location":"#architecture","text":"The Elesto approach leverages open standards to reach its goals and offers an open model compatible with third-party projects that use the open standards. In particular, the Elesto project roadmap includes: Self-sovereign identity ( SSI ) Decentralized identifier ( DID ) Verifiable credentials ( VC ) Zero-knowledge proofs ( ZKP ) For a detailed architecture description and design choices, visit the ADR section. Do you have questions or want to get in touch? Please send us an email at cosmos-cash@tendermint.com .","title":"Architecture"},{"location":"ABOUT/","text":"Documentation How to use the Elesto documentation: Documentation Overview Contributing Reference Overview In Elesto, we use the Grand Unified Theory of Documentation (David Laing) described by Divio as a basis for our documentation strategy. This approach outlines four specific use cases for documentation: Tutorials How-Tos Explanation Reference For background, see ADR 002: Documentation Structure . Contributing Write all documentation following Google Documentation Best Practice Generate as much documentation as possible from the code. Raise a PR for all documentation changes Follow our Code of Conduct Reference Google Style Guide for Markdown Write the Docs global community The good docs project Readme editor","title":"About Documentation"},{"location":"ABOUT/#documentation","text":"How to use the Elesto documentation: Documentation Overview Contributing Reference","title":"Documentation"},{"location":"ABOUT/#overview","text":"In Elesto, we use the Grand Unified Theory of Documentation (David Laing) described by Divio as a basis for our documentation strategy. This approach outlines four specific use cases for documentation: Tutorials How-Tos Explanation Reference For background, see ADR 002: Documentation Structure .","title":"Overview"},{"location":"ABOUT/#contributing","text":"Write all documentation following Google Documentation Best Practice Generate as much documentation as possible from the code. Raise a PR for all documentation changes Follow our Code of Conduct","title":"Contributing"},{"location":"ABOUT/#reference","text":"Google Style Guide for Markdown Write the Docs global community The good docs project Readme editor","title":"Reference"},{"location":"Explanation/","text":"Explanation Documentation How to use the Elesto Explanation Documentation: Explanation Documentation Introduction Layout Topics Presentations Architecture Decisions Records (ADRs) Articles Discussions Contributing Reference Introduction This section contains Explanation documentation for Elesto. This content is intended to help readers understand Elesto and related topics . It is intended to be discursive, thoughtful, interesting, and occasionally educational. The content includes analysis and review of alternative approaches. Please see the ADR relating to the documentation structure for further background information. Layout The scope and structure of the Explanation documentation follow this layout. Topics Topics are discursive documents that explore some particular feature or theme. For example, an article might investigate Decentralised Identity Documents or Self-Sovereign Identity. To contribute, create a folder in topics with a self-descriptive name. Add your content as needed. Presentations The Presentations file describes and links to presentations about Elesto at various events. Presentations also include YouTube videos, podcasts, interviews, and so on. Architecture Decisions Records (ADRs) ADRs are the mechanism for contributors to raise design proposals. In turn, the ADRs explain the rationale behind Elesto design and implementation for subsequent contributors. For example, ADR 002: Documentation Structure explains why the Elesto documentation structure was chosen. See the Architecture Decision Records (ADR) README file for more details about raising and proposing an ADR. Articles This folder contains all articles relating to Elesto, includes papers, blog posts, etc. For details, see Articles README . Discussions The explanation content includes articles, topics, and so on, and also includes discussion on relevant channels, including Pull Requests and Issues . Important Pull Requests are listed in this document. Future: Elesto currently does not have a Discord or Telegram Channel. When we do, the links will be added here as well. Contributing The Explanation content should be dry, clear, and terse in style. All documentation is written following Google Documentation Best Practice Autogenerate documentation from the code whenever possible. Raise a PR for all documentation changes Follow our Code of Conduct Reference Google Style Guide for Markdown Write the Docs global community Write the Docs Code of Conduct","title":"About Explanation Documentation"},{"location":"Explanation/#explanation-documentation","text":"How to use the Elesto Explanation Documentation: Explanation Documentation Introduction Layout Topics Presentations Architecture Decisions Records (ADRs) Articles Discussions Contributing Reference","title":"Explanation Documentation"},{"location":"Explanation/#introduction","text":"This section contains Explanation documentation for Elesto. This content is intended to help readers understand Elesto and related topics . It is intended to be discursive, thoughtful, interesting, and occasionally educational. The content includes analysis and review of alternative approaches. Please see the ADR relating to the documentation structure for further background information.","title":"Introduction"},{"location":"Explanation/#layout","text":"The scope and structure of the Explanation documentation follow this layout.","title":"Layout"},{"location":"Explanation/#topics","text":"Topics are discursive documents that explore some particular feature or theme. For example, an article might investigate Decentralised Identity Documents or Self-Sovereign Identity. To contribute, create a folder in topics with a self-descriptive name. Add your content as needed.","title":"Topics"},{"location":"Explanation/#presentations","text":"The Presentations file describes and links to presentations about Elesto at various events. Presentations also include YouTube videos, podcasts, interviews, and so on.","title":"Presentations"},{"location":"Explanation/#architecture-decisions-records-adrs","text":"ADRs are the mechanism for contributors to raise design proposals. In turn, the ADRs explain the rationale behind Elesto design and implementation for subsequent contributors. For example, ADR 002: Documentation Structure explains why the Elesto documentation structure was chosen. See the Architecture Decision Records (ADR) README file for more details about raising and proposing an ADR.","title":"Architecture Decisions Records (ADRs)"},{"location":"Explanation/#articles","text":"This folder contains all articles relating to Elesto, includes papers, blog posts, etc. For details, see Articles README .","title":"Articles"},{"location":"Explanation/#discussions","text":"The explanation content includes articles, topics, and so on, and also includes discussion on relevant channels, including Pull Requests and Issues . Important Pull Requests are listed in this document. Future: Elesto currently does not have a Discord or Telegram Channel. When we do, the links will be added here as well.","title":"Discussions"},{"location":"Explanation/#contributing","text":"The Explanation content should be dry, clear, and terse in style. All documentation is written following Google Documentation Best Practice Autogenerate documentation from the code whenever possible. Raise a PR for all documentation changes Follow our Code of Conduct","title":"Contributing"},{"location":"Explanation/#reference","text":"Google Style Guide for Markdown Write the Docs global community Write the Docs Code of Conduct","title":"Reference"},{"location":"Explanation/presentations/","text":"Presentations Below are the related links to the Cosmos Cash slides, interviews, presentations. Slides Tendermint <> ECB - May 2021 Interviews Paddy Mchale interview with Jack Zampolin - July 2021 34 minutes Alessio interview Cryptocito on CBDCs 55 minutes Demos","title":"Presentations"},{"location":"Explanation/presentations/#presentations","text":"Below are the related links to the Cosmos Cash slides, interviews, presentations.","title":"Presentations"},{"location":"Explanation/presentations/#slides","text":"Tendermint <> ECB - May 2021","title":"Slides"},{"location":"Explanation/presentations/#interviews","text":"Paddy Mchale interview with Jack Zampolin - July 2021 34 minutes Alessio interview Cryptocito on CBDCs 55 minutes","title":"Interviews"},{"location":"Explanation/presentations/#demos","text":"","title":"Demos"},{"location":"Explanation/ADR/","text":"Architecture Decision Records (ADRs) This section includes all high-level architecture decisions for the Elesto protocol. Definitions Within the context of an ADR, we define the following: Architectural decision records (ADRs) are documents that describe a software design choice that addresses a functional or non-functional requirement that is architecturally significant. An architectural decision record (ADR) document describes a software design choice that addresses a functional or non-functional requirement that is architecturally significant. The collection of ADRs created and maintained in this project constitutes its decision log. An architecturally significant requirement (ASR) is a requirement that has a measurable effect on a software system\u2019s architecture and quality. All these records are within the topic of Architectural Knowledge Management (AKM). You can read more about the ADR concept in the Documenting architecture decisions, the Reverb way blog post. Rationale ADRs are intended to be the primary mechanism for proposing new feature designs and processes, collecting community input on an issue, and documenting the design decisions. An ADR provides: Context on the relevant goals and the current state Proposed changes to achieve the goals Summary of pros and cons References Changelog Note the distinction between an ADR and a specification. The ADR provides the context, intuition, reasoning, and justification for a change in architecture or the architecture of something new. The specification is a summary of everything as it stands today. If recorded decisions turned out to be lacking the required substance, the process is to convene a discussion, record the new decisions here, and then modify the code to match. Creating new ADRs See ADR Creation Process . Use RFC 2119 keywords When writing ADRs, follow the best practices that apply to writing RFCs . Keywords are used to signify the requirements in the specification and are often capitalized: \"MUST\" \"MUST NOT\" \"REQUIRED\" \"SHALL\" \"SHALL NOT\" \"SHOULD\" \"SHOULD NOT\" \"RECOMMENDED\" \"MAY\" \"OPTIONAL\" Keywords are to be interpreted as described in RFC 2119 .","title":"About Architecture Decision Records (ADRs)"},{"location":"Explanation/ADR/#architecture-decision-records-adrs","text":"This section includes all high-level architecture decisions for the Elesto protocol.","title":"Architecture Decision Records (ADRs)"},{"location":"Explanation/ADR/#definitions","text":"Within the context of an ADR, we define the following: Architectural decision records (ADRs) are documents that describe a software design choice that addresses a functional or non-functional requirement that is architecturally significant. An architectural decision record (ADR) document describes a software design choice that addresses a functional or non-functional requirement that is architecturally significant. The collection of ADRs created and maintained in this project constitutes its decision log. An architecturally significant requirement (ASR) is a requirement that has a measurable effect on a software system\u2019s architecture and quality. All these records are within the topic of Architectural Knowledge Management (AKM). You can read more about the ADR concept in the Documenting architecture decisions, the Reverb way blog post.","title":"Definitions"},{"location":"Explanation/ADR/#rationale","text":"ADRs are intended to be the primary mechanism for proposing new feature designs and processes, collecting community input on an issue, and documenting the design decisions. An ADR provides: Context on the relevant goals and the current state Proposed changes to achieve the goals Summary of pros and cons References Changelog Note the distinction between an ADR and a specification. The ADR provides the context, intuition, reasoning, and justification for a change in architecture or the architecture of something new. The specification is a summary of everything as it stands today. If recorded decisions turned out to be lacking the required substance, the process is to convene a discussion, record the new decisions here, and then modify the code to match.","title":"Rationale"},{"location":"Explanation/ADR/#creating-new-adrs","text":"See ADR Creation Process .","title":"Creating new ADRs"},{"location":"Explanation/ADR/#use-rfc-2119-keywords","text":"When writing ADRs, follow the best practices that apply to writing RFCs . Keywords are used to signify the requirements in the specification and are often capitalized: \"MUST\" \"MUST NOT\" \"REQUIRED\" \"SHALL\" \"SHALL NOT\" \"SHOULD\" \"SHOULD NOT\" \"RECOMMENDED\" \"MAY\" \"OPTIONAL\" Keywords are to be interpreted as described in RFC 2119 .","title":"Use RFC 2119 keywords"},{"location":"Explanation/ADR/PROCESS/","text":"ADR Creation Process Copy the adr-template.md file. Use the following filename pattern: adr-next_number-title.md Create a draft Pull Request to get early feedback. Make sure the context and a solution are clear and well documented. Add an entry to a list in the README file. Create a Pull Request to propose a new ADR. ADR life cycle ADR creation is an iterative process. Instead of solving all decisions in a single ADR pull request, we MUST initially understand the problem and collect feedback by having conversations in a GitHub Issue. Every ADR proposal SHOULD start with a new GitHub issue or be a result of existing Issues. The Issue must contain a brief proposal summary. After the motivation is validated, create a new document on the adr-template.md . An ADR solution does not have to arrive to the main branch with an accepted status in a single PR. If the motivation is clear and the solution is sound, we SHOULD be able to merge PRs iteratively and keep a proposed status. It is preferable to have an iterative approach rather than long, not merged Pull Requests. If a proposed ADR is merged, then the outstanding changes must be clearly documented in outstanding issues in ADR document notes or in a GitHub Issue. The PR SHOULD always be merged. In the case of a faulty ADR, we still prefer to merge it with a rejected status. The only time the ADR SHOULD NOT be merged is if the author abandons it. Merged ADRs SHOULD NOT be pruned. ADR status Status has two components: {CONSENSUS STATUS} {IMPLEMENTATION STATUS} IMPLEMENTATION STATUS is either Implemented or Not Implemented . Consensus Status DRAFT -> PROPOSED -> LAST CALL yyyy-mm-dd -> ACCEPTED | REJECTED -> SUPERSEEDED by ADR-xxx \\ | \\ | v v ABANDONED DRAFT : [optional] an ADR, which is a work in progress, not being ready for a general review. This is to present an early work and get an early feedback in a Draft Pull Request form. PROPOSED : an ADR covering a full solution architecture and still in the review - project stakeholders have not reached an agreement yet. LAST CALL <date for the last call> : [optional] clear notify that we are close to accept updates. Changing status to LAST CALL means that social consensus (of Elesto maintainers) has been reached, and we still want to give it time to let the community react or analyze. ACCEPTED : ADR, which will represent a currently implemented or to be implemented architecture design. REJECTED : ADR can go from PROPOSED or ACCEPTED to rejected if the consensus among project stakeholders will decide. SUPERSEEDED by ADR-xxx : ADR which has been superseded by a new ADR. ABANDONED : the ADR is no longer pursued by the original authors. Language used in ADR Write the context/background in the present tense. Avoid using a first, personal form.","title":"ADR Creation Process"},{"location":"Explanation/ADR/PROCESS/#adr-creation-process","text":"Copy the adr-template.md file. Use the following filename pattern: adr-next_number-title.md Create a draft Pull Request to get early feedback. Make sure the context and a solution are clear and well documented. Add an entry to a list in the README file. Create a Pull Request to propose a new ADR.","title":"ADR Creation Process"},{"location":"Explanation/ADR/PROCESS/#adr-life-cycle","text":"ADR creation is an iterative process. Instead of solving all decisions in a single ADR pull request, we MUST initially understand the problem and collect feedback by having conversations in a GitHub Issue. Every ADR proposal SHOULD start with a new GitHub issue or be a result of existing Issues. The Issue must contain a brief proposal summary. After the motivation is validated, create a new document on the adr-template.md . An ADR solution does not have to arrive to the main branch with an accepted status in a single PR. If the motivation is clear and the solution is sound, we SHOULD be able to merge PRs iteratively and keep a proposed status. It is preferable to have an iterative approach rather than long, not merged Pull Requests. If a proposed ADR is merged, then the outstanding changes must be clearly documented in outstanding issues in ADR document notes or in a GitHub Issue. The PR SHOULD always be merged. In the case of a faulty ADR, we still prefer to merge it with a rejected status. The only time the ADR SHOULD NOT be merged is if the author abandons it. Merged ADRs SHOULD NOT be pruned.","title":"ADR life cycle"},{"location":"Explanation/ADR/PROCESS/#adr-status","text":"Status has two components: {CONSENSUS STATUS} {IMPLEMENTATION STATUS} IMPLEMENTATION STATUS is either Implemented or Not Implemented .","title":"ADR status"},{"location":"Explanation/ADR/PROCESS/#consensus-status","text":"DRAFT -> PROPOSED -> LAST CALL yyyy-mm-dd -> ACCEPTED | REJECTED -> SUPERSEEDED by ADR-xxx \\ | \\ | v v ABANDONED DRAFT : [optional] an ADR, which is a work in progress, not being ready for a general review. This is to present an early work and get an early feedback in a Draft Pull Request form. PROPOSED : an ADR covering a full solution architecture and still in the review - project stakeholders have not reached an agreement yet. LAST CALL <date for the last call> : [optional] clear notify that we are close to accept updates. Changing status to LAST CALL means that social consensus (of Elesto maintainers) has been reached, and we still want to give it time to let the community react or analyze. ACCEPTED : ADR, which will represent a currently implemented or to be implemented architecture design. REJECTED : ADR can go from PROPOSED or ACCEPTED to rejected if the consensus among project stakeholders will decide. SUPERSEEDED by ADR-xxx : ADR which has been superseded by a new ADR. ABANDONED : the ADR is no longer pursued by the original authors.","title":"Consensus Status"},{"location":"Explanation/ADR/PROCESS/#language-used-in-adr","text":"Write the context/background in the present tense. Avoid using a first, personal form.","title":"Language used in ADR"},{"location":"Explanation/ADR/adr-002-did/","text":"ADR 002: DID Changelog 2022-02-14: Moved to last call 2022-02-14: Renamed to ADR002 2021-09-23: Added security and privacy considerations 2021-08-02: Initial draft Status LAST CALL 2022-02-28 Abstract Decentralized identifiers (DIDs) are a type of identifier that enables verifiable, decentralized digital identity. A DID refer to any subject (for example, a person, organization, thing, data model, abstract entity, and so on) as determined by the controller of the DID. This document specifies the DID method for a Cosmos SDK-based implementation of the W3C recommendation, its properties, operations, and an explanation of the process to resolve DIDs to the resources that they represent. Context The aim of the Elesto project is to provide a state-of-the-art platform for the hosting of collateralized stable coins that is compliant with: EU regulations such as General Data Protection Regulation (GDPR) and Markets in Crypto-Assets (MiCA) International recommendations such as the Financial Action Task Force (FATF) \"Travel Rule\" Local anti-money laundering (AML) regulations The Elesto platform is based on the following principles: Open financial infrastructure is a public good Money laundering prevention also benefits society Users benefit from a strict privacy-respecting approach (GDPR) The self-sovereign identity (SSI) approach to tackling the identity and privacy challenge has been gaining momentum in recent years. Coupled with distributed ledger technology (DLT) technology, the SSI approach has been capturing the attention of both the private and public sectors. The SSI approach relies on two building blocks: decentralized identifiers (DID) and verifiable credentials (VC). This architecture decision record (ADR) describes the DID implementation in a Cosmos SDK-based blockchain. The goal of this ADR is to define a foundation for the necessary components to realize the Elesto objectives while ensuring the implementation of the DID is fully compliant with the W3C specifications. Successive iterations will address API ergonomics and standard compatibility issues. Decision The Elesto implementation for DIDs will follow the DID W3C core recommendations with the goal of maximizing compatibility with 3rd party tools and projects. DID Method Name The namestring that shall identify the Elesto DID method is: cosmos . A DID that uses the Elesto method MUST begin with the following prefix: did:cosmos . Per the W3C DID specification , this prefix string MUST be in lowercase. The remainder of the DID, after the prefix, is as follows: Method Specific Identifier The namespace specific identifier is defined by the following ABNF: cosmos-did = \"did:cosmos:\" identifier-type identifier-type = cosmos-key / cosmos-network cosmos-key = \"key:\" 1*255 id-char \"1\" 20*255 HEXDIG cosmos-network = \"net:\" 1*255 id-char \":\" unique-identifier unique-identifier = 38*255 id-char id-char = ALPHA / DIGIT / ( ALPHA \"-\" ) / ( DIGIT \"-\" ) For the unique-identifier it is RECOMMENDED to use a UUID. The identifier-type distinguishes between two DID types: The key type, inspired from the did:key method The net type that identifies the DID and the originating network of the DID DIDs of key type are ephemeral and immutable. DIDs of key type are always generated from the Cosmos blockchain address they refer to. For example, see these DIDs of key type: did:cosmos:key:cash1ts9ejqg7k4ht2sm53hycty875362yqxqmt9grj did:cosmos:key:cosmos1lvl2s8x4pta5f96appxrwn3mypsvumukvk7ck2 DIDs of net type are persistent and mutable. DIDs of net type are stored in the node database and can be created and updated according to rules described in the DID Operations section. For example, see these DIDs of net type: did:cosmos:net:cash:806e557e-ecdb-4e80-ab0d-a82ad35c9ceb did:cosmos:net:cosmoshub:1cc7813c-bb31-4999-a768-19424e6c10fa DID Operations DID and associated DID documents are managed by a Cosmos SDK module that uses the gRPC communication protocol. See Method operations for details on how the create, read, update and delete (CRUD) operations are handed in a Cosmos DID. Create To create and publish a DID document use the message MsgCreateDidDocument ( id string , signerPubKey string ) The message parameters are the DID to be created and the signerPubKey . The signerPubKey MUST be the public key of the account that signs the transaction. The public key MUST be used to attach a verification method of type EcdsaSecp256k1VerificationKey2019 with the value of publicKeyMultibase that contains the public key encoded according to the Multibase Data Format Hexadecimal upper-case encoding . The verification method controller MUST be one of the following: The DID of the document The DID of key type of the address that signs the transaction The verification method id SHOULD be generated as: {verificationMethodController}#{CosmosAddressFromPubKey} The verification method id MUST be listed in the authentication relationships. If the input DID is not a valid DID for the Cosmos method, or if the DID already exists on-chain, the message returns an error. Contextually with the creation of a DID document, a DID document metadata MUST be created with the following values: The hash of the transaction as versionId The block time for the created and updated fields The deactivated field is false To address privacy concerns: Use an id that is different from the blockchain account address Isolate the verification methods to the DID subject (for example, during key rotation) Note: A more fine-grained DID creation method can be implemented with the goal of saving in gas by executing a single transaction in a complex DID scenario. Resolve and Verify The integrity of the DID documents stored on the ledger is guaranteed by the underlying blockchain protocol. A DID can be resolved using the gRPC message: QueryDidDocumentRequest ( did string ) This example shows a DID document that was resolved using the gRPC interface: { \"didDocument\" : { \"context\" : [ \"https://www.w3.org/ns/did/v1\" ], \"id\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"controller\" : [ \"did:cosmos:key:cosmos1sl48sj2jjed7enrv3lzzplr9wc2f5js5tzjph8\" ], \"verificationMethod\" : [ { \"controller\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"id\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" , \"publicKeyMultibase\" : \"0248a5178d7a90ec187b3c3d533a4385db905f6fcdaac5026859ca5ef7b0b1c3b5\" , \"type\" : \"EcdsaSecp256k1VerificationKey2019\" } ], \"authentication\" : [ \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" ] }, \"didMetadata\" : { \"versionId\" : \"9f7c547dc852af60c9da1fd514e1497d407b6a3d8ae3e52b626d536519dc8f4c\" , \"created\" : \"2021-08-23T08:24:26.972761898Z\" , \"updated\" : \"2021-08-24T15:54:40.902858856Z\" , \"deactivated\" : false } } The DID can also be resolved by a REST endpoint. The REST endpoint MUST be compatible with the W3C DID core recommendations and pass the DID Core Specification Test Suite : {NODE_URL}:{NODE_REST_PORT}/identifier/{did} This example shows a DID document that was resolved using a REST endpoint: { \"didDocument\" : { \"@context\" : [ \"https://www.w3.org/ns/did/v1\" ], \"id\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"controller\" : [ \"did:cosmos:key:cosmos1sl48sj2jjed7enrv3lzzplr9wc2f5js5tzjph8\" ], \"verificationMethod\" : [ { \"controller\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"id\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" , \"publicKeyMultibase\" : \"0248a5178d7a90ec187b3c3d533a4385db905f6fcdaac5026859ca5ef7b0b1c3b5\" , \"type\" : \"EcdsaSecp256k1VerificationKey2019\" } ], \"authentication\" : [ \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" ] }, \"didDocumentMetadata\" : { \"versionId\" : \"4f0f8857ab36bdeee0ddb541ea7e7b9cb509d29e1103cc7def44d3d1e8220c22\" , \"created\" : \"2021-08-23T08:24:26.972761898Z\" , \"updated\" : \"2021-08-24T15:54:40.902858856Z\" }, \"didResolutionMetadata\" : { \"contentType\" : \"application/ld+json\" , \"did\" : { \"method\" : \"cosmos\" , \"methodSpecificId\" : \"net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" } } } Update There are two ways of updating a DID document: Manage DID controllers Manipulate verification methods and relationships In both cases, the target DID must exist on-chain and the signerAccount must exist as a verification method in a verification relationship of type authentication or it's key DID be listed as a DID controller. Additionally the DID document MUST NOT be in a deactivated status. Each update operation MUST update the versionId and the updated field of the associated DID document metadata with the transaction hash and the block time respectively. Manage DID Controllers Set the DID controllers using the gRPC message: MsgUpdateDidDocument ( did string , controllers [] string , signerAccount string ) The parameters are as follows: did identifies the DID document controllers are a list of Cosmos addresses that will replace the DID document controllers list signerAccount is the account address that signs the transaction Controllers will be added using the did:cosmos:key: method type. A controller of a DID document MUST be a DID of type key . Manipulate Verification Methods and Relationships Add a new verification method using the gRPC message: MsgAddVerification ( did string , accountId string , relationships [] string , signerAccount string ) The parameters are as follows: did identifies the did document accountId is the account to be added to the verification method relationships is the list of relationships that the accountId will be registered into signerAccount is the account address that is signing the transaction The list of relationships must contain only valid verification relationships names as defined in the DID document and MUST be non-empty: Set the relationships of a verification method using the gRPC message: MsgSetVerificationRelationships(did string, accountId string, relationships []string, signerAccount string) Services A service MUST be an entity with the following properties: id : a valid RFC3986 URI string. type : a non empty string. serviceEndpoint : a valid RFC3986 URI string. A service can be added using the gRPC method: MsgAddService ( did string , service_data Service , signerAccount string ) The id of a service MUST be unique within the DID document. A service can be deleted using the gRPC message: MsgDeleteService ( did string , service_id string , signerAccount string ) Deactivate A DID can be deactivated using the gRPC message: MsgDeactivateDid ( did string , signerAccount string ) The operation MUST update the DID document metadata and set the deactivated value to true. The operation is not reversible. Method-Specific Properties DID Core Verification Material The Verification Material type MUST support: Type EcdsaSecp256k1VerificationKey2019 with pubKeyMultibase to encode a Cosmos account public key in hexadecimal format Type CosmosAccountAddress with blockchainAccountID to represent a Cosmos account Support for other verification materials can be added. Verification Relationships The DID document MUST support the following verification relationships : authentication - authorizes amends to the DID document assertionMethod keyAgreement capabilityInvocation capabilityDelegation DID Document Metadata The implementation for DID document metadata MUST report the following properties for a DID document: created : a datetime string of the creation date that is the UTC date associated with the block height when the DID document was submitted the first time updated : a datetime string of the last update date that is the UTC date associated with the block height when the DID document was submitted the last time deactivated : a boolean field that indicates if the DID document is deactivated versionId : a hex-encoded BLAKE2b hash of the transaction that created or updated the DID DID Resolution Metadata The DID Resolution Metadata is outside the scope of the gRPC interface and is not covered in this ADR. DID URL Syntax The DID URL Syntax is outside the scope of the gRPC interface and is not covered in this ADR. DID Query Parameters The DID Query parameters URL is outside the scope of the gRPC interface and is not covered in this ADR. Privacy Considerations When any data (for example, W3C Verifiable Credentials) is associated with Cosmos DIDs, sharing that data would also impose sharing the on-chain data graph (for example, transaction history) of the blockchain account that controls the DID. Using personally identifiable information as DID Method-specific identifiers (for example, account name alice) discloses personal information every time the DID is shared with a counterparty. This specification DOES NOT endorse the use of identifiers that correlates to human beings or other sensible subjects. Security Considerations Ephemeral DIDs ( did:cosmos:key type) are generated based on a blockchain address. If access to the authoritative keys for an account are lost, the control of the DID and verifiable data issued by the DID is lost as well. Consequences The Cosmos ecosystem WILL HAVE a DID module that is compatible with the W3C standard and offers a high chance of compatibility with third-party components such as cloud and edge agents, resolvers, and so on. Backwards Compatibility This is a new module so backward compatibility is not a concern. Positive The implementation of the ADR provides the foundation for interoperability with the DID standard and the SSI identity approach. Closely following the W3C standard gives the best chances of successful interoperability with third-party components. Negative The implementation rigidly follows the W3C specification which leaves little room for extensibility. This approach might become an issue for wider adoption. Neutral N/A Further Discussions While an ADR is in the DRAFT or PROPOSED stage, this section contains a summary of issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. The did:key method specifies a key format that is different from the one used in this ADR. This ADR needs to be amended or follow a different approach. The approach proposed is somewhat locked into the current implementation and will have to be revised in successive iterations. Test Cases [optional] N/A References DID Core v1.0 DID Specification Registries (11 February 2022)","title":"ADR 002: DID"},{"location":"Explanation/ADR/adr-002-did/#adr-002-did","text":"","title":"ADR 002: DID"},{"location":"Explanation/ADR/adr-002-did/#changelog","text":"2022-02-14: Moved to last call 2022-02-14: Renamed to ADR002 2021-09-23: Added security and privacy considerations 2021-08-02: Initial draft","title":"Changelog"},{"location":"Explanation/ADR/adr-002-did/#status","text":"LAST CALL 2022-02-28","title":"Status"},{"location":"Explanation/ADR/adr-002-did/#abstract","text":"Decentralized identifiers (DIDs) are a type of identifier that enables verifiable, decentralized digital identity. A DID refer to any subject (for example, a person, organization, thing, data model, abstract entity, and so on) as determined by the controller of the DID. This document specifies the DID method for a Cosmos SDK-based implementation of the W3C recommendation, its properties, operations, and an explanation of the process to resolve DIDs to the resources that they represent.","title":"Abstract"},{"location":"Explanation/ADR/adr-002-did/#context","text":"The aim of the Elesto project is to provide a state-of-the-art platform for the hosting of collateralized stable coins that is compliant with: EU regulations such as General Data Protection Regulation (GDPR) and Markets in Crypto-Assets (MiCA) International recommendations such as the Financial Action Task Force (FATF) \"Travel Rule\" Local anti-money laundering (AML) regulations The Elesto platform is based on the following principles: Open financial infrastructure is a public good Money laundering prevention also benefits society Users benefit from a strict privacy-respecting approach (GDPR) The self-sovereign identity (SSI) approach to tackling the identity and privacy challenge has been gaining momentum in recent years. Coupled with distributed ledger technology (DLT) technology, the SSI approach has been capturing the attention of both the private and public sectors. The SSI approach relies on two building blocks: decentralized identifiers (DID) and verifiable credentials (VC). This architecture decision record (ADR) describes the DID implementation in a Cosmos SDK-based blockchain. The goal of this ADR is to define a foundation for the necessary components to realize the Elesto objectives while ensuring the implementation of the DID is fully compliant with the W3C specifications. Successive iterations will address API ergonomics and standard compatibility issues.","title":"Context"},{"location":"Explanation/ADR/adr-002-did/#decision","text":"The Elesto implementation for DIDs will follow the DID W3C core recommendations with the goal of maximizing compatibility with 3rd party tools and projects.","title":"Decision"},{"location":"Explanation/ADR/adr-002-did/#did-method-name","text":"The namestring that shall identify the Elesto DID method is: cosmos . A DID that uses the Elesto method MUST begin with the following prefix: did:cosmos . Per the W3C DID specification , this prefix string MUST be in lowercase. The remainder of the DID, after the prefix, is as follows:","title":"DID Method Name"},{"location":"Explanation/ADR/adr-002-did/#method-specific-identifier","text":"The namespace specific identifier is defined by the following ABNF: cosmos-did = \"did:cosmos:\" identifier-type identifier-type = cosmos-key / cosmos-network cosmos-key = \"key:\" 1*255 id-char \"1\" 20*255 HEXDIG cosmos-network = \"net:\" 1*255 id-char \":\" unique-identifier unique-identifier = 38*255 id-char id-char = ALPHA / DIGIT / ( ALPHA \"-\" ) / ( DIGIT \"-\" ) For the unique-identifier it is RECOMMENDED to use a UUID. The identifier-type distinguishes between two DID types: The key type, inspired from the did:key method The net type that identifies the DID and the originating network of the DID DIDs of key type are ephemeral and immutable. DIDs of key type are always generated from the Cosmos blockchain address they refer to. For example, see these DIDs of key type: did:cosmos:key:cash1ts9ejqg7k4ht2sm53hycty875362yqxqmt9grj did:cosmos:key:cosmos1lvl2s8x4pta5f96appxrwn3mypsvumukvk7ck2 DIDs of net type are persistent and mutable. DIDs of net type are stored in the node database and can be created and updated according to rules described in the DID Operations section. For example, see these DIDs of net type: did:cosmos:net:cash:806e557e-ecdb-4e80-ab0d-a82ad35c9ceb did:cosmos:net:cosmoshub:1cc7813c-bb31-4999-a768-19424e6c10fa","title":"Method Specific Identifier"},{"location":"Explanation/ADR/adr-002-did/#did-operations","text":"DID and associated DID documents are managed by a Cosmos SDK module that uses the gRPC communication protocol. See Method operations for details on how the create, read, update and delete (CRUD) operations are handed in a Cosmos DID.","title":"DID Operations"},{"location":"Explanation/ADR/adr-002-did/#create","text":"To create and publish a DID document use the message MsgCreateDidDocument ( id string , signerPubKey string ) The message parameters are the DID to be created and the signerPubKey . The signerPubKey MUST be the public key of the account that signs the transaction. The public key MUST be used to attach a verification method of type EcdsaSecp256k1VerificationKey2019 with the value of publicKeyMultibase that contains the public key encoded according to the Multibase Data Format Hexadecimal upper-case encoding . The verification method controller MUST be one of the following: The DID of the document The DID of key type of the address that signs the transaction The verification method id SHOULD be generated as: {verificationMethodController}#{CosmosAddressFromPubKey} The verification method id MUST be listed in the authentication relationships. If the input DID is not a valid DID for the Cosmos method, or if the DID already exists on-chain, the message returns an error. Contextually with the creation of a DID document, a DID document metadata MUST be created with the following values: The hash of the transaction as versionId The block time for the created and updated fields The deactivated field is false To address privacy concerns: Use an id that is different from the blockchain account address Isolate the verification methods to the DID subject (for example, during key rotation) Note: A more fine-grained DID creation method can be implemented with the goal of saving in gas by executing a single transaction in a complex DID scenario.","title":"Create"},{"location":"Explanation/ADR/adr-002-did/#resolve-and-verify","text":"The integrity of the DID documents stored on the ledger is guaranteed by the underlying blockchain protocol. A DID can be resolved using the gRPC message: QueryDidDocumentRequest ( did string ) This example shows a DID document that was resolved using the gRPC interface: { \"didDocument\" : { \"context\" : [ \"https://www.w3.org/ns/did/v1\" ], \"id\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"controller\" : [ \"did:cosmos:key:cosmos1sl48sj2jjed7enrv3lzzplr9wc2f5js5tzjph8\" ], \"verificationMethod\" : [ { \"controller\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"id\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" , \"publicKeyMultibase\" : \"0248a5178d7a90ec187b3c3d533a4385db905f6fcdaac5026859ca5ef7b0b1c3b5\" , \"type\" : \"EcdsaSecp256k1VerificationKey2019\" } ], \"authentication\" : [ \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" ] }, \"didMetadata\" : { \"versionId\" : \"9f7c547dc852af60c9da1fd514e1497d407b6a3d8ae3e52b626d536519dc8f4c\" , \"created\" : \"2021-08-23T08:24:26.972761898Z\" , \"updated\" : \"2021-08-24T15:54:40.902858856Z\" , \"deactivated\" : false } } The DID can also be resolved by a REST endpoint. The REST endpoint MUST be compatible with the W3C DID core recommendations and pass the DID Core Specification Test Suite : {NODE_URL}:{NODE_REST_PORT}/identifier/{did} This example shows a DID document that was resolved using a REST endpoint: { \"didDocument\" : { \"@context\" : [ \"https://www.w3.org/ns/did/v1\" ], \"id\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"controller\" : [ \"did:cosmos:key:cosmos1sl48sj2jjed7enrv3lzzplr9wc2f5js5tzjph8\" ], \"verificationMethod\" : [ { \"controller\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"id\" : \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" , \"publicKeyMultibase\" : \"0248a5178d7a90ec187b3c3d533a4385db905f6fcdaac5026859ca5ef7b0b1c3b5\" , \"type\" : \"EcdsaSecp256k1VerificationKey2019\" } ], \"authentication\" : [ \"did:cosmos:net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" ] }, \"didDocumentMetadata\" : { \"versionId\" : \"4f0f8857ab36bdeee0ddb541ea7e7b9cb509d29e1103cc7def44d3d1e8220c22\" , \"created\" : \"2021-08-23T08:24:26.972761898Z\" , \"updated\" : \"2021-08-24T15:54:40.902858856Z\" }, \"didResolutionMetadata\" : { \"contentType\" : \"application/ld+json\" , \"did\" : { \"method\" : \"cosmos\" , \"methodSpecificId\" : \"net:cosmoscash-testnet:900d82bc-2bfe-45a7-ab22-a8d11773568e\" } } }","title":"Resolve and Verify"},{"location":"Explanation/ADR/adr-002-did/#update","text":"There are two ways of updating a DID document: Manage DID controllers Manipulate verification methods and relationships In both cases, the target DID must exist on-chain and the signerAccount must exist as a verification method in a verification relationship of type authentication or it's key DID be listed as a DID controller. Additionally the DID document MUST NOT be in a deactivated status. Each update operation MUST update the versionId and the updated field of the associated DID document metadata with the transaction hash and the block time respectively. Manage DID Controllers Set the DID controllers using the gRPC message: MsgUpdateDidDocument ( did string , controllers [] string , signerAccount string ) The parameters are as follows: did identifies the DID document controllers are a list of Cosmos addresses that will replace the DID document controllers list signerAccount is the account address that signs the transaction Controllers will be added using the did:cosmos:key: method type. A controller of a DID document MUST be a DID of type key . Manipulate Verification Methods and Relationships Add a new verification method using the gRPC message: MsgAddVerification ( did string , accountId string , relationships [] string , signerAccount string ) The parameters are as follows: did identifies the did document accountId is the account to be added to the verification method relationships is the list of relationships that the accountId will be registered into signerAccount is the account address that is signing the transaction The list of relationships must contain only valid verification relationships names as defined in the DID document and MUST be non-empty: Set the relationships of a verification method using the gRPC message: MsgSetVerificationRelationships(did string, accountId string, relationships []string, signerAccount string) Services A service MUST be an entity with the following properties: id : a valid RFC3986 URI string. type : a non empty string. serviceEndpoint : a valid RFC3986 URI string. A service can be added using the gRPC method: MsgAddService ( did string , service_data Service , signerAccount string ) The id of a service MUST be unique within the DID document. A service can be deleted using the gRPC message: MsgDeleteService ( did string , service_id string , signerAccount string )","title":"Update"},{"location":"Explanation/ADR/adr-002-did/#deactivate","text":"A DID can be deactivated using the gRPC message: MsgDeactivateDid ( did string , signerAccount string ) The operation MUST update the DID document metadata and set the deactivated value to true. The operation is not reversible.","title":"Deactivate"},{"location":"Explanation/ADR/adr-002-did/#method-specific-properties","text":"","title":"Method-Specific Properties"},{"location":"Explanation/ADR/adr-002-did/#did-core-verification-material","text":"The Verification Material type MUST support: Type EcdsaSecp256k1VerificationKey2019 with pubKeyMultibase to encode a Cosmos account public key in hexadecimal format Type CosmosAccountAddress with blockchainAccountID to represent a Cosmos account Support for other verification materials can be added.","title":"DID Core Verification Material"},{"location":"Explanation/ADR/adr-002-did/#verification-relationships","text":"The DID document MUST support the following verification relationships : authentication - authorizes amends to the DID document assertionMethod keyAgreement capabilityInvocation capabilityDelegation","title":"Verification Relationships"},{"location":"Explanation/ADR/adr-002-did/#did-document-metadata","text":"The implementation for DID document metadata MUST report the following properties for a DID document: created : a datetime string of the creation date that is the UTC date associated with the block height when the DID document was submitted the first time updated : a datetime string of the last update date that is the UTC date associated with the block height when the DID document was submitted the last time deactivated : a boolean field that indicates if the DID document is deactivated versionId : a hex-encoded BLAKE2b hash of the transaction that created or updated the DID","title":"DID Document Metadata"},{"location":"Explanation/ADR/adr-002-did/#did-resolution-metadata","text":"The DID Resolution Metadata is outside the scope of the gRPC interface and is not covered in this ADR.","title":"DID Resolution Metadata"},{"location":"Explanation/ADR/adr-002-did/#did-url-syntax","text":"The DID URL Syntax is outside the scope of the gRPC interface and is not covered in this ADR.","title":"DID URL Syntax"},{"location":"Explanation/ADR/adr-002-did/#did-query-parameters","text":"The DID Query parameters URL is outside the scope of the gRPC interface and is not covered in this ADR.","title":"DID Query Parameters"},{"location":"Explanation/ADR/adr-002-did/#privacy-considerations","text":"When any data (for example, W3C Verifiable Credentials) is associated with Cosmos DIDs, sharing that data would also impose sharing the on-chain data graph (for example, transaction history) of the blockchain account that controls the DID. Using personally identifiable information as DID Method-specific identifiers (for example, account name alice) discloses personal information every time the DID is shared with a counterparty. This specification DOES NOT endorse the use of identifiers that correlates to human beings or other sensible subjects.","title":"Privacy Considerations"},{"location":"Explanation/ADR/adr-002-did/#security-considerations","text":"Ephemeral DIDs ( did:cosmos:key type) are generated based on a blockchain address. If access to the authoritative keys for an account are lost, the control of the DID and verifiable data issued by the DID is lost as well.","title":"Security Considerations"},{"location":"Explanation/ADR/adr-002-did/#consequences","text":"The Cosmos ecosystem WILL HAVE a DID module that is compatible with the W3C standard and offers a high chance of compatibility with third-party components such as cloud and edge agents, resolvers, and so on.","title":"Consequences"},{"location":"Explanation/ADR/adr-002-did/#backwards-compatibility","text":"This is a new module so backward compatibility is not a concern.","title":"Backwards Compatibility"},{"location":"Explanation/ADR/adr-002-did/#positive","text":"The implementation of the ADR provides the foundation for interoperability with the DID standard and the SSI identity approach. Closely following the W3C standard gives the best chances of successful interoperability with third-party components.","title":"Positive"},{"location":"Explanation/ADR/adr-002-did/#negative","text":"The implementation rigidly follows the W3C specification which leaves little room for extensibility. This approach might become an issue for wider adoption.","title":"Negative"},{"location":"Explanation/ADR/adr-002-did/#neutral","text":"N/A","title":"Neutral"},{"location":"Explanation/ADR/adr-002-did/#further-discussions","text":"While an ADR is in the DRAFT or PROPOSED stage, this section contains a summary of issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. The did:key method specifies a key format that is different from the one used in this ADR. This ADR needs to be amended or follow a different approach. The approach proposed is somewhat locked into the current implementation and will have to be revised in successive iterations.","title":"Further Discussions"},{"location":"Explanation/ADR/adr-002-did/#test-cases-optional","text":"N/A","title":"Test Cases [optional]"},{"location":"Explanation/ADR/adr-002-did/#references","text":"DID Core v1.0 DID Specification Registries (11 February 2022)","title":"References"},{"location":"Explanation/ADR/adr-002-docs-structure/","text":"ADR 002: Documentation Structure Status ACCEPTED Abstract This ADR proposes a documentation strategy based on the Grand Unified Theory of Documentation (David Laing) as described by Divio . The documentation strategy outlines four specific use cases for documentation. Based on these use cases and other non-functional requirements, a structure is proposed to address these concerns using GitHub as the Content Management System. The documentation strategy also proposes: The use and re-use of document and format templates Specific code owners for documentation Comment and commit templates combined with githook checks The outcome shall be focused, consistent, high quality documentation. Context Good documentation is necessary to the success of software projects. Excellent writing code does not end when your code compiles or even if your test coverage reaches 100%. It is easy to write something a computer understands, it's much harder to write something both a human and a computer understand. As a Code Health-conscious engineer, the mission is to write for humans first computers second. Documentation is an important part of this skill. Google Documentation Best Practice The documentation use cases, as outlined by Divio, are: Allow a new user to get started Show a user how to solve a specific problem Describe the machinery, for example, classes, functions, interfaces, parameters, and so on Explanation and context for design, scope, and so on The goals of well-structured and well-written documentation include: Findability: As per the use case, the technical content can be discovered and accessed Style: The documentation is written in an appropriate style for the use case Consistency: Each type of documentation is written in a consistent style Scoped: Documentation is scoped to a specific use case; for example, a tutorial can provide links but does not include technical content that describes why the software works, a tutorial teaches how to use it Additional Documentation non-functional use cases include: Technical content SHOULD BE as close to the code as reasonably practicable and strive to use the docs as code workflow Technical content SHOULD BE generated from code as much as possible Technical content SHOULD USE a consistent format Technical content SHOULD BE useable from within the repository Technical content COULD HAVE an automatic process that converts the content to a website based on Read The Docs , Gitbook , or other suitable hosting systems Decision To address the use cases outlined in the context, this ADR proposes the following decisions: Use GitHub as primary content management https://github.com/elesto-dao/elesto Use Markdown and LaTeX to deliver research publications Given that GitHub will form the content management system, we propose the following structure: Structure The documentation structure shall use as much as possible a content structure similar to the Divio user cases . Tutorials How-to guides Reference Explanation Oriented to Learning A goal Information Understanding Must Allow a newcomer to get started Show how to solve a specific problem Describe the machinery Explain Takes the form of A lesson A series of steps A dry description A discursive explanation Analogy Teaching a child to cook Recipe in a cookery book An encyclopedia article A paper on culinary social history The specific implementation for Elesto SHOULD BE as per the following tree structure. / \u251c\u2500\u2500 README \u251c\u2500\u2500 CONTRIBUTING \u251c\u2500\u2500 TECHNICAL-SETUP \u251c\u2500\u2500 CODEOWNERS \u251c\u2500\u2500 x/ | \u251c\u2500\u2500 module_a/ | \u251c\u2500\u2500 README | \u251c\u2500\u2500 docs/ | \u251c\u2500\u2500 state | \u251c\u2500\u2500 state_transitions | \u251c\u2500\u2500 messages \u251c\u2500\u2500 docs/ \u251c\u2500\u2500 README \u251c\u2500\u2500 CODEOWNERS \u251c\u2500\u2500 Explanation/ | \u251c\u2500\u2500 README | \u251c\u2500\u2500 ADR/ | | \u251c\u2500\u2500 README | | \u251c\u2500\u2500 PROCESS | | \u251c\u2500\u2500 adr-template | | \u251c\u2500\u2500 adr-{number}-{desc} | \u251c\u2500\u2500 articles/ | | \u251c\u2500\u2500 regulation-litepaper/ | | \u251c\u2500\u2500 ARTICLE | \u251c\u2500\u2500 research/ | \u251c\u2500\u2500 README | \u251c\u2500\u2500 research_topic/ \u251c\u2500\u2500 How-To/ | \u251c\u2500\u2500 HowToDoSomething/ | \u251c\u2500\u2500 HowToDoSomethingElse/ \u251c\u2500\u2500 Reference/ | \u251c\u2500\u2500 README | \u251c\u2500\u2500 GLOSSARY | \u251c\u2500\u2500 MODULES | \u251c\u2500\u2500 use-cases/ | | \u251c\u2500\u2500 use-case-A | | \u251c\u2500\u2500 use-case-B | \u251c\u2500\u2500 architecture/ \u251c\u2500\u2500 Tutorials/ \u251c\u2500\u2500 Tutorial_1/ \u251c\u2500\u2500 Tutorial_2/ Root level documents The following files are required at the repo root level: README.md - General repo overview to introduce the product and orientate the user. All README files must follow the best practices outlined in the GitHub README guidelines. TECHNICAL-SETUP.md - Specific steps on getting started with the repo, can be a link to a tutorial or include the specific action-oriented steps Links to specific tooling setup requirements for development tools, linters, and so on Dependencies such as pre-commit package manager Building the code Running tests CONTRIBUTING.md - Details on how new users can contribute to the project. In specific: Committing changes Commit message formats (see Commit Comments Raising PRs Code of Conduct CODEOWNERS - Although not part of the documentation itself, a CODEOWNERS file defines the code maintainers who are responsible for code in a repository and perform quality assurance on comments, PRs, and issues. Modules In line with Cosmos SDK convention (TODO: needs reference), each module contains its relevant documentation: Module specifications - A document that outlines state transitions x/module-name/docs/ Module-level README.md e.g. x/module-name/README.md README files are classed as reference documentation. Content in module-level README files is descriptive but explanatory. Explanations should be part of issues, Pull Requests, and docs/explanation/architecture. docs/ The docs folder shall include the following files and folders: README.md - SHALL USE this for introduction and orientating the user, based on the content of this ADR and other materials. CODEOWNERS - This CODEOWNERS file details the reviewers for documentation folder. The listed code owners SHALL INCLUDE the code maintainers in the root CODEOWNERS file plus a Tendermint Technical Writing Team member. docs/Reference Reference documentation includes several different forms: README.md - This document outlines the purpose of the reference documentation as per the use-case documentation strategy and methodology. In addition, the README also links to documentation that is created from the code itself, specifically: Code Documentation in the form of Go Docs Swagger API documentation GLOSSARY.md - Review and maintenance must be regularly and consistently applied. These form the terms of reference for users and ensure that discussion and design are based on consistent terms of reference. This file will be similar to Cosmos Network Glossary and can reference this. MODULES.md - A markdown document that has references to module-relevant documentation docs/Reference/use-cases The use-cases folder describes Elesto use cases. Ideally, use cases are written in behavior-driven development (BDD) format. Use case content should be dry and avoid explanations covered in the explanation documentation. docs/Reference/architecture The architecture folder contains architecture diagrams such as component, activity, and sequence diagrams as relevant. Specifically, these assets should be in a format suitable for version management and easy to update. Therefore, these diagrams should be in SVG or DOT format and not image formats (JPEG, PNG, and so on). docs/Explanation The Explanation folder contains content that provides context for readers and is discursive. See the Divio Explanation page for more detail. docs/explanation/README.md - This file orients the reader and explains the content. docs/Explanation/ADR The ADR folder tracks decisions regarding design and architecture (such as this documentation strategy). ADR content includes the following: docs/explanation/adr/README - introduction to ADR docs/explanation/adr/PROCESS.md - describes how to raise ADRs docs/explanation/adr/adr-template.md - template for raising ADR docs/explanation/adr/adr-{number}-{desc}.md - an ADR document docs/Explanation/articles The articles folder contains a sub-folder for each published article. Published articles this COULD REFER to blog posts. The folder should be named such that it describes the article's purpose. Each sub-folder SHALL CONTAIN all the content relevant to the article (for example, images, bibliographies, and so on). These articles can be converted into PDF format using Pandoc. To convert articles to PDF using Pandoc: There SHOULD BE a makefile with targets for calling Pandoc. Note: the process for building PDF files is not part of the commit or release processes but ad-hoc There SHOULD BE a LaTeX template file that can create PDF files with a consistent look and feel. WITH SUITABLE MODIFICATIONS, this COULD BE the Eisvogel template . The makefile and template should be independent of the article There SHOULD BE a README.md that describes how to use the makefile and template and build articles Note: Explanations can come in other forms, particularly issue discussion and Pull Requests. docs/Tutorials As indicated in the overview, tutorials SHALL BE documents that target beginners and guide a user step-by-step through a process to achieve some goal. Please see the Divio tutorial page for details. There SHALL BE a folder for each tutorial. See the Cosmos SDK tutorials as an example. The folder SHALL CONTAIN all of the relevant content for that tutorial. The content SHOULD BE consistent in format with Cosmos SDK tutorials . docs/How-To In contrast to tutorials, how-to guides are a series of actionable steps to help an experienced reader solve a specific problem. These how-to guides SHALL USE templates similar to the tutorials - see above. Templates The documentation SHOULD USE Markdown templates to develop structured technical content like module messages follow templates in the Cosmos SDK. The good docs project Readme editor Code Comments PR review comments also form part of the documentation. Comments SHALL FOLLOW recommendation as per Conventional Comments <label> [decoration]: <subject> [discussion] where label = (praise|nitpick|suggestion|issue|question|thought|chore) Commit Comments Commits comments will also follow a similar format as laid out following the standard defined by Conventional Commits . This commit convention SHOULD BE enforced as part of pre-commit checks. Consequences This section describes the resulting context after applying the decision. Backwards Compatibility After this ADR is implemented, existing documentation will be migrated from existing sources that include: Notion Other Git Repos Published papers Blog posts Positive As a result of this documentation strategy: Content development and maintenance will follow best practices that ensure content is easy to navigate and read Content will be in a consistent format Commits, Issues, and Pull Requests in the repo will follow best practices CHANGELOG and release documentation will benefit from better commit messages, reducing developer effort Negative There may be more effort required Moving modules into new repos may cause inconsistencies in the repo Further Discussions While an ADR is in the DRAFT or PROPOSED stage, this section should summarize issues to be solved in future iterations (usually referencing comments from a pull-request discussion). Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. References Google Style Guide for Markdown Write the Docs global community Write the Docs Code of Conduct","title":"ADR 002: Documentation Structure"},{"location":"Explanation/ADR/adr-002-docs-structure/#adr-002-documentation-structure","text":"","title":"ADR 002: Documentation Structure"},{"location":"Explanation/ADR/adr-002-docs-structure/#status","text":"ACCEPTED","title":"Status"},{"location":"Explanation/ADR/adr-002-docs-structure/#abstract","text":"This ADR proposes a documentation strategy based on the Grand Unified Theory of Documentation (David Laing) as described by Divio . The documentation strategy outlines four specific use cases for documentation. Based on these use cases and other non-functional requirements, a structure is proposed to address these concerns using GitHub as the Content Management System. The documentation strategy also proposes: The use and re-use of document and format templates Specific code owners for documentation Comment and commit templates combined with githook checks The outcome shall be focused, consistent, high quality documentation.","title":"Abstract"},{"location":"Explanation/ADR/adr-002-docs-structure/#context","text":"Good documentation is necessary to the success of software projects. Excellent writing code does not end when your code compiles or even if your test coverage reaches 100%. It is easy to write something a computer understands, it's much harder to write something both a human and a computer understand. As a Code Health-conscious engineer, the mission is to write for humans first computers second. Documentation is an important part of this skill. Google Documentation Best Practice The documentation use cases, as outlined by Divio, are: Allow a new user to get started Show a user how to solve a specific problem Describe the machinery, for example, classes, functions, interfaces, parameters, and so on Explanation and context for design, scope, and so on The goals of well-structured and well-written documentation include: Findability: As per the use case, the technical content can be discovered and accessed Style: The documentation is written in an appropriate style for the use case Consistency: Each type of documentation is written in a consistent style Scoped: Documentation is scoped to a specific use case; for example, a tutorial can provide links but does not include technical content that describes why the software works, a tutorial teaches how to use it Additional Documentation non-functional use cases include: Technical content SHOULD BE as close to the code as reasonably practicable and strive to use the docs as code workflow Technical content SHOULD BE generated from code as much as possible Technical content SHOULD USE a consistent format Technical content SHOULD BE useable from within the repository Technical content COULD HAVE an automatic process that converts the content to a website based on Read The Docs , Gitbook , or other suitable hosting systems","title":"Context"},{"location":"Explanation/ADR/adr-002-docs-structure/#decision","text":"To address the use cases outlined in the context, this ADR proposes the following decisions: Use GitHub as primary content management https://github.com/elesto-dao/elesto Use Markdown and LaTeX to deliver research publications Given that GitHub will form the content management system, we propose the following structure:","title":"Decision"},{"location":"Explanation/ADR/adr-002-docs-structure/#structure","text":"The documentation structure shall use as much as possible a content structure similar to the Divio user cases . Tutorials How-to guides Reference Explanation Oriented to Learning A goal Information Understanding Must Allow a newcomer to get started Show how to solve a specific problem Describe the machinery Explain Takes the form of A lesson A series of steps A dry description A discursive explanation Analogy Teaching a child to cook Recipe in a cookery book An encyclopedia article A paper on culinary social history The specific implementation for Elesto SHOULD BE as per the following tree structure. / \u251c\u2500\u2500 README \u251c\u2500\u2500 CONTRIBUTING \u251c\u2500\u2500 TECHNICAL-SETUP \u251c\u2500\u2500 CODEOWNERS \u251c\u2500\u2500 x/ | \u251c\u2500\u2500 module_a/ | \u251c\u2500\u2500 README | \u251c\u2500\u2500 docs/ | \u251c\u2500\u2500 state | \u251c\u2500\u2500 state_transitions | \u251c\u2500\u2500 messages \u251c\u2500\u2500 docs/ \u251c\u2500\u2500 README \u251c\u2500\u2500 CODEOWNERS \u251c\u2500\u2500 Explanation/ | \u251c\u2500\u2500 README | \u251c\u2500\u2500 ADR/ | | \u251c\u2500\u2500 README | | \u251c\u2500\u2500 PROCESS | | \u251c\u2500\u2500 adr-template | | \u251c\u2500\u2500 adr-{number}-{desc} | \u251c\u2500\u2500 articles/ | | \u251c\u2500\u2500 regulation-litepaper/ | | \u251c\u2500\u2500 ARTICLE | \u251c\u2500\u2500 research/ | \u251c\u2500\u2500 README | \u251c\u2500\u2500 research_topic/ \u251c\u2500\u2500 How-To/ | \u251c\u2500\u2500 HowToDoSomething/ | \u251c\u2500\u2500 HowToDoSomethingElse/ \u251c\u2500\u2500 Reference/ | \u251c\u2500\u2500 README | \u251c\u2500\u2500 GLOSSARY | \u251c\u2500\u2500 MODULES | \u251c\u2500\u2500 use-cases/ | | \u251c\u2500\u2500 use-case-A | | \u251c\u2500\u2500 use-case-B | \u251c\u2500\u2500 architecture/ \u251c\u2500\u2500 Tutorials/ \u251c\u2500\u2500 Tutorial_1/ \u251c\u2500\u2500 Tutorial_2/","title":"Structure"},{"location":"Explanation/ADR/adr-002-docs-structure/#root-level-documents","text":"The following files are required at the repo root level: README.md - General repo overview to introduce the product and orientate the user. All README files must follow the best practices outlined in the GitHub README guidelines. TECHNICAL-SETUP.md - Specific steps on getting started with the repo, can be a link to a tutorial or include the specific action-oriented steps Links to specific tooling setup requirements for development tools, linters, and so on Dependencies such as pre-commit package manager Building the code Running tests CONTRIBUTING.md - Details on how new users can contribute to the project. In specific: Committing changes Commit message formats (see Commit Comments Raising PRs Code of Conduct CODEOWNERS - Although not part of the documentation itself, a CODEOWNERS file defines the code maintainers who are responsible for code in a repository and perform quality assurance on comments, PRs, and issues.","title":"Root level documents"},{"location":"Explanation/ADR/adr-002-docs-structure/#modules","text":"In line with Cosmos SDK convention (TODO: needs reference), each module contains its relevant documentation: Module specifications - A document that outlines state transitions x/module-name/docs/ Module-level README.md e.g. x/module-name/README.md README files are classed as reference documentation. Content in module-level README files is descriptive but explanatory. Explanations should be part of issues, Pull Requests, and docs/explanation/architecture.","title":"Modules"},{"location":"Explanation/ADR/adr-002-docs-structure/#docs","text":"The docs folder shall include the following files and folders: README.md - SHALL USE this for introduction and orientating the user, based on the content of this ADR and other materials. CODEOWNERS - This CODEOWNERS file details the reviewers for documentation folder. The listed code owners SHALL INCLUDE the code maintainers in the root CODEOWNERS file plus a Tendermint Technical Writing Team member.","title":"docs/"},{"location":"Explanation/ADR/adr-002-docs-structure/#docsreference","text":"Reference documentation includes several different forms: README.md - This document outlines the purpose of the reference documentation as per the use-case documentation strategy and methodology. In addition, the README also links to documentation that is created from the code itself, specifically: Code Documentation in the form of Go Docs Swagger API documentation GLOSSARY.md - Review and maintenance must be regularly and consistently applied. These form the terms of reference for users and ensure that discussion and design are based on consistent terms of reference. This file will be similar to Cosmos Network Glossary and can reference this. MODULES.md - A markdown document that has references to module-relevant documentation","title":"docs/Reference"},{"location":"Explanation/ADR/adr-002-docs-structure/#docsreferenceuse-cases","text":"The use-cases folder describes Elesto use cases. Ideally, use cases are written in behavior-driven development (BDD) format. Use case content should be dry and avoid explanations covered in the explanation documentation.","title":"docs/Reference/use-cases"},{"location":"Explanation/ADR/adr-002-docs-structure/#docsreferencearchitecture","text":"The architecture folder contains architecture diagrams such as component, activity, and sequence diagrams as relevant. Specifically, these assets should be in a format suitable for version management and easy to update. Therefore, these diagrams should be in SVG or DOT format and not image formats (JPEG, PNG, and so on).","title":"docs/Reference/architecture"},{"location":"Explanation/ADR/adr-002-docs-structure/#docsexplanation","text":"The Explanation folder contains content that provides context for readers and is discursive. See the Divio Explanation page for more detail. docs/explanation/README.md - This file orients the reader and explains the content.","title":"docs/Explanation"},{"location":"Explanation/ADR/adr-002-docs-structure/#docsexplanationadr","text":"The ADR folder tracks decisions regarding design and architecture (such as this documentation strategy). ADR content includes the following: docs/explanation/adr/README - introduction to ADR docs/explanation/adr/PROCESS.md - describes how to raise ADRs docs/explanation/adr/adr-template.md - template for raising ADR docs/explanation/adr/adr-{number}-{desc}.md - an ADR document","title":"docs/Explanation/ADR"},{"location":"Explanation/ADR/adr-002-docs-structure/#docsexplanationarticles","text":"The articles folder contains a sub-folder for each published article. Published articles this COULD REFER to blog posts. The folder should be named such that it describes the article's purpose. Each sub-folder SHALL CONTAIN all the content relevant to the article (for example, images, bibliographies, and so on). These articles can be converted into PDF format using Pandoc. To convert articles to PDF using Pandoc: There SHOULD BE a makefile with targets for calling Pandoc. Note: the process for building PDF files is not part of the commit or release processes but ad-hoc There SHOULD BE a LaTeX template file that can create PDF files with a consistent look and feel. WITH SUITABLE MODIFICATIONS, this COULD BE the Eisvogel template . The makefile and template should be independent of the article There SHOULD BE a README.md that describes how to use the makefile and template and build articles Note: Explanations can come in other forms, particularly issue discussion and Pull Requests.","title":"docs/Explanation/articles"},{"location":"Explanation/ADR/adr-002-docs-structure/#docstutorials","text":"As indicated in the overview, tutorials SHALL BE documents that target beginners and guide a user step-by-step through a process to achieve some goal. Please see the Divio tutorial page for details. There SHALL BE a folder for each tutorial. See the Cosmos SDK tutorials as an example. The folder SHALL CONTAIN all of the relevant content for that tutorial. The content SHOULD BE consistent in format with Cosmos SDK tutorials .","title":"docs/Tutorials"},{"location":"Explanation/ADR/adr-002-docs-structure/#docshow-to","text":"In contrast to tutorials, how-to guides are a series of actionable steps to help an experienced reader solve a specific problem. These how-to guides SHALL USE templates similar to the tutorials - see above.","title":"docs/How-To"},{"location":"Explanation/ADR/adr-002-docs-structure/#templates","text":"The documentation SHOULD USE Markdown templates to develop structured technical content like module messages follow templates in the Cosmos SDK. The good docs project Readme editor","title":"Templates"},{"location":"Explanation/ADR/adr-002-docs-structure/#code-comments","text":"PR review comments also form part of the documentation. Comments SHALL FOLLOW recommendation as per Conventional Comments <label> [decoration]: <subject> [discussion] where label = (praise|nitpick|suggestion|issue|question|thought|chore)","title":"Code Comments"},{"location":"Explanation/ADR/adr-002-docs-structure/#commit-comments","text":"Commits comments will also follow a similar format as laid out following the standard defined by Conventional Commits . This commit convention SHOULD BE enforced as part of pre-commit checks.","title":"Commit Comments"},{"location":"Explanation/ADR/adr-002-docs-structure/#consequences","text":"This section describes the resulting context after applying the decision.","title":"Consequences"},{"location":"Explanation/ADR/adr-002-docs-structure/#backwards-compatibility","text":"After this ADR is implemented, existing documentation will be migrated from existing sources that include: Notion Other Git Repos Published papers Blog posts","title":"Backwards Compatibility"},{"location":"Explanation/ADR/adr-002-docs-structure/#positive","text":"As a result of this documentation strategy: Content development and maintenance will follow best practices that ensure content is easy to navigate and read Content will be in a consistent format Commits, Issues, and Pull Requests in the repo will follow best practices CHANGELOG and release documentation will benefit from better commit messages, reducing developer effort","title":"Positive"},{"location":"Explanation/ADR/adr-002-docs-structure/#negative","text":"There may be more effort required Moving modules into new repos may cause inconsistencies in the repo","title":"Negative"},{"location":"Explanation/ADR/adr-002-docs-structure/#further-discussions","text":"While an ADR is in the DRAFT or PROPOSED stage, this section should summarize issues to be solved in future iterations (usually referencing comments from a pull-request discussion). Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR.","title":"Further Discussions"},{"location":"Explanation/ADR/adr-002-docs-structure/#references","text":"Google Style Guide for Markdown Write the Docs global community Write the Docs Code of Conduct","title":"References"},{"location":"Explanation/ADR/adr-003-did/","text":"ADR 003: DID Changelog 2022-02-14: Moved to last call 2022-02-14: Renamed to ADR002 2021-09-23: Added security and privacy considerations 2021-08-02: Initial draft Status LAST CALL 2022-02-28 Abstract Decentralized identifiers (DIDs) are a type of identifier that enables verifiable, decentralized digital identity. A DID refer to any subject (for example, a person, organization, thing, data model, abstract entity, and so on) as determined by the controller of the DID. This document specifies the DID method for a Cosmos SDK-based implementation of the W3C recommendation, its properties, operations, and an explanation of the process to resolve DIDs to the resources they represent. Context The Elesto project aims to provide a state-of-the-art platform for the hosting of collateralized stable coins that is compliant with: EU regulations such as General Data Protection Regulation (GDPR) and Markets in Crypto-Assets (MiCA) International recommendations such as the Financial Action Task Force (FATF) \"Travel Rule\" Local anti-money laundering (AML) regulations The Elesto platform is based on the following principles: Open financial infrastructure is a public good Money laundering prevention also benefits society Users benefit from a strict privacy-respecting approach (GDPR) The self-sovereign identity (SSI) approach to tackling the identity and privacy challenge has gained momentum in recent years. Coupled with distributed ledger technology (DLT) technology, the SSI approach has captured the attention of both the private and public sectors. The SSI approach relies on two building blocks: decentralized identifiers (DID) and verifiable credentials (VC). This architecture decision record (ADR) describes the DID implementation in a Cosmos SDK-based blockchain. This ADR aims to define a foundation for the necessary components to realize the Elesto objectives while ensuring the implementation of the DID is fully compliant with the W3C specifications. Successive iterations will address API ergonomics and standard compatibility issues. Decision The Elesto implementation for DIDs will follow the DID W3C core recommendations to maximize compatibility with 3rd party tools and projects. DID Method Name The namestring that shall identify the Elesto DID method is: cosmos . A DID that uses the Elesto method MUST begin with the following prefix: did:cosmos . Per the W3C DID specification , this prefix string MUST be in lowercase. The remainder of the DID, after the prefix, is as follows: Method Specific Identifier The namespace specific identifier is defined by the following ABNF: cosmos-did = \"did:cosmos:\" identifier-type identifier-type = cosmos-key / unique-identifier cosmos-key = \"key:\" 1*255 id-char \"1\" 20*255 HEXDIG unique-identifier = 38*255 id-char id-char = ALPHA / DIGIT / ( ALPHA \"-\" ) / ( DIGIT \"-\" ) / ( ALPHA \":\" ) / ( DIGIT \":\" ) For the unique-identifier it is RECOMMENDED to use a UUID. The identifier-type distinguishes between two DID types: The key type, inspired from the did:key method The unique-identifier type that identifies the DID and the originating network of the DID DIDs of key type are ephemeral and immutable. DIDs of key type are always generated from the Cosmos blockchain address they refer to. For example, see this DID of key type: did:cosmos:key:elesto1ts9ejqg7k4ht2sm53hycty875362yqxqmt9grj DIDs of net type are persistent and mutable. DIDs of net type are stored in the node database and can be created and updated according to rules described in the DID Operations section. For example, see this DID of net type: did:cosmos:elesto:806e557e-ecdb-4e80-ab0d-a82ad35c9ceb DID Operations DID and associated DID documents are managed by a Cosmos SDK module that uses the gRPC communication protocol. See Method operations for details on how the create, read, update and delete (CRUD) operations are handed in a Cosmos DID. Create To create and publish a DID document use the message MsgCreateDidDocument ( id string , signerPubKey string ) The message parameters are the DID to be created and the signerPubKey . The signerPubKey MUST be the public key of the account that signs the transaction. The public key MUST be used to attach a verification method of type EcdsaSecp256k1VerificationKey2019 with the value of publicKeyMultibase that contains the public key encoded according to the Multibase Data Format Hexadecimal upper-case encoding . The verification method controller MUST be one of the following: The DID of the document The DID of key type of the address that signs the transaction The verification method id SHOULD be generated as: {verificationMethodController}#{CosmosAddressFromPubKey} The verification method id MUST be listed in the authentication relationships. If the input DID is not a valid DID for the Cosmos method, or if the DID already exists on-chain, the message returns an error. Contextually with the creation of a DID document, a DID document metadata MUST be created with the following values: The hash of the transaction as versionId The block time for the created and updated fields The deactivated field is false To address privacy concerns: Use an id that is different from the blockchain account address Isolate the verification methods to the DID subject (for example, during key rotation) Note: A more fine-grained DID creation method can be implemented to save gas by executing a single transaction in a complex DID scenario. Resolve and Verify The underlying blockchain protocol guarantees the integrity of the DID documents stored on the ledger. A DID can be resolved using the gRPC message: QueryDidDocumentRequest ( did string ) This example shows a DID document that was resolved using the gRPC interface: { \"didDocument\" : { \"context\" : [ \"https://www.w3.org/ns/did/v1\" ], \"id\" : \"did:cosmos:elesto:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"controller\" : [ \"did:cosmos:key:cosmos1sl48sj2jjed7enrv3lzzplr9wc2f5js5tzjph8\" ], \"verificationMethod\" : [ { \"controller\" : \"did:cosmos:elesto:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"id\" : \"did:cosmos:elesto:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" , \"publicKeyMultibase\" : \"0248a5178d7a90ec187b3c3d533a4385db905f6fcdaac5026859ca5ef7b0b1c3b5\" , \"type\" : \"EcdsaSecp256k1VerificationKey2019\" } ], \"authentication\" : [ \"did:cosmos:elesto:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" ] }, } Note: the DID document resolution following the W3C DID core recommendations and pass the DID Core Specification Test Suite SHOULD be managed outside the node implementation, in a dedicated project. Update A DID document can be updated only if it is persisted on-chain on-chain and must it is of subtype net and it's not in deactivated metadata property is set to false . The possible updates are the following: Add and remove controllers Add and remove services Add and revoke verification method Set verification method relationships Replace the DID document content The constraints on updating a DID document are one of the following: The signerAccount must exist as a verification method in a verification relationship of type authentication The signerAccount key DID is listed as a DID controller. Each update operation MUST update the versionId and the updated field of the associated DID document metadata with the transaction hash and the block time respectively. Add DID document controller Add DID document controllers using the gRPC message: AddController ( MsgAddController { Id string , ControllerDid [] string , SignerAccount string } ) The parameters are as follows: Id identifies the DID document Controller the DID to be added as a controller SignerAccount is the account address that signs the transaction A controller of a DID document MUST be a DID of subtype key . Remove a DID document controller Remove DID document controllers using the gRPC message: DeleteController ( MsgDeleteController { Id string , ControllerDid [] string , SignerAccount string } ) The parameters are: Id identifies the DID document Controller the DID to be removed from the controllers list SignerAccount is the account address that signs the transaction Add a service A service MUST be an entity with the following properties: id : a valid RFC3986 URI string. type : a non empty string. serviceEndpoint : a valid RFC3986 URI string. A service can be added using the gRPC method: AddService ( MsgAddService { Id string , ServiceData Service , SignerAccount string } ) The parameters are: Id identifies the DID document ServiceData contains the service definition as described above SignerAccount is the account address that signs the transaction Remove a service A service can be deleted using the gRPC message: DeleteService ( MsgDeleteService { Id string , ServiceID string , SignerAccount string } ) The parameters are as follows: Id identifies the DID document ServiceID the id of the service to remove SignerAccount is the account address that signs the transaction Verification methods and relationships A verification method and its relationships are manipulated via the Verification object with the following properties: method a verification method as described in the W3C specification relationships a non-empty list of relationships associated to the verification method context a list of additional json-ld contexts to be added to the did document Add a verification method Add a new verification method using the gRPC message: AddVefication ( MsgAddVerification { Id string , Verification Verification , SignerAccount string } ) The fields of the MsgAddVerification message are: Id identifies the did document Verification the verification as described before SignerAccount is the account address that is signing the transaction The list of relationships must contain only valid verification relationships names as defined in the DID document and MUST be non-empty. The verification method id must be unique within the DID document. Remove a verification method Remove a verification method using the gRPC message: RevokeVerification ( MsgRevokeVerification { Id string MethodId string SignerAccount string } ) The fields of the MsgAddVerification message are: Id identifies the did document MethodId the verification method id to remove SignerAccount is the account address that is signing the transaction Set verification method relationships Set the relationships of a verification method using the gRPC message: SetVerificationRelationships ( MsgSetVerificationRelationships { Id string , MethodId string , Relationships [] string , SignerAccount string } ) The fields of the MsgSetVerificationRelationships message are: Id identifies the did document MethodId identifies the method id to change the relationships for Relationships the list of relationships to set SignerAccount is the account address that is signing the transaction The list of relationships must contain only valid verification relationships names as defined in the DID document and MUST be non-empty. Overwrite an existing DID document To completely replace the content of a DID document use the message: UpdateDidDocument ( MsgUpdateDidDocument { Doc DidDocument SignerAccount string } ) The fields of the MsgSetVerificationRelationships message are: Doc the updated DID document SignerAccount is the account address that is signing the transaction The DID of the new DID document must match the existing document. All the validation rules also apply while replacing the document. Deactivate Deactivation of a DID document is not currently supported Method-Specific Properties DID Core Verification Material The Verification Material type MUST support: Type EcdsaSecp256k1VerificationKey2019 with pubKeyMultibase to encode a Cosmos account public key in hexadecimal format Type CosmosAccountAddress with blockchainAccountID to represent a Cosmos account Support for other verification materials can be added. Verification Relationships The DID document MUST support the following verification relationships : authentication - authorizes amends to the DID document assertionMethod keyAgreement capabilityInvocation capabilityDelegation DID Document Metadata The implementation for DID document metadata MUST report the following properties for a DID document: created : a datetime string of the creation date that is the UTC date associated with the block height when the DID document was submitted the first time updated : a datetime string of the last update date that is the UTC date associated with the block height when the DID document was submitted the last time deactivated : a boolean field that indicates if the DID document is deactivated versionId : a hex-encoded BLAKE2b hash of the transaction that created or updated the DID DID Resolution Metadata The DID Resolution Metadata is outside the scope of the gRPC interface and is not covered in this ADR. DID URL Syntax The DID URL Syntax is outside the scope of the gRPC interface and is not covered in this ADR. DID Query Parameters The DID Query parameters URL is outside the scope of the gRPC interface and is not covered in this ADR. Privacy Considerations When any data (for example, W3C Verifiable Credentials) is associated with Cosmos DIDs, sharing that data would also impose sharing the on-chain data graph (for example, transaction history) of the blockchain account that controls the DID. Using personally identifiable information as DID Method-specific identifiers (for example, account name Alice) discloses personal information every time the DID is shared with a counterparty. This specification DOES NOT endorse the use of identifiers that correlate to human beings or other sensible subjects. Security Considerations Ephemeral DIDs ( did:cosmos:key type) are generated based on blockchain addresses. If access to the authoritative keys for an account is lost, the DID's control and verifiable data issued by the DID is lost. Consequences The Cosmos ecosystem WILL HAVE a DID module compatible with the W3C standard and offers a high chance of compatibility with third-party components such as cloud and edge agents, resolvers, etc. Backwards Compatibility This is a new module so backward compatibility is not a concern. Positive The ADR implementation provides the foundation for interoperability with the DID standard and the SSI identity approach. Closely following the W3C standard gives the best chances of successful interoperability with third-party components. Negative The implementation rigidly follows the W3C specification which leaves little room for extensibility. This approach might become an issue for wider adoption. Neutral N/A Further Discussions While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. The did:key method specifies a key format that is different from the one used in this ADR. This ADR needs to be amended or follow a different approach. The approach proposed is somewhat locked into the current implementation and will have to be revised in successive iterations. Test Cases [optional] N/A References DID Core v1.0 DID Specification Registries (11 February 2022)","title":"ADR 003: DID"},{"location":"Explanation/ADR/adr-003-did/#adr-003-did","text":"","title":"ADR 003: DID"},{"location":"Explanation/ADR/adr-003-did/#changelog","text":"2022-02-14: Moved to last call 2022-02-14: Renamed to ADR002 2021-09-23: Added security and privacy considerations 2021-08-02: Initial draft","title":"Changelog"},{"location":"Explanation/ADR/adr-003-did/#status","text":"LAST CALL 2022-02-28","title":"Status"},{"location":"Explanation/ADR/adr-003-did/#abstract","text":"Decentralized identifiers (DIDs) are a type of identifier that enables verifiable, decentralized digital identity. A DID refer to any subject (for example, a person, organization, thing, data model, abstract entity, and so on) as determined by the controller of the DID. This document specifies the DID method for a Cosmos SDK-based implementation of the W3C recommendation, its properties, operations, and an explanation of the process to resolve DIDs to the resources they represent.","title":"Abstract"},{"location":"Explanation/ADR/adr-003-did/#context","text":"The Elesto project aims to provide a state-of-the-art platform for the hosting of collateralized stable coins that is compliant with: EU regulations such as General Data Protection Regulation (GDPR) and Markets in Crypto-Assets (MiCA) International recommendations such as the Financial Action Task Force (FATF) \"Travel Rule\" Local anti-money laundering (AML) regulations The Elesto platform is based on the following principles: Open financial infrastructure is a public good Money laundering prevention also benefits society Users benefit from a strict privacy-respecting approach (GDPR) The self-sovereign identity (SSI) approach to tackling the identity and privacy challenge has gained momentum in recent years. Coupled with distributed ledger technology (DLT) technology, the SSI approach has captured the attention of both the private and public sectors. The SSI approach relies on two building blocks: decentralized identifiers (DID) and verifiable credentials (VC). This architecture decision record (ADR) describes the DID implementation in a Cosmos SDK-based blockchain. This ADR aims to define a foundation for the necessary components to realize the Elesto objectives while ensuring the implementation of the DID is fully compliant with the W3C specifications. Successive iterations will address API ergonomics and standard compatibility issues.","title":"Context"},{"location":"Explanation/ADR/adr-003-did/#decision","text":"The Elesto implementation for DIDs will follow the DID W3C core recommendations to maximize compatibility with 3rd party tools and projects.","title":"Decision"},{"location":"Explanation/ADR/adr-003-did/#did-method-name","text":"The namestring that shall identify the Elesto DID method is: cosmos . A DID that uses the Elesto method MUST begin with the following prefix: did:cosmos . Per the W3C DID specification , this prefix string MUST be in lowercase. The remainder of the DID, after the prefix, is as follows:","title":"DID Method Name"},{"location":"Explanation/ADR/adr-003-did/#method-specific-identifier","text":"The namespace specific identifier is defined by the following ABNF: cosmos-did = \"did:cosmos:\" identifier-type identifier-type = cosmos-key / unique-identifier cosmos-key = \"key:\" 1*255 id-char \"1\" 20*255 HEXDIG unique-identifier = 38*255 id-char id-char = ALPHA / DIGIT / ( ALPHA \"-\" ) / ( DIGIT \"-\" ) / ( ALPHA \":\" ) / ( DIGIT \":\" ) For the unique-identifier it is RECOMMENDED to use a UUID. The identifier-type distinguishes between two DID types: The key type, inspired from the did:key method The unique-identifier type that identifies the DID and the originating network of the DID DIDs of key type are ephemeral and immutable. DIDs of key type are always generated from the Cosmos blockchain address they refer to. For example, see this DID of key type: did:cosmos:key:elesto1ts9ejqg7k4ht2sm53hycty875362yqxqmt9grj DIDs of net type are persistent and mutable. DIDs of net type are stored in the node database and can be created and updated according to rules described in the DID Operations section. For example, see this DID of net type: did:cosmos:elesto:806e557e-ecdb-4e80-ab0d-a82ad35c9ceb","title":"Method Specific Identifier"},{"location":"Explanation/ADR/adr-003-did/#did-operations","text":"DID and associated DID documents are managed by a Cosmos SDK module that uses the gRPC communication protocol. See Method operations for details on how the create, read, update and delete (CRUD) operations are handed in a Cosmos DID.","title":"DID Operations"},{"location":"Explanation/ADR/adr-003-did/#create","text":"To create and publish a DID document use the message MsgCreateDidDocument ( id string , signerPubKey string ) The message parameters are the DID to be created and the signerPubKey . The signerPubKey MUST be the public key of the account that signs the transaction. The public key MUST be used to attach a verification method of type EcdsaSecp256k1VerificationKey2019 with the value of publicKeyMultibase that contains the public key encoded according to the Multibase Data Format Hexadecimal upper-case encoding . The verification method controller MUST be one of the following: The DID of the document The DID of key type of the address that signs the transaction The verification method id SHOULD be generated as: {verificationMethodController}#{CosmosAddressFromPubKey} The verification method id MUST be listed in the authentication relationships. If the input DID is not a valid DID for the Cosmos method, or if the DID already exists on-chain, the message returns an error. Contextually with the creation of a DID document, a DID document metadata MUST be created with the following values: The hash of the transaction as versionId The block time for the created and updated fields The deactivated field is false To address privacy concerns: Use an id that is different from the blockchain account address Isolate the verification methods to the DID subject (for example, during key rotation) Note: A more fine-grained DID creation method can be implemented to save gas by executing a single transaction in a complex DID scenario.","title":"Create"},{"location":"Explanation/ADR/adr-003-did/#resolve-and-verify","text":"The underlying blockchain protocol guarantees the integrity of the DID documents stored on the ledger. A DID can be resolved using the gRPC message: QueryDidDocumentRequest ( did string ) This example shows a DID document that was resolved using the gRPC interface: { \"didDocument\" : { \"context\" : [ \"https://www.w3.org/ns/did/v1\" ], \"id\" : \"did:cosmos:elesto:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"controller\" : [ \"did:cosmos:key:cosmos1sl48sj2jjed7enrv3lzzplr9wc2f5js5tzjph8\" ], \"verificationMethod\" : [ { \"controller\" : \"did:cosmos:elesto:900d82bc-2bfe-45a7-ab22-a8d11773568e\" , \"id\" : \"did:cosmos:elesto:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" , \"publicKeyMultibase\" : \"0248a5178d7a90ec187b3c3d533a4385db905f6fcdaac5026859ca5ef7b0b1c3b5\" , \"type\" : \"EcdsaSecp256k1VerificationKey2019\" } ], \"authentication\" : [ \"did:cosmos:elesto:900d82bc-2bfe-45a7-ab22-a8d11773568e#cosmos1x5hrv0hngmg8gls5cft7nphqs83njj25pwxpt0\" ] }, } Note: the DID document resolution following the W3C DID core recommendations and pass the DID Core Specification Test Suite SHOULD be managed outside the node implementation, in a dedicated project.","title":"Resolve and Verify"},{"location":"Explanation/ADR/adr-003-did/#update","text":"A DID document can be updated only if it is persisted on-chain on-chain and must it is of subtype net and it's not in deactivated metadata property is set to false . The possible updates are the following: Add and remove controllers Add and remove services Add and revoke verification method Set verification method relationships Replace the DID document content The constraints on updating a DID document are one of the following: The signerAccount must exist as a verification method in a verification relationship of type authentication The signerAccount key DID is listed as a DID controller. Each update operation MUST update the versionId and the updated field of the associated DID document metadata with the transaction hash and the block time respectively. Add DID document controller Add DID document controllers using the gRPC message: AddController ( MsgAddController { Id string , ControllerDid [] string , SignerAccount string } ) The parameters are as follows: Id identifies the DID document Controller the DID to be added as a controller SignerAccount is the account address that signs the transaction A controller of a DID document MUST be a DID of subtype key . Remove a DID document controller Remove DID document controllers using the gRPC message: DeleteController ( MsgDeleteController { Id string , ControllerDid [] string , SignerAccount string } ) The parameters are: Id identifies the DID document Controller the DID to be removed from the controllers list SignerAccount is the account address that signs the transaction Add a service A service MUST be an entity with the following properties: id : a valid RFC3986 URI string. type : a non empty string. serviceEndpoint : a valid RFC3986 URI string. A service can be added using the gRPC method: AddService ( MsgAddService { Id string , ServiceData Service , SignerAccount string } ) The parameters are: Id identifies the DID document ServiceData contains the service definition as described above SignerAccount is the account address that signs the transaction Remove a service A service can be deleted using the gRPC message: DeleteService ( MsgDeleteService { Id string , ServiceID string , SignerAccount string } ) The parameters are as follows: Id identifies the DID document ServiceID the id of the service to remove SignerAccount is the account address that signs the transaction Verification methods and relationships A verification method and its relationships are manipulated via the Verification object with the following properties: method a verification method as described in the W3C specification relationships a non-empty list of relationships associated to the verification method context a list of additional json-ld contexts to be added to the did document Add a verification method Add a new verification method using the gRPC message: AddVefication ( MsgAddVerification { Id string , Verification Verification , SignerAccount string } ) The fields of the MsgAddVerification message are: Id identifies the did document Verification the verification as described before SignerAccount is the account address that is signing the transaction The list of relationships must contain only valid verification relationships names as defined in the DID document and MUST be non-empty. The verification method id must be unique within the DID document. Remove a verification method Remove a verification method using the gRPC message: RevokeVerification ( MsgRevokeVerification { Id string MethodId string SignerAccount string } ) The fields of the MsgAddVerification message are: Id identifies the did document MethodId the verification method id to remove SignerAccount is the account address that is signing the transaction Set verification method relationships Set the relationships of a verification method using the gRPC message: SetVerificationRelationships ( MsgSetVerificationRelationships { Id string , MethodId string , Relationships [] string , SignerAccount string } ) The fields of the MsgSetVerificationRelationships message are: Id identifies the did document MethodId identifies the method id to change the relationships for Relationships the list of relationships to set SignerAccount is the account address that is signing the transaction The list of relationships must contain only valid verification relationships names as defined in the DID document and MUST be non-empty. Overwrite an existing DID document To completely replace the content of a DID document use the message: UpdateDidDocument ( MsgUpdateDidDocument { Doc DidDocument SignerAccount string } ) The fields of the MsgSetVerificationRelationships message are: Doc the updated DID document SignerAccount is the account address that is signing the transaction The DID of the new DID document must match the existing document. All the validation rules also apply while replacing the document.","title":"Update"},{"location":"Explanation/ADR/adr-003-did/#deactivate","text":"Deactivation of a DID document is not currently supported","title":"Deactivate"},{"location":"Explanation/ADR/adr-003-did/#method-specific-properties","text":"","title":"Method-Specific Properties"},{"location":"Explanation/ADR/adr-003-did/#did-core-verification-material","text":"The Verification Material type MUST support: Type EcdsaSecp256k1VerificationKey2019 with pubKeyMultibase to encode a Cosmos account public key in hexadecimal format Type CosmosAccountAddress with blockchainAccountID to represent a Cosmos account Support for other verification materials can be added.","title":"DID Core Verification Material"},{"location":"Explanation/ADR/adr-003-did/#verification-relationships","text":"The DID document MUST support the following verification relationships : authentication - authorizes amends to the DID document assertionMethod keyAgreement capabilityInvocation capabilityDelegation","title":"Verification Relationships"},{"location":"Explanation/ADR/adr-003-did/#did-document-metadata","text":"The implementation for DID document metadata MUST report the following properties for a DID document: created : a datetime string of the creation date that is the UTC date associated with the block height when the DID document was submitted the first time updated : a datetime string of the last update date that is the UTC date associated with the block height when the DID document was submitted the last time deactivated : a boolean field that indicates if the DID document is deactivated versionId : a hex-encoded BLAKE2b hash of the transaction that created or updated the DID","title":"DID Document Metadata"},{"location":"Explanation/ADR/adr-003-did/#did-resolution-metadata","text":"The DID Resolution Metadata is outside the scope of the gRPC interface and is not covered in this ADR.","title":"DID Resolution Metadata"},{"location":"Explanation/ADR/adr-003-did/#did-url-syntax","text":"The DID URL Syntax is outside the scope of the gRPC interface and is not covered in this ADR.","title":"DID URL Syntax"},{"location":"Explanation/ADR/adr-003-did/#did-query-parameters","text":"The DID Query parameters URL is outside the scope of the gRPC interface and is not covered in this ADR.","title":"DID Query Parameters"},{"location":"Explanation/ADR/adr-003-did/#privacy-considerations","text":"When any data (for example, W3C Verifiable Credentials) is associated with Cosmos DIDs, sharing that data would also impose sharing the on-chain data graph (for example, transaction history) of the blockchain account that controls the DID. Using personally identifiable information as DID Method-specific identifiers (for example, account name Alice) discloses personal information every time the DID is shared with a counterparty. This specification DOES NOT endorse the use of identifiers that correlate to human beings or other sensible subjects.","title":"Privacy Considerations"},{"location":"Explanation/ADR/adr-003-did/#security-considerations","text":"Ephemeral DIDs ( did:cosmos:key type) are generated based on blockchain addresses. If access to the authoritative keys for an account is lost, the DID's control and verifiable data issued by the DID is lost.","title":"Security Considerations"},{"location":"Explanation/ADR/adr-003-did/#consequences","text":"The Cosmos ecosystem WILL HAVE a DID module compatible with the W3C standard and offers a high chance of compatibility with third-party components such as cloud and edge agents, resolvers, etc.","title":"Consequences"},{"location":"Explanation/ADR/adr-003-did/#backwards-compatibility","text":"This is a new module so backward compatibility is not a concern.","title":"Backwards Compatibility"},{"location":"Explanation/ADR/adr-003-did/#positive","text":"The ADR implementation provides the foundation for interoperability with the DID standard and the SSI identity approach. Closely following the W3C standard gives the best chances of successful interoperability with third-party components.","title":"Positive"},{"location":"Explanation/ADR/adr-003-did/#negative","text":"The implementation rigidly follows the W3C specification which leaves little room for extensibility. This approach might become an issue for wider adoption.","title":"Negative"},{"location":"Explanation/ADR/adr-003-did/#neutral","text":"N/A","title":"Neutral"},{"location":"Explanation/ADR/adr-003-did/#further-discussions","text":"While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. The did:key method specifies a key format that is different from the one used in this ADR. This ADR needs to be amended or follow a different approach. The approach proposed is somewhat locked into the current implementation and will have to be revised in successive iterations.","title":"Further Discussions"},{"location":"Explanation/ADR/adr-003-did/#test-cases-optional","text":"N/A","title":"Test Cases [optional]"},{"location":"Explanation/ADR/adr-003-did/#references","text":"DID Core v1.0 DID Specification Registries (11 February 2022)","title":"References"},{"location":"Explanation/ADR/adr-004-light-client-resolver/","text":"ADR 004: Light Client resolver Changelog 2022-05-05: First Draft Status PROPOSED - Not Implemented Abstract DID resolution is the process of obtaining a DID document for a given DID. This is one of four required operations that can be performed on any DID (\"Read\"; the other ones being \"Create\", \"Update\", and \"Deactivate\"). The details of these operations differ depending on the DID method. Building on top of DID resolution, DID URL dereferencing is the process of retrieving a representation of a resource for a given DID URL. Software and/or hardware that is able to execute these processes is called a DID resolver. Resolvers are off-chain services that query blockchain data, these are widly used for getting DID (Decentralized identifier) Documents from a VDR (Verifiable Data Registry). We need a resolver for the Elesto network that suppliments the VDR application and provides the same guarantees about data security. Context We want to integrate into the SSI ecosystem, one way to do this is by creating a DID resovler and integrating it into the DIF universal resolver. Most resolvers connect to a single node ( did:kilt , did:ethr , did:jolo ) this causes a problem of trust, now users of the resolver need to trust the data requested from the resolver is correct. Resolving a DID Document This section defines an algorithm for DID resolution, based on the abstract functions resolve() and resolveRepresentation() as defined in section DID Resolution in DID-CORE : resolve ( did , resolutionOptions ) -> ( didResolutionMetadata , didDocument , didDocumentMetadata ) resolveRepresentation ( did , resolutionOptions ) -> ( didResolutionMetadata , didDocumentStream , didDocumentMetadata ) The resolve function returns the DID document in its abstract form (a map). The resolveRepresentation function returns a byte stream of the DID Document formatted in the corresponding representation. Resovler implementation The resolvers will use a GRPC client based on the cosmos-sdk protobuffer implementation. This will connect to a full elesto node to get data. Light Client To enable the resolver to have the same guarantees about it's data as querying the blockchain directly we leverage a light client protocol. Light clients are assumed to be initialized once from a trusted source with a trusted header and validator set. The light client protocol allows a client to then securely update its trusted state by requesting and verifying a minimal set of data from a network of full nodes (at least one of which is correct). Data transformation on the resolver Before returning data to the user, some data needs to be transformed. Data transformation is necessary due to some limitations with protobuffers . Rename \"context\" to \"@context\" Remove empty lists based on JSON-LD context Compute DID metadata For ephemeral DIDs , the resolver will generate the resolved document without interacting with the node. Endpoints Two endpoints will be exposed both will have the same functionality but will transform the did document slightly, the aries endpoint is specifically used by aries-framework-go agents . /1.0/identifier /1.0/identifier/aries Sequence Diagram Resolution PUML Dereferencing All conforming DID resolvers implement the following function which has the following abstract form: dereference ( didUrl , dereferenceOptions ) \u2192 \u00ab dereferencingMetadata , contentStream , contentMetadata \u00bb Architecture Decision The scope of this work is two fold: We will create a resolver, this resolver will query data and compute proofs that data is correct. Then we will integrate the resolver into the DIF universal resolver. Resovler implementation The resovler will package a cosmos-sdk GRPC client and a tendermint light client into a golang binary. DIF universal resolver driver implementation The universal resolver driver will be a docker image that can be packaged into the DIF universal resovler. Consequences The implementation of the resolver will take more time than implementing a single node GRPC resovler. Backwards Compatibility N/A Positive Solves the issue with data security between resolver serivce and consuming applications defined in #13 Negative Could complicate resolver deployment Neutral Utilizing tendermint core advanced features Further Discussions Integration into DIF universal-resovler Exposing light client broadcast tx functionality by default Test Cases w3c did test suite References https://w3c-ccg.github.io/did-resolution/ https://github.com/w3c-ccg/did-resolution/issues/13 https://medium.com/decentralized-identity/a-universal-resolver-for-self-sovereign-identifiers-48e6b4a5cc3c https://github.com/decentralized-identity/ethr-did-resolver https://github.com/jolocom/jolo-did-method/tree/master/packages/jolo-did-resolver https://github.com/KILTprotocol/kilt-did-driver https://eth.wiki/concepts/light-client-protocol https://docs.tendermint.com/master/tendermint-core/light-client.html https://developers.google.com/protocol-buffers","title":"ADR 004: Light Client resolver"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#adr-004-light-client-resolver","text":"","title":"ADR 004: Light Client resolver"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#changelog","text":"2022-05-05: First Draft","title":"Changelog"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#status","text":"PROPOSED - Not Implemented","title":"Status"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#abstract","text":"DID resolution is the process of obtaining a DID document for a given DID. This is one of four required operations that can be performed on any DID (\"Read\"; the other ones being \"Create\", \"Update\", and \"Deactivate\"). The details of these operations differ depending on the DID method. Building on top of DID resolution, DID URL dereferencing is the process of retrieving a representation of a resource for a given DID URL. Software and/or hardware that is able to execute these processes is called a DID resolver. Resolvers are off-chain services that query blockchain data, these are widly used for getting DID (Decentralized identifier) Documents from a VDR (Verifiable Data Registry). We need a resolver for the Elesto network that suppliments the VDR application and provides the same guarantees about data security.","title":"Abstract"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#context","text":"We want to integrate into the SSI ecosystem, one way to do this is by creating a DID resovler and integrating it into the DIF universal resolver. Most resolvers connect to a single node ( did:kilt , did:ethr , did:jolo ) this causes a problem of trust, now users of the resolver need to trust the data requested from the resolver is correct.","title":"Context"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#resolving-a-did-document","text":"This section defines an algorithm for DID resolution, based on the abstract functions resolve() and resolveRepresentation() as defined in section DID Resolution in DID-CORE : resolve ( did , resolutionOptions ) -> ( didResolutionMetadata , didDocument , didDocumentMetadata ) resolveRepresentation ( did , resolutionOptions ) -> ( didResolutionMetadata , didDocumentStream , didDocumentMetadata ) The resolve function returns the DID document in its abstract form (a map). The resolveRepresentation function returns a byte stream of the DID Document formatted in the corresponding representation.","title":"Resolving a DID Document"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#resovler-implementation","text":"The resolvers will use a GRPC client based on the cosmos-sdk protobuffer implementation. This will connect to a full elesto node to get data.","title":"Resovler implementation"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#light-client","text":"To enable the resolver to have the same guarantees about it's data as querying the blockchain directly we leverage a light client protocol. Light clients are assumed to be initialized once from a trusted source with a trusted header and validator set. The light client protocol allows a client to then securely update its trusted state by requesting and verifying a minimal set of data from a network of full nodes (at least one of which is correct).","title":"Light Client"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#data-transformation-on-the-resolver","text":"Before returning data to the user, some data needs to be transformed. Data transformation is necessary due to some limitations with protobuffers . Rename \"context\" to \"@context\" Remove empty lists based on JSON-LD context Compute DID metadata For ephemeral DIDs , the resolver will generate the resolved document without interacting with the node.","title":"Data transformation on the resolver"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#endpoints","text":"Two endpoints will be exposed both will have the same functionality but will transform the did document slightly, the aries endpoint is specifically used by aries-framework-go agents . /1.0/identifier /1.0/identifier/aries Sequence Diagram Resolution PUML","title":"Endpoints"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#dereferencing","text":"All conforming DID resolvers implement the following function which has the following abstract form: dereference ( didUrl , dereferenceOptions ) \u2192 \u00ab dereferencingMetadata , contentStream , contentMetadata \u00bb","title":"Dereferencing"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#architecture","text":"","title":"Architecture"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#decision","text":"The scope of this work is two fold: We will create a resolver, this resolver will query data and compute proofs that data is correct. Then we will integrate the resolver into the DIF universal resolver.","title":"Decision"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#resovler-implementation_1","text":"The resovler will package a cosmos-sdk GRPC client and a tendermint light client into a golang binary.","title":"Resovler implementation"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#dif-universal-resolver-driver-implementation","text":"The universal resolver driver will be a docker image that can be packaged into the DIF universal resovler.","title":"DIF universal resolver driver implementation"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#consequences","text":"The implementation of the resolver will take more time than implementing a single node GRPC resovler.","title":"Consequences"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#backwards-compatibility","text":"N/A","title":"Backwards Compatibility"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#positive","text":"Solves the issue with data security between resolver serivce and consuming applications defined in #13","title":"Positive"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#negative","text":"Could complicate resolver deployment","title":"Negative"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#neutral","text":"Utilizing tendermint core advanced features","title":"Neutral"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#further-discussions","text":"Integration into DIF universal-resovler Exposing light client broadcast tx functionality by default","title":"Further Discussions"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#test-cases","text":"w3c did test suite","title":"Test Cases"},{"location":"Explanation/ADR/adr-004-light-client-resolver/#references","text":"https://w3c-ccg.github.io/did-resolution/ https://github.com/w3c-ccg/did-resolution/issues/13 https://medium.com/decentralized-identity/a-universal-resolver-for-self-sovereign-identifiers-48e6b4a5cc3c https://github.com/decentralized-identity/ethr-did-resolver https://github.com/jolocom/jolo-did-method/tree/master/packages/jolo-did-resolver https://github.com/KILTprotocol/kilt-did-driver https://eth.wiki/concepts/light-client-protocol https://docs.tendermint.com/master/tendermint-core/light-client.html https://developers.google.com/protocol-buffers","title":"References"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/","text":"ADR 005: IBC-enabled DIDs Changelog 2022-04-12: Initial draft Status DRAFT Abstract This document describes how Elesto decentralized identifiers behave in the context of the IBC protocol, with particular focus on how they tie in with the Interchain Accounts module. Context In an IBC-enabled ecosystem like Cosmos, application-specific blockchain act as central points of connectivity for a well-defined set of functionalities. One of the main functionality of Elesto is providing decentralized identities infrastructure - such as DIDs themselves and SSI-compatible resolvers - which can benefit from being operated and interacted with by means of the IBC protocol. This document outlines how IBC-enabled DIDs can be implemented by leveraging infrastructures which already exist in the Cosmos ecosystem. General architecture Elesto is the central point of storage for decentralized identifiers in the Cosmos ecosystem. Instead of implementing the W3C DID specification from scratch, chain developers leverage the already-existing infrastructure in Elesto to archive and retrieve identities in a standard-compliant way. Chain developers would just need to include a small library which will take care of setting up the whole communication architecture for them, reducing the \"identity use-case\" time-to-market factor to an almost insignificant value On top of that using Elesto as a unified archive for DIDs in the ecosystem would greatly promote usage of well-defined and adopted standards, pushing forward the decentralized identity use-cases and philosophy. sequenceDiagram actor User User->>Chain A: createDID() activate Chain A Note left of Elesto: This message is routed through IBC Chain A->>+Elesto: createIdentity() Elesto->>-Chain A: identityCreated() deactivate Chain A User->>Chain A: queryIdentity() activate Chain A Note left of Elesto: This message is routed through IBC Chain A->>+Elesto: queryIdentity() Elesto->>-Chain A: queryIdentityResponse() Chain A->>User: queryIdentityResponse() deactivate Chain A Interchain Accounts The Interchain Accounts (IA) standard defines an IBC-enabled way for different blockchains to create and authorize transactions among them, without the need for explicit cryptographic signatures on both sides. A IA-enabled blockchain can either be: - host , where an IA is registered - controller , where IA registration is initiated and user can authorize transactions to be executed on a host Since Elesto wants to provide DID registration and querying functionality to all IA-enabled chains out there, it will act as a host . Controller chains create IA through IBC messages, after that the associated accounts are enabled to execute transactions on the host chain simply because the original transaction has been verified and committed on the controller's ledger: host chains limit themselves to keeping state and obeying whatever the IA module says. Since the Host chain is just in charge of doing minimal validity checks, the Controller chain is in charge of implementing protocol-level checks to assure the user who's broadcasting a IA transaction is doing so with data that belongs to them. Each IA is associated with an IBC channel and port. During the IA creation a Cosmos SDK capability is added to the account holder which allows them to use the newly created IBC channel/port combo. If a user tries to broadcast a IBC transaction on a channel/port combo for which they don't hold a capability, the chain node will refuse the transaction before initiating any IBC-related interactions. Interchain Accounts-enabled DIDs To create a DID a user must broadcast a MsgCreateDidDocument message from an Interchain Account-enabled chain, which is wired to support Elesto's DID message types and part of its protobuf codec. The process works as follows, assuming Chain A and Elesto have the basic IBC components in place: 1. user broadcasts register transaction on Chain A 2. various IBC protocol components will deliver the transaction to Elesto , which will process it and create an IA for the user on its local ledger \u2014 now user can query their own IA Elesto address by querying Chain A 3. user broadcasts a submitTx transaction from Chain A , which contains a well-defined MsgCreateDidDocument 4. IBC transports the message to Elesto , which will validate and eventually execute the message hence creating a DID for the user. The user will be able to query their new DID by using any SSI resolver connected to the Elesto network. sequenceDiagram actor U as User participant A as Chain A participant E as Elesto U ->> A: createIA() Note left of A: This message is chain-local A ->> E: createIA() activate E Note left of E: This message has come from IBC E --> E: create IA for User E ->> A: IAAddressOf(user: User) deactivate E U->>A: createDID() activate A Note left of E: This message has come from IBC A->>+E: createIdentity() E -->> E: parse MsgCreateDidDocument E -->> E: execute MsgCreateDidDocument E->>-A: identityCreated() deactivate A Since spam prevention is embedded in both the IBC protocol and more generally in the Cosmos transactional model, there is no need to add a separate firewalling layer at the Elesto level. Controller chain must check that the user who's broadcasting a DID-related transaction is doing so with data that are referred to them. To do that, Controller chain must check that the id.method metadata matches the user who's broadcasting the transaction. Additional checks on the DID id field are done on Host chain side, which will promptly deny the data write if anything looks suspicious or malformed. Decision Given the drastically lower complexity Interchain Accounts bring, we will integrate a host component in Elesto instead of rolling our own IBC-enabled DID module. We will also design an easy to use library which will allow users and developers to easily integrate into the Elesto identities ecosystem. Considering the design implications and projected use-case of Elesto, we decided to follow through with the user-assigned IBC channel approach in spite of the potential DoS issue \u2014 Interchain DIDs are a much less compelling target for IBC disruptors because they do not yield any economic advantage. Point of actions Integrate IA Host module in Elesto Design a Controller-side module which hooks into IA Controller module and authorizes Interchain DID transaction based on their content Consequences Implementing IBC-enabled DIDs through Interchain Accounts is substantially less intensive in terms of developer and design hours, although there are some negative points to be taken into account. Backwards Compatibility Since controller chains will need to embed a piece of the Elesto models in their own model schema, a clear and up-to-date upgrade path must be provided to them if/when the DID model changes. Positive Solution is easy and quick to implement for both Elesto and controller chains Many chains will benefit from being SSI-compatible with minimal effort Most protocol-level moving parts are already audited and ready to be used Elesto DID work towards distributed identities will benefit the entire ecosystem Negative Since Interchain Accounts rely on IBC, there's risk of the protocol not scaling enough in high-traffic situations IBC clients must be kept in sync to avoid expiration, which could potentially lead to DID being unavailable The IBC protocol brings another layer of abstraction which potentially could makes debugging protocol problems hard There's a potential IBC DoS risk in using Interchain Accounts in their current iteration, which stems from the fact that an attacker could spam IA creation messages and potentially impede other users to interact with Elesto Neutral IBC relayers are scarce, and they'll probably stay like that until proper incentivization is implemented Designing and maintaining a IA-enabled client library is not hard but it surely is tiresome The spam scenario requires capital to be spent on relaying messages and submitting transactions to the Controller chain, hence it is quite unlikely Further Discussions Right now the Elesto DID protocol does not have any form of extra fee payment for the creation of a DID, which should be taken into account before moving this spec from DRAFT to PROPOSED. References Elesto DID specification Interchain Account specification","title":"IBC-enabled DIDs"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#adr-005-ibc-enabled-dids","text":"","title":"ADR 005: IBC-enabled DIDs"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#changelog","text":"2022-04-12: Initial draft","title":"Changelog"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#status","text":"DRAFT","title":"Status"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#abstract","text":"This document describes how Elesto decentralized identifiers behave in the context of the IBC protocol, with particular focus on how they tie in with the Interchain Accounts module.","title":"Abstract"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#context","text":"In an IBC-enabled ecosystem like Cosmos, application-specific blockchain act as central points of connectivity for a well-defined set of functionalities. One of the main functionality of Elesto is providing decentralized identities infrastructure - such as DIDs themselves and SSI-compatible resolvers - which can benefit from being operated and interacted with by means of the IBC protocol. This document outlines how IBC-enabled DIDs can be implemented by leveraging infrastructures which already exist in the Cosmos ecosystem.","title":"Context"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#general-architecture","text":"Elesto is the central point of storage for decentralized identifiers in the Cosmos ecosystem. Instead of implementing the W3C DID specification from scratch, chain developers leverage the already-existing infrastructure in Elesto to archive and retrieve identities in a standard-compliant way. Chain developers would just need to include a small library which will take care of setting up the whole communication architecture for them, reducing the \"identity use-case\" time-to-market factor to an almost insignificant value On top of that using Elesto as a unified archive for DIDs in the ecosystem would greatly promote usage of well-defined and adopted standards, pushing forward the decentralized identity use-cases and philosophy. sequenceDiagram actor User User->>Chain A: createDID() activate Chain A Note left of Elesto: This message is routed through IBC Chain A->>+Elesto: createIdentity() Elesto->>-Chain A: identityCreated() deactivate Chain A User->>Chain A: queryIdentity() activate Chain A Note left of Elesto: This message is routed through IBC Chain A->>+Elesto: queryIdentity() Elesto->>-Chain A: queryIdentityResponse() Chain A->>User: queryIdentityResponse() deactivate Chain A","title":"General architecture"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#interchain-accounts","text":"The Interchain Accounts (IA) standard defines an IBC-enabled way for different blockchains to create and authorize transactions among them, without the need for explicit cryptographic signatures on both sides. A IA-enabled blockchain can either be: - host , where an IA is registered - controller , where IA registration is initiated and user can authorize transactions to be executed on a host Since Elesto wants to provide DID registration and querying functionality to all IA-enabled chains out there, it will act as a host . Controller chains create IA through IBC messages, after that the associated accounts are enabled to execute transactions on the host chain simply because the original transaction has been verified and committed on the controller's ledger: host chains limit themselves to keeping state and obeying whatever the IA module says. Since the Host chain is just in charge of doing minimal validity checks, the Controller chain is in charge of implementing protocol-level checks to assure the user who's broadcasting a IA transaction is doing so with data that belongs to them. Each IA is associated with an IBC channel and port. During the IA creation a Cosmos SDK capability is added to the account holder which allows them to use the newly created IBC channel/port combo. If a user tries to broadcast a IBC transaction on a channel/port combo for which they don't hold a capability, the chain node will refuse the transaction before initiating any IBC-related interactions.","title":"Interchain Accounts"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#interchain-accounts-enabled-dids","text":"To create a DID a user must broadcast a MsgCreateDidDocument message from an Interchain Account-enabled chain, which is wired to support Elesto's DID message types and part of its protobuf codec. The process works as follows, assuming Chain A and Elesto have the basic IBC components in place: 1. user broadcasts register transaction on Chain A 2. various IBC protocol components will deliver the transaction to Elesto , which will process it and create an IA for the user on its local ledger \u2014 now user can query their own IA Elesto address by querying Chain A 3. user broadcasts a submitTx transaction from Chain A , which contains a well-defined MsgCreateDidDocument 4. IBC transports the message to Elesto , which will validate and eventually execute the message hence creating a DID for the user. The user will be able to query their new DID by using any SSI resolver connected to the Elesto network. sequenceDiagram actor U as User participant A as Chain A participant E as Elesto U ->> A: createIA() Note left of A: This message is chain-local A ->> E: createIA() activate E Note left of E: This message has come from IBC E --> E: create IA for User E ->> A: IAAddressOf(user: User) deactivate E U->>A: createDID() activate A Note left of E: This message has come from IBC A->>+E: createIdentity() E -->> E: parse MsgCreateDidDocument E -->> E: execute MsgCreateDidDocument E->>-A: identityCreated() deactivate A Since spam prevention is embedded in both the IBC protocol and more generally in the Cosmos transactional model, there is no need to add a separate firewalling layer at the Elesto level. Controller chain must check that the user who's broadcasting a DID-related transaction is doing so with data that are referred to them. To do that, Controller chain must check that the id.method metadata matches the user who's broadcasting the transaction. Additional checks on the DID id field are done on Host chain side, which will promptly deny the data write if anything looks suspicious or malformed.","title":"Interchain Accounts-enabled DIDs"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#decision","text":"Given the drastically lower complexity Interchain Accounts bring, we will integrate a host component in Elesto instead of rolling our own IBC-enabled DID module. We will also design an easy to use library which will allow users and developers to easily integrate into the Elesto identities ecosystem. Considering the design implications and projected use-case of Elesto, we decided to follow through with the user-assigned IBC channel approach in spite of the potential DoS issue \u2014 Interchain DIDs are a much less compelling target for IBC disruptors because they do not yield any economic advantage.","title":"Decision"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#point-of-actions","text":"Integrate IA Host module in Elesto Design a Controller-side module which hooks into IA Controller module and authorizes Interchain DID transaction based on their content","title":"Point of actions"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#consequences","text":"Implementing IBC-enabled DIDs through Interchain Accounts is substantially less intensive in terms of developer and design hours, although there are some negative points to be taken into account.","title":"Consequences"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#backwards-compatibility","text":"Since controller chains will need to embed a piece of the Elesto models in their own model schema, a clear and up-to-date upgrade path must be provided to them if/when the DID model changes.","title":"Backwards Compatibility"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#positive","text":"Solution is easy and quick to implement for both Elesto and controller chains Many chains will benefit from being SSI-compatible with minimal effort Most protocol-level moving parts are already audited and ready to be used Elesto DID work towards distributed identities will benefit the entire ecosystem","title":"Positive"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#negative","text":"Since Interchain Accounts rely on IBC, there's risk of the protocol not scaling enough in high-traffic situations IBC clients must be kept in sync to avoid expiration, which could potentially lead to DID being unavailable The IBC protocol brings another layer of abstraction which potentially could makes debugging protocol problems hard There's a potential IBC DoS risk in using Interchain Accounts in their current iteration, which stems from the fact that an attacker could spam IA creation messages and potentially impede other users to interact with Elesto","title":"Negative"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#neutral","text":"IBC relayers are scarce, and they'll probably stay like that until proper incentivization is implemented Designing and maintaining a IA-enabled client library is not hard but it surely is tiresome The spam scenario requires capital to be spent on relaying messages and submitting transactions to the Controller chain, hence it is quite unlikely","title":"Neutral"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#further-discussions","text":"Right now the Elesto DID protocol does not have any form of extra fee payment for the creation of a DID, which should be taken into account before moving this spec from DRAFT to PROPOSED.","title":"Further Discussions"},{"location":"Explanation/ADR/adr-005-ibc-enabled-dids/#references","text":"Elesto DID specification Interchain Account specification","title":"References"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/","text":"ADR 006: Verifiable Credentials Changelog 2022-07-04: Initial draft Status DRAFT Abstract Credentials are part of our daily interactions; driver's licenses are used to assert that we are capable of operating a motor vehicle, university degrees can be used to assert our level of education, and concert tickets are used to assert that we can attend an event. Many credential types are used to store personal identifiable information (PII) and therefore must be kept private. However, there are many cases where it is more practical to publish credentials. For example, business licenses are used to assert that a business is legitimate and has the authorization to operate. In this context, a credential is defined as a set of one or more claims made by an issuer and a verifiable credential (VC) as a tamper-evident credential that has authorship that can be cryptographically verified. This document specifies support for VCs for private credentials and public credentials and support for credential definitions. Context The self-sovereign identity (SSI) approach to tackling the identity and privacy challenge has gained momentum in recent years. Coupled with distributed ledger technology (DLT) technology, the SSI approach has captured the attention of the private and public sectors. The SSI approach relies on two building blocks: decentralized identifiers (DID) and VCs. This architecture decision record (ADR) describes the implementation for supporting VCs in a Cosmos SDK-based blockchain. This ADR aims to define a foundation for the components required to realize the Elesto objectives while ensuring the VC implementation is fully compliant with the W3C recommendations. Successive iterations will address API ergonomics and standard compatibility issues. Decision A new credential module for the Elesto implementation for VCs will follow the Verifiable Credentials Data Model W3C Recommendations to maximize compatibility with third-party tools and projects. This ADR introduces two data structures for the Elesto chain: Credential Definition (CD) Public Verifiable Credential (PVC) Credential Definition (CD) CDs are used to describe the model of a credential, that is, its structure, fields, properties, and behavior. CDs consist of the following fields: id - the credential definition did publisherId - the DID of the publisher of the credential name - the human-readable name of the credential description - the description of the credential usage isPublic - the credential can be issued on-chain isActive - a hint that indicates the credentials based on this schema should not be issued supersededBy - id of a new credential definition that supersedes this definition schema - the credential data schema vocab - the credential JSON-LD vocabulary A CD cannot be deleted from the state. Credential Data Schema A credential data schema is a machine-readable definition of fields and data types of a credential. The credential module supports the JsonSchemaValidator2018 JSON-LD type schema format as described in the W3C Verifiable Credentials JSON Schema Specification . The schema is stored as an uncompressed byte slice. Credential JSON-LD vocabulary A credential JSON-LD context is a semantic vocabulary for the credential field descriptions. The vocabulary, in JSON format, is stored as an uncompressed byte slice. Public Verifiable Credential (PVC) With PVCs, a VC is stored on-chain. To publish a VC on-chain, the sender must provide the credential definition that describes the credential. A credential is published only if: The credential definition has been published on-chain The credential definition allows publication of the credential (the field isPublic is true) The credential definition status is active (the field isActive is true) The credential conforms to the schema The proof of the credential can be positively verified The supersededBy is used only for communication purposes and does not influence the publication of a credential. PVCs are intended for advertising information that is public domain and leverages the tamper-resistant capability of the blockchain. A PVC can be deleted from the state. The validation sequence is described in the following diagram: Privacy Considerations There is a risk that a credential definition allows publication of PII since the failsafe mechanism provided by the isPublic field can be misused by the credential publisher. Security Considerations The credential schema and the vocabulary must be stored uncompressed. Compression will make the node vulnerable to a zip bomb attack. Consequences The Elesto chain will provide support for credential schemas and vocabularies. At the same time, support for PVCs provides a strong foundation for a network of trust. Backward Compatibility The credential module is a new module so backward compatibility is not a concern. Positive The ADR implementation improves compatibility with the SSI identity model. Closely following the W3C standard gives the best chance of successful interoperability with third-party components. Negative N/A Neutral N/A Further Discussions While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. Test Cases [optional] N/A References W3C Recommendation Verificable Credentials Data Model v1.1 W3C Verifiable Credentials Data Model v1.1 W3C Recommendation JSON-LD v1.1 W3C Verifiable Credentials JSON Schema Specification Personally Identifiable Information (PII) General Data Protection Regulation (GDPR)","title":"ADR 006: Verifiable Credentials"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#adr-006-verifiable-credentials","text":"","title":"ADR 006: Verifiable Credentials"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#changelog","text":"2022-07-04: Initial draft","title":"Changelog"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#status","text":"DRAFT","title":"Status"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#abstract","text":"Credentials are part of our daily interactions; driver's licenses are used to assert that we are capable of operating a motor vehicle, university degrees can be used to assert our level of education, and concert tickets are used to assert that we can attend an event. Many credential types are used to store personal identifiable information (PII) and therefore must be kept private. However, there are many cases where it is more practical to publish credentials. For example, business licenses are used to assert that a business is legitimate and has the authorization to operate. In this context, a credential is defined as a set of one or more claims made by an issuer and a verifiable credential (VC) as a tamper-evident credential that has authorship that can be cryptographically verified. This document specifies support for VCs for private credentials and public credentials and support for credential definitions.","title":"Abstract"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#context","text":"The self-sovereign identity (SSI) approach to tackling the identity and privacy challenge has gained momentum in recent years. Coupled with distributed ledger technology (DLT) technology, the SSI approach has captured the attention of the private and public sectors. The SSI approach relies on two building blocks: decentralized identifiers (DID) and VCs. This architecture decision record (ADR) describes the implementation for supporting VCs in a Cosmos SDK-based blockchain. This ADR aims to define a foundation for the components required to realize the Elesto objectives while ensuring the VC implementation is fully compliant with the W3C recommendations. Successive iterations will address API ergonomics and standard compatibility issues.","title":"Context"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#decision","text":"A new credential module for the Elesto implementation for VCs will follow the Verifiable Credentials Data Model W3C Recommendations to maximize compatibility with third-party tools and projects. This ADR introduces two data structures for the Elesto chain: Credential Definition (CD) Public Verifiable Credential (PVC)","title":"Decision"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#credential-definition-cd","text":"CDs are used to describe the model of a credential, that is, its structure, fields, properties, and behavior. CDs consist of the following fields: id - the credential definition did publisherId - the DID of the publisher of the credential name - the human-readable name of the credential description - the description of the credential usage isPublic - the credential can be issued on-chain isActive - a hint that indicates the credentials based on this schema should not be issued supersededBy - id of a new credential definition that supersedes this definition schema - the credential data schema vocab - the credential JSON-LD vocabulary A CD cannot be deleted from the state.","title":"Credential Definition (CD)"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#credential-data-schema","text":"A credential data schema is a machine-readable definition of fields and data types of a credential. The credential module supports the JsonSchemaValidator2018 JSON-LD type schema format as described in the W3C Verifiable Credentials JSON Schema Specification . The schema is stored as an uncompressed byte slice.","title":"Credential Data Schema"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#credential-json-ld-vocabulary","text":"A credential JSON-LD context is a semantic vocabulary for the credential field descriptions. The vocabulary, in JSON format, is stored as an uncompressed byte slice.","title":"Credential JSON-LD vocabulary"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#public-verifiable-credential-pvc","text":"With PVCs, a VC is stored on-chain. To publish a VC on-chain, the sender must provide the credential definition that describes the credential. A credential is published only if: The credential definition has been published on-chain The credential definition allows publication of the credential (the field isPublic is true) The credential definition status is active (the field isActive is true) The credential conforms to the schema The proof of the credential can be positively verified The supersededBy is used only for communication purposes and does not influence the publication of a credential. PVCs are intended for advertising information that is public domain and leverages the tamper-resistant capability of the blockchain. A PVC can be deleted from the state. The validation sequence is described in the following diagram:","title":"Public Verifiable Credential (PVC)"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#privacy-considerations","text":"There is a risk that a credential definition allows publication of PII since the failsafe mechanism provided by the isPublic field can be misused by the credential publisher.","title":"Privacy Considerations"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#security-considerations","text":"The credential schema and the vocabulary must be stored uncompressed. Compression will make the node vulnerable to a zip bomb attack.","title":"Security Considerations"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#consequences","text":"The Elesto chain will provide support for credential schemas and vocabularies. At the same time, support for PVCs provides a strong foundation for a network of trust.","title":"Consequences"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#backward-compatibility","text":"The credential module is a new module so backward compatibility is not a concern.","title":"Backward Compatibility"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#positive","text":"The ADR implementation improves compatibility with the SSI identity model. Closely following the W3C standard gives the best chance of successful interoperability with third-party components.","title":"Positive"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#negative","text":"N/A","title":"Negative"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#neutral","text":"N/A","title":"Neutral"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#further-discussions","text":"While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR.","title":"Further Discussions"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#test-cases-optional","text":"N/A","title":"Test Cases [optional]"},{"location":"Explanation/ADR/adr-006-public-verifiable-credential/#references","text":"W3C Recommendation Verificable Credentials Data Model v1.1 W3C Verifiable Credentials Data Model v1.1 W3C Recommendation JSON-LD v1.1 W3C Verifiable Credentials JSON Schema Specification Personally Identifiable Information (PII) General Data Protection Regulation (GDPR)","title":"References"},{"location":"Explanation/ADR/adr-007-revocation-lists/","text":"ADR 007: Revocation Lists Changelog 2022-07-04: Initial draft Status DRAFT Abstract Credentials are part of our daily interactions; driver's licenses are used to assert that we are capable of operating a motor vehicle, university degrees can be used to assert our level of education, and concert tickets are used to assert that we can attend an event. It is helpful for a credential issuer of a verifiable credential (VC) to provide a location where a verifier can check to see if a credential has been revoked. This document specifies support for a native implementation of revocation lists that are based on the W3C Credentials Community Group Revocation List 2020 report. This report details a strong privacy-preserving, space-efficient, and high-performance mechanism for publishing the revocation status of VCs. Context The self-sovereign identity (SSI) approach to tackling the identity and privacy challenge has gained momentum in recent years. Coupled with distributed ledger technology (DLT) technology, the SSI approach has captured the attention of the private and public sectors. The SSI approach relies on two building blocks: decentralized identifiers (DID) and VCs. This architecture decision record (ADR) describes a method to leverage public VCs in Cosmos SDK-based blockchains to provide support for revocation lists. Decision By leveraging public verifiable credentials (PVCs) and a credential definition schema, the Elesto node will offer native support for revocation lists. Privacy and performance must be considered when designing, publishing, and processing revocation lists. This ADR introduces a credential definition for use by a credential issuer to publish one or more revocation lists. Each revocation list is encoded in a public verifiable credential (PVC) . The revocation list model is an implementation of the W3C Credentials Community Group Revocation List 2020 privacy-preserving, space-efficient, and high-performance mechanism for publishing the revocation status of VCs. In this model, the credential issuer assigns an arbitrary positive number to each credential that it issues: the number is the index in the revocation list encoded in the public verifiable credential . The credential schema, included in the revocation list credential definition, is defined by this JSON-formatted schema: { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"https://elesto.id/revocation-list2020/1.0/json-schema.json\" , \"$metadata\" : { \"slug\" : \"revocation-list2020\" , \"version\" : \"1.0\" }, \"title\" : \"RevocationList2020\" , \"description\" : \"RevocationList2020 - A privacy-preserving mechanism for revoking Verifiable Credentials\" , \"type\" : \"object\" , \"required\" : [ \"@context\" , \"type\" , \"issuer\" , \"issuanceDate\" , \"credentialSubject\" ], \"properties\" : { \"@context\" : { \"type\" : [ \"string\" , \"array\" , \"object\" ] }, \"id\" : { \"type\" : \"string\" , \"format\" : \"uri\" }, \"type\" : { \"type\" : [ \"string\" , \"array\" ], \"items\" : { \"type\" : \"string\" } }, \"issuer\" : { \"type\" : [ \"string\" , \"object\" ], \"format\" : \"uri\" , \"required\" : [ \"id\" ], \"properties\" : { \"id\" : { \"type\" : \"string\" , \"format\" : \"uri\" } } }, \"issuanceDate\" : { \"type\" : \"string\" , \"format\" : \"date-time\" }, \"expirationDate\" : { \"type\" : \"string\" , \"format\" : \"date-time\" }, \"credentialSubject\" : { \"type\" : \"object\" , \"required\" : [ \"id\" , \"type\" , \"encodedList\" ], \"properties\" : { \"id\" : { \"title\" : \"ID\" , \"description\" : \"The revocation list ID\" , \"type\" : \"string\" , \"format\" : \"uri\" }, \"type\" : { \"title\" : \"Type\" , \"description\" : \"value must be: RevocationList2020 \" , \"type\" : \"string\" }, \"encodedList\" : { \"title\" : \"encodedList\" , \"description\" : \"base64 endcoded string of the zlib compressed bitstring\" , \"type\" : \"string\" } } }, \"credentialSchema\" : { \"type\" : \"object\" , \"required\" : [ \"id\" , \"type\" ], \"properties\" : { \"id\" : { \"type\" : \"string\" , \"format\" : \"uri\" }, \"type\" : { \"type\" : \"string\" } } } } } Example For example, a revocation list based on the credential definition schema looks like: { \"@context\" : [ \"https://www.w3.org/2018/credentials/v1\" , \"https://w3id.org/vc-revocation-list-2020/v1\" ], \"id\" : \"https://regulator/credentials/status/001\" , \"type\" : [ \"VerifiableCredential\" , \"RevocationList2020Credential\" ], \"issuer\" : \"did:cosmos:elesto:example-credential-issuer\" , \"issuanceDate\" : \"2020-04-05T14:27:40Z\" , \"credentialSubject\" : { \"id\" : \"https://regulator/credentials/status/001#list\" , \"type\" : \"RevocationList2020\" , \"encodedList\" : \"H4sIAAAAAAAAA-3BMQEAAADCoPVPbQsvoAAAAAAAAAAAAAAAAP4GcwM92tQwAAA\" } } As shown in the following diagram: Privacy Considerations Refer to the privacy considerations of the W3C Revocation List 2020 report. Security Considerations Refer to the security considerations of the W3C Revocation List 2020 report. Consequences By leveraging the public verifiable credentials, the Elesto node offers native support for revocation lists. Revocation lists are stored as credentials in the node state, within the credential module keeper. Backward Compatibility There are no concerns related to backward compatibility. Positive The revocation list support and implementation improves the compatibility of the Elesto node with the SSI identity model. Negative N/A Neutral The credential issuer will be responsible for creating, maintaining, and tracking an index of the credentials that it issues; it is the credential issuer's responsibility to know what the next unassigned credential index associated with a revocation list is. Further Discussions While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. Test Cases [optional] N/A References W3C Revocation List 2020 report W3C Recommendation Verifiable Credentials Data Model v1.1","title":"ADR 007: Revocation Lists"},{"location":"Explanation/ADR/adr-007-revocation-lists/#adr-007-revocation-lists","text":"","title":"ADR 007: Revocation Lists"},{"location":"Explanation/ADR/adr-007-revocation-lists/#changelog","text":"2022-07-04: Initial draft","title":"Changelog"},{"location":"Explanation/ADR/adr-007-revocation-lists/#status","text":"DRAFT","title":"Status"},{"location":"Explanation/ADR/adr-007-revocation-lists/#abstract","text":"Credentials are part of our daily interactions; driver's licenses are used to assert that we are capable of operating a motor vehicle, university degrees can be used to assert our level of education, and concert tickets are used to assert that we can attend an event. It is helpful for a credential issuer of a verifiable credential (VC) to provide a location where a verifier can check to see if a credential has been revoked. This document specifies support for a native implementation of revocation lists that are based on the W3C Credentials Community Group Revocation List 2020 report. This report details a strong privacy-preserving, space-efficient, and high-performance mechanism for publishing the revocation status of VCs.","title":"Abstract"},{"location":"Explanation/ADR/adr-007-revocation-lists/#context","text":"The self-sovereign identity (SSI) approach to tackling the identity and privacy challenge has gained momentum in recent years. Coupled with distributed ledger technology (DLT) technology, the SSI approach has captured the attention of the private and public sectors. The SSI approach relies on two building blocks: decentralized identifiers (DID) and VCs. This architecture decision record (ADR) describes a method to leverage public VCs in Cosmos SDK-based blockchains to provide support for revocation lists.","title":"Context"},{"location":"Explanation/ADR/adr-007-revocation-lists/#decision","text":"By leveraging public verifiable credentials (PVCs) and a credential definition schema, the Elesto node will offer native support for revocation lists. Privacy and performance must be considered when designing, publishing, and processing revocation lists. This ADR introduces a credential definition for use by a credential issuer to publish one or more revocation lists. Each revocation list is encoded in a public verifiable credential (PVC) . The revocation list model is an implementation of the W3C Credentials Community Group Revocation List 2020 privacy-preserving, space-efficient, and high-performance mechanism for publishing the revocation status of VCs. In this model, the credential issuer assigns an arbitrary positive number to each credential that it issues: the number is the index in the revocation list encoded in the public verifiable credential . The credential schema, included in the revocation list credential definition, is defined by this JSON-formatted schema: { \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"https://elesto.id/revocation-list2020/1.0/json-schema.json\" , \"$metadata\" : { \"slug\" : \"revocation-list2020\" , \"version\" : \"1.0\" }, \"title\" : \"RevocationList2020\" , \"description\" : \"RevocationList2020 - A privacy-preserving mechanism for revoking Verifiable Credentials\" , \"type\" : \"object\" , \"required\" : [ \"@context\" , \"type\" , \"issuer\" , \"issuanceDate\" , \"credentialSubject\" ], \"properties\" : { \"@context\" : { \"type\" : [ \"string\" , \"array\" , \"object\" ] }, \"id\" : { \"type\" : \"string\" , \"format\" : \"uri\" }, \"type\" : { \"type\" : [ \"string\" , \"array\" ], \"items\" : { \"type\" : \"string\" } }, \"issuer\" : { \"type\" : [ \"string\" , \"object\" ], \"format\" : \"uri\" , \"required\" : [ \"id\" ], \"properties\" : { \"id\" : { \"type\" : \"string\" , \"format\" : \"uri\" } } }, \"issuanceDate\" : { \"type\" : \"string\" , \"format\" : \"date-time\" }, \"expirationDate\" : { \"type\" : \"string\" , \"format\" : \"date-time\" }, \"credentialSubject\" : { \"type\" : \"object\" , \"required\" : [ \"id\" , \"type\" , \"encodedList\" ], \"properties\" : { \"id\" : { \"title\" : \"ID\" , \"description\" : \"The revocation list ID\" , \"type\" : \"string\" , \"format\" : \"uri\" }, \"type\" : { \"title\" : \"Type\" , \"description\" : \"value must be: RevocationList2020 \" , \"type\" : \"string\" }, \"encodedList\" : { \"title\" : \"encodedList\" , \"description\" : \"base64 endcoded string of the zlib compressed bitstring\" , \"type\" : \"string\" } } }, \"credentialSchema\" : { \"type\" : \"object\" , \"required\" : [ \"id\" , \"type\" ], \"properties\" : { \"id\" : { \"type\" : \"string\" , \"format\" : \"uri\" }, \"type\" : { \"type\" : \"string\" } } } } }","title":"Decision"},{"location":"Explanation/ADR/adr-007-revocation-lists/#example","text":"For example, a revocation list based on the credential definition schema looks like: { \"@context\" : [ \"https://www.w3.org/2018/credentials/v1\" , \"https://w3id.org/vc-revocation-list-2020/v1\" ], \"id\" : \"https://regulator/credentials/status/001\" , \"type\" : [ \"VerifiableCredential\" , \"RevocationList2020Credential\" ], \"issuer\" : \"did:cosmos:elesto:example-credential-issuer\" , \"issuanceDate\" : \"2020-04-05T14:27:40Z\" , \"credentialSubject\" : { \"id\" : \"https://regulator/credentials/status/001#list\" , \"type\" : \"RevocationList2020\" , \"encodedList\" : \"H4sIAAAAAAAAA-3BMQEAAADCoPVPbQsvoAAAAAAAAAAAAAAAAP4GcwM92tQwAAA\" } } As shown in the following diagram:","title":"Example"},{"location":"Explanation/ADR/adr-007-revocation-lists/#privacy-considerations","text":"Refer to the privacy considerations of the W3C Revocation List 2020 report.","title":"Privacy Considerations"},{"location":"Explanation/ADR/adr-007-revocation-lists/#security-considerations","text":"Refer to the security considerations of the W3C Revocation List 2020 report.","title":"Security Considerations"},{"location":"Explanation/ADR/adr-007-revocation-lists/#consequences","text":"By leveraging the public verifiable credentials, the Elesto node offers native support for revocation lists. Revocation lists are stored as credentials in the node state, within the credential module keeper.","title":"Consequences"},{"location":"Explanation/ADR/adr-007-revocation-lists/#backward-compatibility","text":"There are no concerns related to backward compatibility.","title":"Backward Compatibility"},{"location":"Explanation/ADR/adr-007-revocation-lists/#positive","text":"The revocation list support and implementation improves the compatibility of the Elesto node with the SSI identity model.","title":"Positive"},{"location":"Explanation/ADR/adr-007-revocation-lists/#negative","text":"N/A","title":"Negative"},{"location":"Explanation/ADR/adr-007-revocation-lists/#neutral","text":"The credential issuer will be responsible for creating, maintaining, and tracking an index of the credentials that it issues; it is the credential issuer's responsibility to know what the next unassigned credential index associated with a revocation list is.","title":"Neutral"},{"location":"Explanation/ADR/adr-007-revocation-lists/#further-discussions","text":"While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR.","title":"Further Discussions"},{"location":"Explanation/ADR/adr-007-revocation-lists/#test-cases-optional","text":"N/A","title":"Test Cases [optional]"},{"location":"Explanation/ADR/adr-007-revocation-lists/#references","text":"W3C Revocation List 2020 report W3C Recommendation Verifiable Credentials Data Model v1.1","title":"References"},{"location":"Explanation/ADR/adr-008-inflation/","text":"ADR 008: Inflation Changelog 2022-08-20: Initial draft 2022-08-30: Draft 2 (inflation rewards allocation, minor grammar edits) 2022-09-06: Draft 3 - replace years with epochs Status DRAFT Abstract Inflation is the process by which a currency like the dollar or euro loses value over time, causing the price of goods to rise. Elesto, like other cryptocurrencies, is designed to experience predictable and low rates of inflation. This document details the inflation model for the Elesto chain. Context - Decision Elesto inflation is inspired by Bitcoin inflation model. The Bitcoin supply is limited and known, and the creation of new bitcoin will taper off over time in a predictable way. (There will only ever be 21 million bitcoin, and every four years the amount of bitcoin that is mined is reduced by half.) The Elesto initial supply is to be 200,000,000 (two hundred million) tokens and will reach its maximum value at 1,000,000,000 (one billion) in a period of 10 epochs (roughly 10 years). The rewards per block are further split into three categories: 10% to the community pool, 10% to the development team, and 80% to the staking rewards. We introduce the concept of epoch: an epoch is 6,307,200 blocks. The number of blocks of an eopch is calculated as the number of blocks in a calendar year assuming a block rate of 1 block every 5 seconds. Note The actual token configuration uses the u (micro) unit to express decimal, therefore the actual value for supply must be multplied for 10^6 Epoch n. [1] Current epoch inflation [2] Epoch inflation supply amount [3] Total supply estimate (EOY) [4] Block inflation amount [5] Total supply actual amount (EOY) [6] 1 1 200,000,000 ,000,000 400,000,000 ,000,000 31 ,709,792 400,000,000 ,102,400 2 0.5 200,000,000 ,000,000 600,000,000 ,000,000 31 ,709,792 600,000,000 ,102,400 3 0.25 150,000,000 ,000,000 750,000,000 ,000,000 23 ,782,344 750,000,000 ,076,800 4 0.125 93,750,000 ,000,000 843,750,000 ,000,000 14 ,863,965 843,750,000 ,048,000 5 0.0625 52,734,375 ,000,000 896,484,375 ,000,000 8 ,360,980 896,484,373 ,056,000 6 0.03125 28,015,136 ,718,750 924,499,511 ,718,750 4 ,441,771 924,499,513 ,051,200 7 0.0200 18,489,990 ,234,375 942,989,501 ,953,125 2 ,931,569 942,989,503 ,715,550 8 0.0200 18,859,790 ,039,063 961,849,291 ,992,188 2 ,990,200 961,849,291 ,393,125 9 0.0200 19,236,985 ,839,844 981,086,277 ,832,031 3 ,050,004 981,086,277 ,220,988 10 0.019278348 18,913,722 ,682,071 1,000,000,000 ,514,100 2 ,998,751 1,000,000,000 ,139,230 where the columns are: 1. Epoch n. The epoch from the chain starts, 1 is during the first epoch, 2 the second epoch, and so on. 2. Current epoch inflation % The current epoch inflation is a percentage over the current supply that should be minted for the next epoch. The percentage is between 0-1. The last epoch percentage (0.019278348) is an adjustment over 0.2 to reach the desired value of 1 billion. 3. Epoch inflation supply amount The epoch supply inflation is the theoretical amount that will be minted by the end of the current epoch. It is calculated with the formula: Epoch supply inflation amount = FLOOR(Current epoch inflation [2] * Total supply at beginning of the epoch) For the first epoch, the total supply at beginning of the epoch is the initial supply of two hundred million (200,000,000). 4. Total supply estimate (EOY) The total supply estimate is the total supply at the end of the current epoch. It is the cumulated sum of each epoch supply. 5. Block inflation amount The block inflation is the amount to be minted on each block to reach the expected Epoch inflation supply . It is calcualted with the formula: Block inflation amount = ROUND(Epoch inflation supply amount [3] / Blocks per epoch) 6. Total supply actual amount (EOY) Due to rounding errors, the \"Total supply estimate (EOY) [4]\" is slightly different from the \"Total supply actual amount (EOY) [6].\" This column is the actual supply that will be obeserved on chain and is calcualted using the formula: Total supply actual amount = Block inflation amount [5] * Blocks per epoch The value for block inflation per epoch is hard coded in the node code in the mint module ABCI . Visualizing the inflation curve To visualize the distribution paste the following data to Vega { \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"description\": \"Supply change over time.\", \"data\": {\"values\": [ {\"epoch\": \"1\", \"block\": 6307200, \"supply\": 200000000}, {\"epoch\": \"2\", \"block\": 12614400, \"supply\": 600000000}, {\"epoch\": \"3\", \"block\": 18921600, \"supply\": 750000000}, {\"epoch\": \"4\", \"block\": 25228800, \"supply\": 843750000}, {\"epoch\": \"5\", \"block\": 31536000, \"supply\": 896484373}, {\"epoch\": \"6\", \"block\": 37843200, \"supply\": 924499513}, {\"epoch\": \"7\", \"block\": 44150400, \"supply\": 942989503}, {\"epoch\": \"8\", \"block\": 50457600, \"supply\": 961849291}, {\"epoch\": \"9\", \"block\": 56764800, \"supply\": 981086277}, {\"epoch\": \"10\", \"block\": 63072000, \"supply\": 1000000000}, {\"epoch\": \"11\", \"block\": 63072000, \"supply\": 1000000000} ] }, \"width\": 800, \"height\": 600, \"mark\": { \"type\": \"line\" }, \"encoding\": { \"z\": {\"field\": \"block\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"supply\", \"type\": \"quantitative\"} } } Privacy Considerations N/A Security Considerations N/A Consequences By leveraging the public verifiable credentials, the Elesto node offers native support for revocation lists. Revocation lists are stored as credentials in the node state, within the credential module keeper. Backward Compatibility N/A Positive N/A Negative N/A Neutral N/A Further Discussions While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. Test Cases [optional] N/A References <<<<<<< HEAD Bitcoin Whitepaper ======= Bitcoin Whitepaper 66c85d2 (docs: amend ADR #8, introduce epoch concept)","title":"ADR 008: Inflation"},{"location":"Explanation/ADR/adr-008-inflation/#adr-008-inflation","text":"","title":"ADR 008: Inflation"},{"location":"Explanation/ADR/adr-008-inflation/#changelog","text":"2022-08-20: Initial draft 2022-08-30: Draft 2 (inflation rewards allocation, minor grammar edits) 2022-09-06: Draft 3 - replace years with epochs","title":"Changelog"},{"location":"Explanation/ADR/adr-008-inflation/#status","text":"DRAFT","title":"Status"},{"location":"Explanation/ADR/adr-008-inflation/#abstract","text":"Inflation is the process by which a currency like the dollar or euro loses value over time, causing the price of goods to rise. Elesto, like other cryptocurrencies, is designed to experience predictable and low rates of inflation. This document details the inflation model for the Elesto chain.","title":"Abstract"},{"location":"Explanation/ADR/adr-008-inflation/#context","text":"-","title":"Context"},{"location":"Explanation/ADR/adr-008-inflation/#decision","text":"Elesto inflation is inspired by Bitcoin inflation model. The Bitcoin supply is limited and known, and the creation of new bitcoin will taper off over time in a predictable way. (There will only ever be 21 million bitcoin, and every four years the amount of bitcoin that is mined is reduced by half.) The Elesto initial supply is to be 200,000,000 (two hundred million) tokens and will reach its maximum value at 1,000,000,000 (one billion) in a period of 10 epochs (roughly 10 years). The rewards per block are further split into three categories: 10% to the community pool, 10% to the development team, and 80% to the staking rewards. We introduce the concept of epoch: an epoch is 6,307,200 blocks. The number of blocks of an eopch is calculated as the number of blocks in a calendar year assuming a block rate of 1 block every 5 seconds. Note The actual token configuration uses the u (micro) unit to express decimal, therefore the actual value for supply must be multplied for 10^6 Epoch n. [1] Current epoch inflation [2] Epoch inflation supply amount [3] Total supply estimate (EOY) [4] Block inflation amount [5] Total supply actual amount (EOY) [6] 1 1 200,000,000 ,000,000 400,000,000 ,000,000 31 ,709,792 400,000,000 ,102,400 2 0.5 200,000,000 ,000,000 600,000,000 ,000,000 31 ,709,792 600,000,000 ,102,400 3 0.25 150,000,000 ,000,000 750,000,000 ,000,000 23 ,782,344 750,000,000 ,076,800 4 0.125 93,750,000 ,000,000 843,750,000 ,000,000 14 ,863,965 843,750,000 ,048,000 5 0.0625 52,734,375 ,000,000 896,484,375 ,000,000 8 ,360,980 896,484,373 ,056,000 6 0.03125 28,015,136 ,718,750 924,499,511 ,718,750 4 ,441,771 924,499,513 ,051,200 7 0.0200 18,489,990 ,234,375 942,989,501 ,953,125 2 ,931,569 942,989,503 ,715,550 8 0.0200 18,859,790 ,039,063 961,849,291 ,992,188 2 ,990,200 961,849,291 ,393,125 9 0.0200 19,236,985 ,839,844 981,086,277 ,832,031 3 ,050,004 981,086,277 ,220,988 10 0.019278348 18,913,722 ,682,071 1,000,000,000 ,514,100 2 ,998,751 1,000,000,000 ,139,230 where the columns are:","title":"Decision"},{"location":"Explanation/ADR/adr-008-inflation/#1-epoch-n","text":"The epoch from the chain starts, 1 is during the first epoch, 2 the second epoch, and so on.","title":"1. Epoch n."},{"location":"Explanation/ADR/adr-008-inflation/#2-current-epoch-inflation","text":"The current epoch inflation is a percentage over the current supply that should be minted for the next epoch. The percentage is between 0-1. The last epoch percentage (0.019278348) is an adjustment over 0.2 to reach the desired value of 1 billion.","title":"2. Current epoch inflation %"},{"location":"Explanation/ADR/adr-008-inflation/#3-epoch-inflation-supply-amount","text":"The epoch supply inflation is the theoretical amount that will be minted by the end of the current epoch. It is calculated with the formula: Epoch supply inflation amount = FLOOR(Current epoch inflation [2] * Total supply at beginning of the epoch) For the first epoch, the total supply at beginning of the epoch is the initial supply of two hundred million (200,000,000).","title":"3. Epoch inflation supply amount"},{"location":"Explanation/ADR/adr-008-inflation/#4-total-supply-estimate-eoy","text":"The total supply estimate is the total supply at the end of the current epoch. It is the cumulated sum of each epoch supply.","title":"4. Total supply estimate (EOY)"},{"location":"Explanation/ADR/adr-008-inflation/#5-block-inflation-amount","text":"The block inflation is the amount to be minted on each block to reach the expected Epoch inflation supply . It is calcualted with the formula: Block inflation amount = ROUND(Epoch inflation supply amount [3] / Blocks per epoch)","title":"5. Block inflation amount"},{"location":"Explanation/ADR/adr-008-inflation/#6-total-supply-actual-amount-eoy","text":"Due to rounding errors, the \"Total supply estimate (EOY) [4]\" is slightly different from the \"Total supply actual amount (EOY) [6].\" This column is the actual supply that will be obeserved on chain and is calcualted using the formula: Total supply actual amount = Block inflation amount [5] * Blocks per epoch The value for block inflation per epoch is hard coded in the node code in the mint module ABCI . Visualizing the inflation curve To visualize the distribution paste the following data to Vega { \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"description\": \"Supply change over time.\", \"data\": {\"values\": [ {\"epoch\": \"1\", \"block\": 6307200, \"supply\": 200000000}, {\"epoch\": \"2\", \"block\": 12614400, \"supply\": 600000000}, {\"epoch\": \"3\", \"block\": 18921600, \"supply\": 750000000}, {\"epoch\": \"4\", \"block\": 25228800, \"supply\": 843750000}, {\"epoch\": \"5\", \"block\": 31536000, \"supply\": 896484373}, {\"epoch\": \"6\", \"block\": 37843200, \"supply\": 924499513}, {\"epoch\": \"7\", \"block\": 44150400, \"supply\": 942989503}, {\"epoch\": \"8\", \"block\": 50457600, \"supply\": 961849291}, {\"epoch\": \"9\", \"block\": 56764800, \"supply\": 981086277}, {\"epoch\": \"10\", \"block\": 63072000, \"supply\": 1000000000}, {\"epoch\": \"11\", \"block\": 63072000, \"supply\": 1000000000} ] }, \"width\": 800, \"height\": 600, \"mark\": { \"type\": \"line\" }, \"encoding\": { \"z\": {\"field\": \"block\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"supply\", \"type\": \"quantitative\"} } }","title":"6. Total supply actual amount (EOY)"},{"location":"Explanation/ADR/adr-008-inflation/#privacy-considerations","text":"N/A","title":"Privacy Considerations"},{"location":"Explanation/ADR/adr-008-inflation/#security-considerations","text":"N/A","title":"Security Considerations"},{"location":"Explanation/ADR/adr-008-inflation/#consequences","text":"By leveraging the public verifiable credentials, the Elesto node offers native support for revocation lists. Revocation lists are stored as credentials in the node state, within the credential module keeper.","title":"Consequences"},{"location":"Explanation/ADR/adr-008-inflation/#backward-compatibility","text":"N/A","title":"Backward Compatibility"},{"location":"Explanation/ADR/adr-008-inflation/#positive","text":"N/A","title":"Positive"},{"location":"Explanation/ADR/adr-008-inflation/#negative","text":"N/A","title":"Negative"},{"location":"Explanation/ADR/adr-008-inflation/#neutral","text":"N/A","title":"Neutral"},{"location":"Explanation/ADR/adr-008-inflation/#further-discussions","text":"While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR.","title":"Further Discussions"},{"location":"Explanation/ADR/adr-008-inflation/#test-cases-optional","text":"N/A","title":"Test Cases [optional]"},{"location":"Explanation/ADR/adr-008-inflation/#references","text":"<<<<<<< HEAD Bitcoin Whitepaper ======= Bitcoin Whitepaper 66c85d2 (docs: amend ADR #8, introduce epoch concept)","title":"References"},{"location":"Explanation/ADR/adr-template/","text":"ADR {ADR-NUMBER}: {TITLE} Changelog {date}: {changelog} Status {DRAFT | PROPOSED} Not Implemented For details on ADR workflow, see the PROCESS page. Use DRAFT if the ADR is in a draft stage (draft PR) or PROPOSED if it's in review. Abstract \"If you can not explain it simply, you do not understand it well enough.\" Provide a simplified and layman-accessible explanation of the ADR. A short (~200 word) description of the issue being addressed. Context This section describes the forces at play, including technological, political, social, and project local. These forces are probably in tension describe them as such. The language in this section is value-neutral and just describes facts. The context should clearly explain the problem and motivation that the proposal aims to resolve. {context body} Decision This section describes our response to these forces. It is stated in complete sentences, with an active voice. \"We will ...\" {decision body} Consequences This section describes the resulting context after applying the decision. List all consequences here, taking care not to list only the \"positive\" consequences. A particular decision may have positive, negative, and neutral consequences, but all of the consequences affect the team and project in the future. Backwards Compatibility All ADRs that introduce backward incompatibilities must include a section describing these incompatibilities and their severity. The ADR must explain how the author proposes to deal with these incompatibilities. ADR submissions without a sufficient backward compatibility treatise may be rejected outright. Positive {positive consequences} Negative {negative consequences} Neutral {neutral consequences} Further Discussions While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR. Test Cases [optional] Test cases for implementation are mandatory for ADRs that are affecting consensus changes. Other ADRs can choose to include links to test cases if applicable. References {reference link}","title":"ADR Template"},{"location":"Explanation/ADR/adr-template/#adr-adr-number-title","text":"","title":"ADR {ADR-NUMBER}: {TITLE}"},{"location":"Explanation/ADR/adr-template/#changelog","text":"{date}: {changelog}","title":"Changelog"},{"location":"Explanation/ADR/adr-template/#status","text":"{DRAFT | PROPOSED} Not Implemented For details on ADR workflow, see the PROCESS page. Use DRAFT if the ADR is in a draft stage (draft PR) or PROPOSED if it's in review.","title":"Status"},{"location":"Explanation/ADR/adr-template/#abstract","text":"\"If you can not explain it simply, you do not understand it well enough.\" Provide a simplified and layman-accessible explanation of the ADR. A short (~200 word) description of the issue being addressed.","title":"Abstract"},{"location":"Explanation/ADR/adr-template/#context","text":"This section describes the forces at play, including technological, political, social, and project local. These forces are probably in tension describe them as such. The language in this section is value-neutral and just describes facts. The context should clearly explain the problem and motivation that the proposal aims to resolve. {context body}","title":"Context"},{"location":"Explanation/ADR/adr-template/#decision","text":"This section describes our response to these forces. It is stated in complete sentences, with an active voice. \"We will ...\" {decision body}","title":"Decision"},{"location":"Explanation/ADR/adr-template/#consequences","text":"This section describes the resulting context after applying the decision. List all consequences here, taking care not to list only the \"positive\" consequences. A particular decision may have positive, negative, and neutral consequences, but all of the consequences affect the team and project in the future.","title":"Consequences"},{"location":"Explanation/ADR/adr-template/#backwards-compatibility","text":"All ADRs that introduce backward incompatibilities must include a section describing these incompatibilities and their severity. The ADR must explain how the author proposes to deal with these incompatibilities. ADR submissions without a sufficient backward compatibility treatise may be rejected outright.","title":"Backwards Compatibility"},{"location":"Explanation/ADR/adr-template/#positive","text":"{positive consequences}","title":"Positive"},{"location":"Explanation/ADR/adr-template/#negative","text":"{negative consequences}","title":"Negative"},{"location":"Explanation/ADR/adr-template/#neutral","text":"{neutral consequences}","title":"Neutral"},{"location":"Explanation/ADR/adr-template/#further-discussions","text":"While an ADR is in the DRAFT or PROPOSED stage, this section summarizes issues to be solved in future iterations. The issues summarized here can reference comments from a pull request discussion. Later, this section can optionally list ideas or improvements the author or reviewers found during the analysis of this ADR.","title":"Further Discussions"},{"location":"Explanation/ADR/adr-template/#test-cases-optional","text":"Test cases for implementation are mandatory for ADRs that are affecting consensus changes. Other ADRs can choose to include links to test cases if applicable.","title":"Test Cases [optional]"},{"location":"Explanation/ADR/adr-template/#references","text":"{reference link}","title":"References"},{"location":"Explanation/articles/","text":"Articles README This folder includes all articles, papers, and so on that have been created for Elesto. Each folder represents all of the materials and assets for a single article, including bibliographies, images, and so on. The papers themselves are written in Markdown. The Markdown files can then be published in various formats using Pandoc . For publishing to PDF format, we use this Eisvogel LaTeX template to ensure a consistent look and feel. Technical Setup Set up your environment to manage and publish articles. Prerequisites GNU make utility Pandoc Google Inter font is the Tendermint font. Usage Create a folder with a self-explanatory name for the article Add your content to the folder as needed. Add the following front matter to the top of the Markdown document and customize as needed: --- title: \"My title\" subtitle: \"My sub title\" author: [Joe Smith] date: \"Publish date\" mainfont: Inter # Default Tendermint font fontsize: 10pt subject: \"Elesto\" keywords: [] lang: \"en\" book: true titlepage: true titlepage-background: \"\" classoption: [oneside] page-background: \"../backgrounds/BackgroundTendermint.pdf\" footer-left: \"footer\" header-left: \"header\" footer-right: \"footer\" header-right: \"header\" --- To create a new report, run the make buildmd from the top-level directory NOTE: This build process is under development and won't work for the moment!! To clean outputs, run make clean .","title":"About Articles"},{"location":"Explanation/articles/#articles-readme","text":"This folder includes all articles, papers, and so on that have been created for Elesto. Each folder represents all of the materials and assets for a single article, including bibliographies, images, and so on. The papers themselves are written in Markdown. The Markdown files can then be published in various formats using Pandoc . For publishing to PDF format, we use this Eisvogel LaTeX template to ensure a consistent look and feel.","title":"Articles README"},{"location":"Explanation/articles/#technical-setup","text":"Set up your environment to manage and publish articles.","title":"Technical Setup"},{"location":"Explanation/articles/#prerequisites","text":"GNU make utility Pandoc Google Inter font is the Tendermint font.","title":"Prerequisites"},{"location":"Explanation/articles/#usage","text":"Create a folder with a self-explanatory name for the article Add your content to the folder as needed. Add the following front matter to the top of the Markdown document and customize as needed: --- title: \"My title\" subtitle: \"My sub title\" author: [Joe Smith] date: \"Publish date\" mainfont: Inter # Default Tendermint font fontsize: 10pt subject: \"Elesto\" keywords: [] lang: \"en\" book: true titlepage: true titlepage-background: \"\" classoption: [oneside] page-background: \"../backgrounds/BackgroundTendermint.pdf\" footer-left: \"footer\" header-left: \"header\" footer-right: \"footer\" header-right: \"header\" --- To create a new report, run the make buildmd from the top-level directory NOTE: This build process is under development and won't work for the moment!! To clean outputs, run make clean .","title":"Usage"},{"location":"Explanation/articles/regulation-paper/rpts/CosmosCashRegs/","text":"Macro Syntax Error Line 197 in Markdown file: Missing end of comment tag ### Crypto-Assets exempt from MiCA {#sec:exemptions}","title":"Elesto"},{"location":"Explanation/articles/regulation-paper/rpts/CosmosCashRegs/#macro-syntax-error","text":"Line 197 in Markdown file: Missing end of comment tag ### Crypto-Assets exempt from MiCA {#sec:exemptions}","title":"Macro Syntax Error"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/","text":"USDC vs USDT vs Cosmos Cash Issuer USDC vs USDT vs Cosmos Cash Issuer Summary Methodology TL;DR; USDT ERC20 Smart Contracts Source Analysis Roles Functions USDC ERC-20 smart contracts Source Analysis Roles Functions Cosmos Cash Issuer Module Source Functions Gap Analysis Summary USDC and USDT are Ethereum, ERC-20 smart contract-based stablecoins pegged one-to-one to the US Dollar (USD). However, each USD-backed stablecoin has different implementations. This article will Perform a high-level functional gap analysis of each smart contract Compared to the current Cosmos Cash proof-of-concept implementation Conclude best practices that will inform the Issuer ADR for Cosmos Cash. Why USDT and USDC? These are currently the leading stablecoin tokens with a total market capitalisation of over 90Bn USD (source: coinmarketcap.com) Methodology Each function is labeled based on the following criteria: BESPOKE: custom functionality ERC20 : part of the ERC20 standard PAUSABLE : part of the solidity pausable contract standard OWNABLE : part of the solidity ownable contract standard PROXY : these functions are part of Solidity\u2019s delegate proxy upgradability pattern MINTABLE : part of the solidity mintable contract standard BURNABLE : part of the solidity burnable contract standard RBAC : part of the solidity roles contract standard TL;DR; Label USDT USDC Cosmos Cash Issuer Mintable issue(amount) mint(_to, _amount) mintToken(amount, owner) Burnable redeem(amount) burn(_amount) burnToken(amount, owner) Pausable pause pause TO DO Pausable unpause unpause TO DO blacklist addBlacklist blacklist(_account) TO DO blacklist removeBlacklist(_clearedUser) unBlacklist(_account) TO DO blacklist destroyBlackFunds(_blackListedUser) n/a TO DO blacklist n/a rescueERC20(tokenContract, to, amount) TO DO ERC20 transfer(_from, _value) transfer(_from, _value) ERC20 transferFrom(_from, _to, _value) transferFrom(_from, _to, _value) ERC20 approve(_spender, _value) approve(_spender, _value) Ownable transferOwnership(newOwner) transferOwnership(newOwner) Bespoke setParams(newBasisPoints, newMaxFee) n/a Bespoke n/a transferWithAuthorization(from, to, value, validAfter, validBefore, nonce, v, r, s) Bespoke n/a configureMinter(minter, minterAllowedAmount) Bespoke n/a receiveWithAuthorization(from, to, value, validAfter, validBefore, nonce, v, r, s) Bespoke n/a cancelAuthorization(authorizer, nonce, v, r, s) RBAC increaseAllowance(spender, increment) RBAC decreaseAllowance(spender, decrement) RBAC n/a removeMinter(minter) RBAC n/a updateBlacklister(_newBlacklister) RBAC n/a updateMasterMinter(_newMasterMinter) RBAC n/a updatePauser(_newPauser) RBAC n/a updateRescuer(newRescuer) Proxy n/a initialize(tokenName, tokenSymbol, tokenCurrency, tokenDecimals, newMasterMinter, newPauser, newBlacklister, newOwner) createIssuer(token, fee, owner) Proxy n/a initializeV2(string) Proxy n/a initializeV2_1(newName) Proxy deprecate(_upgradedAddress) n/a USDT ERC20 Smart Contracts Source This analysis used this definition of the USDT ERC-20 smart contract . This is found at 0xdac17f958d2ee523a2206206994597c13d831ec7 Analysis The USDT smart contracts have five main areas of note: Tokens freezing PAUASABLE Tokens minting, burning MINTABLE, BURNABLE Role-Based Access Control User denylisting Upgrading function (albeit limited) Roles This contract has admin privileges for TWO roles, each comprising of one address: OWNER - owner owns the contract and can call admin functions BLACKLISTER - can add and remove users from a blacklist Functions issue(amount) - BESPOKE/MINTABLE: mints a certain amount of tokens. redeem(amount) - BESPOKE/BURNABLE: redeems or burns an amount tokens. pause - PAUSABLE: pauses the token transfers. This function can only be called by the contract owner, the issuer of USDT tokens. unpause - PAUSABLE: unpauses token transfers only callable by the token. addBlacklist(_evilUser) - BESPOKE: this function freezes a user's assets by adding an address to a denylist. removeBlacklist(_clearedUser) - BESPOKE: removes a user from a denylist serves, effectively unfreezing a user account. destroyBlackFunds(_blackListedUser) - BESPOKE: burns tokens of a blacklisted address. transfer(_from, _value) - ERC20: transfer tokens from one user to another. transferFrom(_from, _to, _value) - ERC20: Transfers tokens from one address to another, usually called in conjunction with the approve function. approve(_spender, _value) - ERC20: this function approves an address or contracts to use funds on behalf of another user. transferOwnership(newOwner) - OWNABLE: transfers the owner of the contracts to another address. setParams(newBasisPoints, newMaxFee) - This is BESPOKE: functionality that sets specific params on the contract, probable something to do with earning on each transaction; currently, both are zero. deprecate(_upgradedAddress) - BESPOKE: this function is used as part of an upgradability pattern and sets a previous contract as deprecated. The use of this pattern is specific to the upgrading of Ethereum contracts. The reasons for this e are explained in this Coinbase design blog post USDC ERC-20 smart contracts Source This analysis used this definition of the USDC ERC-20 smart contract . This is found at 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48 Analysis The USDC contract is more complex than USDT, but like USDT, the functions are based upon five function types: Tokens freezing. Tokens minting/burning. RBAC. User denylisting. Upgrades, using a Delegate Proxy pattern. Roles Unlike USDT, USDC has more granular permissions. There are FIVE roles, each comprising one address: OWNER - owner owns the contract and can call admin functions. BLACKLISTER - can add and remove users from a blacklist. MASTERMINTER - can add and remove minters and update minter allowances. RESCUER - can rescue funds from a user, currently a NULL address. PAUSER - can call the pause and unpause functions on the contract. Functions mint(_to, _amount) - MINTABLE: mint tokens to a given user. burn(_amount) - BURNABLE: burns a certain number of tokens. pause - PAUSABLE: pauses the token transfers in the contract, only callable by the owner. unpause - PAUSABLE: unpauses token transfers only callable. blacklist(_account) - BESPOKE: this function freezes a user's assets by adding the address to a denylist. unBlacklist(_account) - BESPOKE: removes a user from a denylist serves as freezing an account. rescueERC20(tokenContract, to, amount) - BESPOKE: function to rescue funds. transfer(_from, _value) - ERC20: transfer tokens from one user to another. transferFrom(_from, _to, _value) - ERC20: Transfers tokens from one address to another, usually called in conjunction with the approve function. approve(_spender, _value) - ERC20: this function approves an address or contract to use funds on behalf of another user. transferOwnership(newOwner) - OWNABLE: transfers the owner of the contracts to another address. transferWithAuthorization(from, to, value, validAfter, validBefore, nonce, v, r, s) - BESPOKE : This allows a user to send tokens with a signature from another user. cancelAuthorization(authoriser, nonce, v, r, s) - BESPOKE: This stops a user from sending tokens with a signature from a user. configureMinter(minter, minterAllowedAmount) - BESPOKE: allows a minter to mint a certain amount of tokens. increaseAllowance(spender, increment) - BESPOKE: This increases the amount a user can spend per transaction for another user. decreaseAllowance(spender, decrement) - BESPOKE: This decreases the amount a user can spend per transaction for another user. recieveWithAuthorization(from, to, value, validAfter, validBefore, nonce, v, r, s) - BESPOKE : This allows a user to send tokens with a signature from a user. removeMinter(minter) - RBAC: removes an address from the minter role callable by MASTERMINTER . updateBlacklister(_newBlacklister) - RBAC: update the admin role BLACKLIST . updateMasterMinter(_newMasterMinter) - RBAC: update the admin role MASTERMINTER . updatePauser(_newPauser) - RBAC: update the admin role PAUSER . updateRescuer(newRescuer) - RBAC: update the admin role RESCUER . initialize(tokenName, tokenSymbol, tokenCurrency, tokenDecimals, newMasterMinter, newPauser, newBlacklister, newOwner) - PROXY: This functionality is used as part of the delegate proxy pattern. It initialises the smart contract and allows delegate proxy functionality. The use of this pattern is specific to the upgrading of Ethereum contracts. The reasons for this e are explained in this Coinbase design blog post . initializeV2(string) - PROXY: This functionality is used as part of the delegate proxy pattern; it initialises the contract and allows delegate proxy functionality. initializeV2_1(newName) - PROXY: This functionality is used as part of the delegate proxy pattern; it initialises the contract and allows delegate proxy functionality. Cosmos Cash Issuer Module Source This analysis is based on the Cosmos Cash proof of concept issuer implementation . Functions createIssuer(token, fee, owner) - This creates an issuer and a token. This initialises the token, and the issuer is the token owner. This is where we could define the token\u2019s PAUSER, BLACKLISTER, MASTERMINTER or other ROLES. mintToken(amount, owner) - mints new tokens to the owner\u2019s address. burnToken(amount, owner) - removes tokens from the owner\u2019s address. Gap Analysis The gap between the issuer module and the USDC and USDT smart contracts is not significant. The following features must be implemented for the Issuer module to be compatible with EVM-based smart contracts. BESPOKE: Blockedlist The blocklist functionality is adding and removing a user from a blocked list addToBlockedList removeFromBlocklist burnBlockedlistTokens PAUSABLE: Freeze/Pause token Freeze token functionality is a kill switch that stops all trading with an issuer token freezeToken/pauseToken unfreezeToken/unpauseToken RBAC: A Role-Based Access Control credential system is required to interact with the contract or module. There are different implementation options available: Defining admin roles in the genesis block. This could be implemented using Decentralized IDentity and public verifiable credentials such that: The verifiable credential can be issued by a regulator actor or DID to an issuer DID. The verifiable credential can allow minting and burning of tokens plus other functions The Issuer DID can have multiple DID controllers who can represent different functions in the issuers, such as Operations and Compliance. ERC20: Some ERC20 token functions are not in the SDK bank module - transferFrom(to, from, amount) - approve(address)","title":"USDC vs USDT vs Cosmos Cash Issuer"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#usdc-vs-usdt-vs-cosmos-cash-issuer","text":"USDC vs USDT vs Cosmos Cash Issuer Summary Methodology TL;DR; USDT ERC20 Smart Contracts Source Analysis Roles Functions USDC ERC-20 smart contracts Source Analysis Roles Functions Cosmos Cash Issuer Module Source Functions Gap Analysis","title":"USDC vs USDT vs Cosmos Cash Issuer"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#summary","text":"USDC and USDT are Ethereum, ERC-20 smart contract-based stablecoins pegged one-to-one to the US Dollar (USD). However, each USD-backed stablecoin has different implementations. This article will Perform a high-level functional gap analysis of each smart contract Compared to the current Cosmos Cash proof-of-concept implementation Conclude best practices that will inform the Issuer ADR for Cosmos Cash. Why USDT and USDC? These are currently the leading stablecoin tokens with a total market capitalisation of over 90Bn USD (source: coinmarketcap.com)","title":"Summary"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#methodology","text":"Each function is labeled based on the following criteria: BESPOKE: custom functionality ERC20 : part of the ERC20 standard PAUSABLE : part of the solidity pausable contract standard OWNABLE : part of the solidity ownable contract standard PROXY : these functions are part of Solidity\u2019s delegate proxy upgradability pattern MINTABLE : part of the solidity mintable contract standard BURNABLE : part of the solidity burnable contract standard RBAC : part of the solidity roles contract standard","title":"Methodology"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#tldr","text":"Label USDT USDC Cosmos Cash Issuer Mintable issue(amount) mint(_to, _amount) mintToken(amount, owner) Burnable redeem(amount) burn(_amount) burnToken(amount, owner) Pausable pause pause TO DO Pausable unpause unpause TO DO blacklist addBlacklist blacklist(_account) TO DO blacklist removeBlacklist(_clearedUser) unBlacklist(_account) TO DO blacklist destroyBlackFunds(_blackListedUser) n/a TO DO blacklist n/a rescueERC20(tokenContract, to, amount) TO DO ERC20 transfer(_from, _value) transfer(_from, _value) ERC20 transferFrom(_from, _to, _value) transferFrom(_from, _to, _value) ERC20 approve(_spender, _value) approve(_spender, _value) Ownable transferOwnership(newOwner) transferOwnership(newOwner) Bespoke setParams(newBasisPoints, newMaxFee) n/a Bespoke n/a transferWithAuthorization(from, to, value, validAfter, validBefore, nonce, v, r, s) Bespoke n/a configureMinter(minter, minterAllowedAmount) Bespoke n/a receiveWithAuthorization(from, to, value, validAfter, validBefore, nonce, v, r, s) Bespoke n/a cancelAuthorization(authorizer, nonce, v, r, s) RBAC increaseAllowance(spender, increment) RBAC decreaseAllowance(spender, decrement) RBAC n/a removeMinter(minter) RBAC n/a updateBlacklister(_newBlacklister) RBAC n/a updateMasterMinter(_newMasterMinter) RBAC n/a updatePauser(_newPauser) RBAC n/a updateRescuer(newRescuer) Proxy n/a initialize(tokenName, tokenSymbol, tokenCurrency, tokenDecimals, newMasterMinter, newPauser, newBlacklister, newOwner) createIssuer(token, fee, owner) Proxy n/a initializeV2(string) Proxy n/a initializeV2_1(newName) Proxy deprecate(_upgradedAddress) n/a","title":"TL;DR;"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#usdt-erc20-smart-contracts","text":"","title":"USDT ERC20 Smart Contracts"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#source","text":"This analysis used this definition of the USDT ERC-20 smart contract . This is found at 0xdac17f958d2ee523a2206206994597c13d831ec7","title":"Source"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#analysis","text":"The USDT smart contracts have five main areas of note: Tokens freezing PAUASABLE Tokens minting, burning MINTABLE, BURNABLE Role-Based Access Control User denylisting Upgrading function (albeit limited)","title":"Analysis"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#roles","text":"This contract has admin privileges for TWO roles, each comprising of one address: OWNER - owner owns the contract and can call admin functions BLACKLISTER - can add and remove users from a blacklist","title":"Roles"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#functions","text":"issue(amount) - BESPOKE/MINTABLE: mints a certain amount of tokens. redeem(amount) - BESPOKE/BURNABLE: redeems or burns an amount tokens. pause - PAUSABLE: pauses the token transfers. This function can only be called by the contract owner, the issuer of USDT tokens. unpause - PAUSABLE: unpauses token transfers only callable by the token. addBlacklist(_evilUser) - BESPOKE: this function freezes a user's assets by adding an address to a denylist. removeBlacklist(_clearedUser) - BESPOKE: removes a user from a denylist serves, effectively unfreezing a user account. destroyBlackFunds(_blackListedUser) - BESPOKE: burns tokens of a blacklisted address. transfer(_from, _value) - ERC20: transfer tokens from one user to another. transferFrom(_from, _to, _value) - ERC20: Transfers tokens from one address to another, usually called in conjunction with the approve function. approve(_spender, _value) - ERC20: this function approves an address or contracts to use funds on behalf of another user. transferOwnership(newOwner) - OWNABLE: transfers the owner of the contracts to another address. setParams(newBasisPoints, newMaxFee) - This is BESPOKE: functionality that sets specific params on the contract, probable something to do with earning on each transaction; currently, both are zero. deprecate(_upgradedAddress) - BESPOKE: this function is used as part of an upgradability pattern and sets a previous contract as deprecated. The use of this pattern is specific to the upgrading of Ethereum contracts. The reasons for this e are explained in this Coinbase design blog post","title":"Functions"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#usdc-erc-20-smart-contracts","text":"","title":"USDC ERC-20 smart contracts"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#source_1","text":"This analysis used this definition of the USDC ERC-20 smart contract . This is found at 0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48","title":"Source"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#analysis_1","text":"The USDC contract is more complex than USDT, but like USDT, the functions are based upon five function types: Tokens freezing. Tokens minting/burning. RBAC. User denylisting. Upgrades, using a Delegate Proxy pattern.","title":"Analysis"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#roles_1","text":"Unlike USDT, USDC has more granular permissions. There are FIVE roles, each comprising one address: OWNER - owner owns the contract and can call admin functions. BLACKLISTER - can add and remove users from a blacklist. MASTERMINTER - can add and remove minters and update minter allowances. RESCUER - can rescue funds from a user, currently a NULL address. PAUSER - can call the pause and unpause functions on the contract.","title":"Roles"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#functions_1","text":"mint(_to, _amount) - MINTABLE: mint tokens to a given user. burn(_amount) - BURNABLE: burns a certain number of tokens. pause - PAUSABLE: pauses the token transfers in the contract, only callable by the owner. unpause - PAUSABLE: unpauses token transfers only callable. blacklist(_account) - BESPOKE: this function freezes a user's assets by adding the address to a denylist. unBlacklist(_account) - BESPOKE: removes a user from a denylist serves as freezing an account. rescueERC20(tokenContract, to, amount) - BESPOKE: function to rescue funds. transfer(_from, _value) - ERC20: transfer tokens from one user to another. transferFrom(_from, _to, _value) - ERC20: Transfers tokens from one address to another, usually called in conjunction with the approve function. approve(_spender, _value) - ERC20: this function approves an address or contract to use funds on behalf of another user. transferOwnership(newOwner) - OWNABLE: transfers the owner of the contracts to another address. transferWithAuthorization(from, to, value, validAfter, validBefore, nonce, v, r, s) - BESPOKE : This allows a user to send tokens with a signature from another user. cancelAuthorization(authoriser, nonce, v, r, s) - BESPOKE: This stops a user from sending tokens with a signature from a user. configureMinter(minter, minterAllowedAmount) - BESPOKE: allows a minter to mint a certain amount of tokens. increaseAllowance(spender, increment) - BESPOKE: This increases the amount a user can spend per transaction for another user. decreaseAllowance(spender, decrement) - BESPOKE: This decreases the amount a user can spend per transaction for another user. recieveWithAuthorization(from, to, value, validAfter, validBefore, nonce, v, r, s) - BESPOKE : This allows a user to send tokens with a signature from a user. removeMinter(minter) - RBAC: removes an address from the minter role callable by MASTERMINTER . updateBlacklister(_newBlacklister) - RBAC: update the admin role BLACKLIST . updateMasterMinter(_newMasterMinter) - RBAC: update the admin role MASTERMINTER . updatePauser(_newPauser) - RBAC: update the admin role PAUSER . updateRescuer(newRescuer) - RBAC: update the admin role RESCUER . initialize(tokenName, tokenSymbol, tokenCurrency, tokenDecimals, newMasterMinter, newPauser, newBlacklister, newOwner) - PROXY: This functionality is used as part of the delegate proxy pattern. It initialises the smart contract and allows delegate proxy functionality. The use of this pattern is specific to the upgrading of Ethereum contracts. The reasons for this e are explained in this Coinbase design blog post . initializeV2(string) - PROXY: This functionality is used as part of the delegate proxy pattern; it initialises the contract and allows delegate proxy functionality. initializeV2_1(newName) - PROXY: This functionality is used as part of the delegate proxy pattern; it initialises the contract and allows delegate proxy functionality.","title":"Functions"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#cosmos-cash-issuer-module","text":"","title":"Cosmos Cash Issuer Module"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#source_2","text":"This analysis is based on the Cosmos Cash proof of concept issuer implementation .","title":"Source"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#functions_2","text":"createIssuer(token, fee, owner) - This creates an issuer and a token. This initialises the token, and the issuer is the token owner. This is where we could define the token\u2019s PAUSER, BLACKLISTER, MASTERMINTER or other ROLES. mintToken(amount, owner) - mints new tokens to the owner\u2019s address. burnToken(amount, owner) - removes tokens from the owner\u2019s address.","title":"Functions"},{"location":"Explanation/topics/Compare%20USDC%20vs%20USDT%20vs%20CASH-ISSUER/#gap-analysis","text":"The gap between the issuer module and the USDC and USDT smart contracts is not significant. The following features must be implemented for the Issuer module to be compatible with EVM-based smart contracts. BESPOKE: Blockedlist The blocklist functionality is adding and removing a user from a blocked list addToBlockedList removeFromBlocklist burnBlockedlistTokens PAUSABLE: Freeze/Pause token Freeze token functionality is a kill switch that stops all trading with an issuer token freezeToken/pauseToken unfreezeToken/unpauseToken RBAC: A Role-Based Access Control credential system is required to interact with the contract or module. There are different implementation options available: Defining admin roles in the genesis block. This could be implemented using Decentralized IDentity and public verifiable credentials such that: The verifiable credential can be issued by a regulator actor or DID to an issuer DID. The verifiable credential can allow minting and burning of tokens plus other functions The Issuer DID can have multiple DID controllers who can represent different functions in the issuers, such as Operations and Compliance. ERC20: Some ERC20 token functions are not in the SDK bank module - transferFrom(to, from, amount) - approve(address)","title":"Gap Analysis"},{"location":"How-To/","text":"How-to guides The How-To folder contains how-to guides for different aspects of the Elesto project. Additional resources are in the seed scripts folder.","title":"How-to guides"},{"location":"How-To/#how-to-guides","text":"The How-To folder contains how-to guides for different aspects of the Elesto project. Additional resources are in the seed scripts folder.","title":"How-to guides"},{"location":"How-To/chain_001_faucet/","text":"Get Testnet Tokens (Faucet) Hint To learn how to manage keys, see the Manage Keys how-to. The Elesto native token denom is tsp . To obtain tsp tokens from the testnet faucet, use the following command: curl -X POST -d $KEY_ADDRESS $FAUCET_URL where: $KEY_ADDRESS is the blockchain address you want to top-up $FAUCET_URL is the URL of the faucet service Example: get tokens for Alice's account curl -X POST \\ -d \"{\\\"address\\\": \\\" $( cosmos-cashd keys show alice -a ) \\\"}\" \\ https://faucet.cosmos-cash.app.beta.starport.cloud","title":"Get Testnet Tokens (Faucet)"},{"location":"How-To/chain_001_faucet/#get-testnet-tokens-faucet","text":"Hint To learn how to manage keys, see the Manage Keys how-to. The Elesto native token denom is tsp . To obtain tsp tokens from the testnet faucet, use the following command: curl -X POST -d $KEY_ADDRESS $FAUCET_URL where: $KEY_ADDRESS is the blockchain address you want to top-up $FAUCET_URL is the URL of the faucet service Example: get tokens for Alice's account curl -X POST \\ -d \"{\\\"address\\\": \\\" $( cosmos-cashd keys show alice -a ) \\\"}\" \\ https://faucet.cosmos-cash.app.beta.starport.cloud","title":"Get Testnet Tokens (Faucet)"},{"location":"How-To/chain_002_key_management/","text":"This section covers how to manage keys for the Elesto network. Basic Key Management Create, import, export, and delete keys using the Elesto CLI. Create a new key To generate a new key pair, run this command: elestod keys add $KEY_NAME where: $KEY_NAME is a human readable name for your key Example: generate Alice's key \u279c elestod keys add alice - name: alice type: local address: elesto1pp7tyzj80hrys3aae043lerkxkd0h3e8mf7khg pubkey: '{\"@type\":\"/cosmos.crypto.secp256k1.PubKey\",\"key\":\"AnogArgAOO1CDC87MOGeJ7mcRqIWa0rOiRbDmm9X3ddi\"}' mnemonic: \"\" **Important** write this mnemonic phrase in a safe place. It is the only way to recover your account if you ever forget your password. dice argue will silent team drink rate print lift pair copy method rather spy jungle way tribe panther outdoor reject agree employ rain poverty The key comes with a \"mnemonic phrase\", which is serialized into a human-readable 24-word mnemonic. User can recover their associated addresses with the mnemonic phrase. Danger It is important that you keep the mnemonic for address secure , as there is no way to recover it. You would not be able to recover and access the funds in the wallet if you forget the mnemonic phrase. Do not share your mnemonic key with anyone!! List your keys Your wallet can host multiple keys. To list the keys available in your wallet, run this command: elestod keys list Example: list keys \u279c elestod keys list - name: alice type: local address: elesto1pp7tyzj80hrys3aae043lerkxkd0h3e8mf7khg pubkey: '{\"@type\":\"/cosmos.crypto.secp256k1.PubKey\",\"key\":\"AnogArgAOO1CDC87MOGeJ7mcRqIWa0rOiRbDmm9X3ddi\"}' mnemonic: \"\" Delete a key To remove a key from your wallet use the command: elestod keys delete $KEY_NAME Example: delete Alice's keys \u279c elestod keys delete alice Key reference will be deleted. Continue? [ y/N ] : y Key deleted forever ( uh oh! ) Restore existing key by seed phrase elestod keys add $KEY_NAME --recover You can restore an existing key with the mnemonic. Example: restore Alice's keys \u279c elestod keys add alice --recover > Enter your bip39 mnemonic ## Enter your 24-word mnemonic here ## - name: alice type: local address: elesto1pp7tyzj80hrys3aae043lerkxkd0h3e8mf7khg pubkey: '{\"@type\":\"/cosmos.crypto.secp256k1.PubKey\",\"key\":\"AnogArgAOO1CDC87MOGeJ7mcRqIWa0rOiRbDmm9X3ddi\"}' mnemonic: \"\"","title":"Manage Keys"},{"location":"How-To/chain_002_key_management/#basic-key-management","text":"Create, import, export, and delete keys using the Elesto CLI.","title":"Basic Key Management"},{"location":"How-To/chain_002_key_management/#create-a-new-key","text":"To generate a new key pair, run this command: elestod keys add $KEY_NAME where: $KEY_NAME is a human readable name for your key Example: generate Alice's key \u279c elestod keys add alice - name: alice type: local address: elesto1pp7tyzj80hrys3aae043lerkxkd0h3e8mf7khg pubkey: '{\"@type\":\"/cosmos.crypto.secp256k1.PubKey\",\"key\":\"AnogArgAOO1CDC87MOGeJ7mcRqIWa0rOiRbDmm9X3ddi\"}' mnemonic: \"\" **Important** write this mnemonic phrase in a safe place. It is the only way to recover your account if you ever forget your password. dice argue will silent team drink rate print lift pair copy method rather spy jungle way tribe panther outdoor reject agree employ rain poverty The key comes with a \"mnemonic phrase\", which is serialized into a human-readable 24-word mnemonic. User can recover their associated addresses with the mnemonic phrase. Danger It is important that you keep the mnemonic for address secure , as there is no way to recover it. You would not be able to recover and access the funds in the wallet if you forget the mnemonic phrase. Do not share your mnemonic key with anyone!!","title":"Create a new key"},{"location":"How-To/chain_002_key_management/#list-your-keys","text":"Your wallet can host multiple keys. To list the keys available in your wallet, run this command: elestod keys list Example: list keys \u279c elestod keys list - name: alice type: local address: elesto1pp7tyzj80hrys3aae043lerkxkd0h3e8mf7khg pubkey: '{\"@type\":\"/cosmos.crypto.secp256k1.PubKey\",\"key\":\"AnogArgAOO1CDC87MOGeJ7mcRqIWa0rOiRbDmm9X3ddi\"}' mnemonic: \"\"","title":"List your keys"},{"location":"How-To/chain_002_key_management/#delete-a-key","text":"To remove a key from your wallet use the command: elestod keys delete $KEY_NAME Example: delete Alice's keys \u279c elestod keys delete alice Key reference will be deleted. Continue? [ y/N ] : y Key deleted forever ( uh oh! )","title":"Delete a key"},{"location":"How-To/chain_002_key_management/#restore-existing-key-by-seed-phrase","text":"elestod keys add $KEY_NAME --recover You can restore an existing key with the mnemonic. Example: restore Alice's keys \u279c elestod keys add alice --recover > Enter your bip39 mnemonic ## Enter your 24-word mnemonic here ## - name: alice type: local address: elesto1pp7tyzj80hrys3aae043lerkxkd0h3e8mf7khg pubkey: '{\"@type\":\"/cosmos.crypto.secp256k1.PubKey\",\"key\":\"AnogArgAOO1CDC87MOGeJ7mcRqIWa0rOiRbDmm9X3ddi\"}' mnemonic: \"\"","title":"Restore existing key by seed phrase"},{"location":"How-To/chain_003_network_upgrade/","text":"This section covers how to execute a software upgrade for the Elesto network. For more information about government proposals, refer to the Cosmos SDK government module documentation. Submit the Upgrade Request The first step is to open the proposal for the network upgrade elestod tx gov submit-proposal software-upgrade \\ testnet-upgrade-2022-06-21 \\ --upgrade-height 1151280 \\ --deposit 200000000utsp \\ --title \"testnet-upgrade-2022-06-21 upgrade\" \\ --description \"testnet upgrade introducing mint and credentials module\" \\ --from elesto1ms2wrq8k04cug7ea6ekf60nfke6a8vu8pwm684 \\ --chain-id elesto-canary-1 \\ -b block List proposals elestod query gov proposals Example: query a proposal \u279c elestod query gov proposals -o json | jq { \"proposals\" : [ { \"proposal_id\" : \"1\" , \"content\" : { \"@type\" : \"/cosmos.upgrade.v1beta1.SoftwareUpgradeProposal\" , \"title\" : \"testnet-upgrade-2022-06-21 upgrade\" , \"description\" : \"testnet upgrade introducing mint and credentials module\" , \"plan\" : { \"name\" : \"testnet-upgrade-2022-06-21\" , \"time\" : \"0001-01-01T00:00:00Z\" , \"height\" : \"1151280\" , \"info\" : \"\" , \"upgraded_client_state\" : null } }, \"status\" : \"PROPOSAL_STATUS_VOTING_PERIOD\" , \"final_tally_result\" : { \"yes\" : \"0\" , \"abstain\" : \"0\" , \"no\" : \"0\" , \"no_with_veto\" : \"0\" }, \"submit_time\" : \"2022-06-20T15:07:20.362575929Z\" , \"deposit_end_time\" : \"2022-06-22T15:07:20.362575929Z\" , \"total_deposit\" : [ { \"denom\" : \"utsp\" , \"amount\" : \"210000000\" } ], \"voting_start_time\" : \"2022-06-20T15:07:20.362575929Z\" , \"voting_end_time\" : \"2022-06-22T15:07:20.362575929Z\" } ], \"pagination\" : { \"next_key\" : null , \"total\" : \"0\" } } Vote a proposal: elestod tx gov vote $PROPOSAL_ID yes \\ --from elesto1ms2wrq8k04cug7ea6ekf60nfke6a8vu8pwm684 \\ -b block -y --chain-id elesto-canary-1 where $PROPOSAL_ID is the id of the proposal as returned by querying the node proposals ( proposal_id ) To display the votes on a proposal use the command: elestod query gov tally $PROPOSAL_ID where $PROPOSAL_ID is the id of the proposal as returned by querying the node proposals ( proposal_id ) Example: query a proposal votes \u279c elestod query gov tally 1 -o json | jq { \"yes\" : \"70000000000\" , \"abstain\" : \"0\" , \"no\" : \"0\" , \"no_with_veto\" : \"0\" } To query a proposal status: elestod query gov proposal $PROPOSAL_ID where $PROPOSAL_ID is the id of the proposal as returned by querying the node proposals ( proposal_id ) Example: query a proposal status \u279c elestod query gov proposal 1 -o json | jq { \"proposal_id\" : \"1\" , \"content\" : { \"@type\" : \"/cosmos.upgrade.v1beta1.SoftwareUpgradeProposal\" , \"title\" : \"testnet-upgrade-2022-06-21 upgrade\" , \"description\" : \"testnet upgrade introducing mint and credentials module\" , \"plan\" : { \"name\" : \"testnet-upgrade-2022-06-21\" , \"time\" : \"0001-01-01T00:00:00Z\" , \"height\" : \"1151280\" , \"info\" : \"\" , \"upgraded_client_state\" : null } }, \"status\" : \"PROPOSAL_STATUS_PASSED\" , \"final_tally_result\" : { \"yes\" : \"267616000000\" , \"abstain\" : \"0\" , \"no\" : \"0\" , \"no_with_veto\" : \"0\" }, \"submit_time\" : \"2022-06-20T15:07:20.362575929Z\" , \"deposit_end_time\" : \"2022-06-22T15:07:20.362575929Z\" , \"total_deposit\" : [ { \"denom\" : \"utsp\" , \"amount\" : \"220000000\" } ], \"voting_start_time\" : \"2022-06-20T15:07:20.362575929Z\" , \"voting_end_time\" : \"2022-06-22T15:07:20.362575929Z\" } When the proposal has been successfully voted, check the upgrade plan with the command: elestod query upgrade plan Example: check upgrade plan \u279c elestod query upgrade plan -o json | jq { \"name\" : \"testnet-upgrade-2022-06-21\" , \"time\" : \"0001-01-01T00:00:00Z\" , \"height\" : \"1151280\" , \"info\" : \"\" , \"upgraded_client_state\" : null } Prepare the Binaries for Cosmovisor After the government proposal for the upgrade has passed, it is time to install the binaries so Cosmovisor can perform the upgrade. Warning Cosmovisor can automatically fetch binaries from the internet, but it is recommended to install the binaries manually to make sure the binaries are correct and they are working on your infrastructure. The first step is to identify the upgrade name: elestod query upgrade plan -o json | jq .name Example: get the upgrade name \u279c elestod query upgrade plan -o json | jq .name \"testnet-upgrade-2022-06-21\" Then we can create the folder for the upgrade in the Cosmovisor folder structure: mkdir -p .elesto/cosmovisor/upgrades/$UPGRADE_NAME/bin where $UPGRADE_NAME is the name of the upgrade obtained in the previous command Example: create the upgrade folder \u279c mkdir -p .elesto/cosmovisor/upgrades/testnet-upgrade-2022-06-21/bin Now we can download the new node binary, make it executable, check if it's working, and move it to the upgrade folder curl -LO $BINARY_URL chmod +x elestod ./elestod version $NEW_NODE_VERSION mv elestod .elesto/cosmovisor/upgrades/$UPGRADE_NAME/bin where $BINARY_URL is the URL pointing to the binary compatible with your architecture and operative system. $NEW_NODE_VERSION is the node version that will run after the upgrade. Example: download the binary \u279c curl -LO https://github.com/elesto-dao/elesto/releases/download/v2.0.0-rc1/elestod \u279c chmod +x elestod \u279c ./elestod version #verify that the binary is working properly 2 .0.0-rc1 \u279c mv elestod .elesto/cosmovisor/upgrades/testnet-upgrade-2022-06-21/bin That's it! the Cosmovisor software should take care of automatically upgrading the node. For more information about how Cosmovisor will apply the upgrade, check the dedicated reference documentation .","title":"Network upgrade"},{"location":"How-To/chain_003_network_upgrade/#submit-the-upgrade-request","text":"The first step is to open the proposal for the network upgrade elestod tx gov submit-proposal software-upgrade \\ testnet-upgrade-2022-06-21 \\ --upgrade-height 1151280 \\ --deposit 200000000utsp \\ --title \"testnet-upgrade-2022-06-21 upgrade\" \\ --description \"testnet upgrade introducing mint and credentials module\" \\ --from elesto1ms2wrq8k04cug7ea6ekf60nfke6a8vu8pwm684 \\ --chain-id elesto-canary-1 \\ -b block List proposals elestod query gov proposals Example: query a proposal \u279c elestod query gov proposals -o json | jq { \"proposals\" : [ { \"proposal_id\" : \"1\" , \"content\" : { \"@type\" : \"/cosmos.upgrade.v1beta1.SoftwareUpgradeProposal\" , \"title\" : \"testnet-upgrade-2022-06-21 upgrade\" , \"description\" : \"testnet upgrade introducing mint and credentials module\" , \"plan\" : { \"name\" : \"testnet-upgrade-2022-06-21\" , \"time\" : \"0001-01-01T00:00:00Z\" , \"height\" : \"1151280\" , \"info\" : \"\" , \"upgraded_client_state\" : null } }, \"status\" : \"PROPOSAL_STATUS_VOTING_PERIOD\" , \"final_tally_result\" : { \"yes\" : \"0\" , \"abstain\" : \"0\" , \"no\" : \"0\" , \"no_with_veto\" : \"0\" }, \"submit_time\" : \"2022-06-20T15:07:20.362575929Z\" , \"deposit_end_time\" : \"2022-06-22T15:07:20.362575929Z\" , \"total_deposit\" : [ { \"denom\" : \"utsp\" , \"amount\" : \"210000000\" } ], \"voting_start_time\" : \"2022-06-20T15:07:20.362575929Z\" , \"voting_end_time\" : \"2022-06-22T15:07:20.362575929Z\" } ], \"pagination\" : { \"next_key\" : null , \"total\" : \"0\" } } Vote a proposal: elestod tx gov vote $PROPOSAL_ID yes \\ --from elesto1ms2wrq8k04cug7ea6ekf60nfke6a8vu8pwm684 \\ -b block -y --chain-id elesto-canary-1 where $PROPOSAL_ID is the id of the proposal as returned by querying the node proposals ( proposal_id ) To display the votes on a proposal use the command: elestod query gov tally $PROPOSAL_ID where $PROPOSAL_ID is the id of the proposal as returned by querying the node proposals ( proposal_id ) Example: query a proposal votes \u279c elestod query gov tally 1 -o json | jq { \"yes\" : \"70000000000\" , \"abstain\" : \"0\" , \"no\" : \"0\" , \"no_with_veto\" : \"0\" } To query a proposal status: elestod query gov proposal $PROPOSAL_ID where $PROPOSAL_ID is the id of the proposal as returned by querying the node proposals ( proposal_id ) Example: query a proposal status \u279c elestod query gov proposal 1 -o json | jq { \"proposal_id\" : \"1\" , \"content\" : { \"@type\" : \"/cosmos.upgrade.v1beta1.SoftwareUpgradeProposal\" , \"title\" : \"testnet-upgrade-2022-06-21 upgrade\" , \"description\" : \"testnet upgrade introducing mint and credentials module\" , \"plan\" : { \"name\" : \"testnet-upgrade-2022-06-21\" , \"time\" : \"0001-01-01T00:00:00Z\" , \"height\" : \"1151280\" , \"info\" : \"\" , \"upgraded_client_state\" : null } }, \"status\" : \"PROPOSAL_STATUS_PASSED\" , \"final_tally_result\" : { \"yes\" : \"267616000000\" , \"abstain\" : \"0\" , \"no\" : \"0\" , \"no_with_veto\" : \"0\" }, \"submit_time\" : \"2022-06-20T15:07:20.362575929Z\" , \"deposit_end_time\" : \"2022-06-22T15:07:20.362575929Z\" , \"total_deposit\" : [ { \"denom\" : \"utsp\" , \"amount\" : \"220000000\" } ], \"voting_start_time\" : \"2022-06-20T15:07:20.362575929Z\" , \"voting_end_time\" : \"2022-06-22T15:07:20.362575929Z\" } When the proposal has been successfully voted, check the upgrade plan with the command: elestod query upgrade plan Example: check upgrade plan \u279c elestod query upgrade plan -o json | jq { \"name\" : \"testnet-upgrade-2022-06-21\" , \"time\" : \"0001-01-01T00:00:00Z\" , \"height\" : \"1151280\" , \"info\" : \"\" , \"upgraded_client_state\" : null }","title":"Submit the Upgrade Request"},{"location":"How-To/chain_003_network_upgrade/#prepare-the-binaries-for-cosmovisor","text":"After the government proposal for the upgrade has passed, it is time to install the binaries so Cosmovisor can perform the upgrade. Warning Cosmovisor can automatically fetch binaries from the internet, but it is recommended to install the binaries manually to make sure the binaries are correct and they are working on your infrastructure. The first step is to identify the upgrade name: elestod query upgrade plan -o json | jq .name Example: get the upgrade name \u279c elestod query upgrade plan -o json | jq .name \"testnet-upgrade-2022-06-21\" Then we can create the folder for the upgrade in the Cosmovisor folder structure: mkdir -p .elesto/cosmovisor/upgrades/$UPGRADE_NAME/bin where $UPGRADE_NAME is the name of the upgrade obtained in the previous command Example: create the upgrade folder \u279c mkdir -p .elesto/cosmovisor/upgrades/testnet-upgrade-2022-06-21/bin Now we can download the new node binary, make it executable, check if it's working, and move it to the upgrade folder curl -LO $BINARY_URL chmod +x elestod ./elestod version $NEW_NODE_VERSION mv elestod .elesto/cosmovisor/upgrades/$UPGRADE_NAME/bin where $BINARY_URL is the URL pointing to the binary compatible with your architecture and operative system. $NEW_NODE_VERSION is the node version that will run after the upgrade. Example: download the binary \u279c curl -LO https://github.com/elesto-dao/elesto/releases/download/v2.0.0-rc1/elestod \u279c chmod +x elestod \u279c ./elestod version #verify that the binary is working properly 2 .0.0-rc1 \u279c mv elestod .elesto/cosmovisor/upgrades/testnet-upgrade-2022-06-21/bin That's it! the Cosmovisor software should take care of automatically upgrading the node. For more information about how Cosmovisor will apply the upgrade, check the dedicated reference documentation .","title":"Prepare the Binaries for Cosmovisor"},{"location":"How-To/general_001_swagger/","text":"Swagger This how-to section is dedicated to the Swagger documentation that is bundled with the project. Note: The Swagger API is supported only as a useful method to query the node data. The Swagger API cannot be used to submit transactions to the node. Generate the Swagger UI The Swagger UI is generated from the protobuf files in the proto folder in the root of the project. To generate or refresh the swagger UI, run the following command from the project's root folder: ./scripts/protoc-swagger-gen.sh Bundle the generate swagger UI as go package: cd ./docs/Reference/swagger statik -f -src=./swagger-ui Enable Swagger UI Swagger UI is disabled by default. Use the app.toml file to enable Swagger support. The default location of the app.toml file is the current user home directory: ~/.cosmos-cash/config/app.toml In the API Configuration section, make sure the variables are set to true as shown in the following example: ############################################################################### ### API Configuration ### ############################################################################### [api] # Enable defines if the API server should be enabled. enable = true # <- this must be set to true # Swagger defines if swagger documentation should automatically be registered. swagger = true # <- this must be set to true Finally, restart the node. The swagger UI should be available at the address http://localhost:1317/swagger/","title":"Swagger"},{"location":"How-To/general_001_swagger/#swagger","text":"This how-to section is dedicated to the Swagger documentation that is bundled with the project. Note: The Swagger API is supported only as a useful method to query the node data. The Swagger API cannot be used to submit transactions to the node.","title":"Swagger"},{"location":"How-To/general_001_swagger/#generate-the-swagger-ui","text":"The Swagger UI is generated from the protobuf files in the proto folder in the root of the project. To generate or refresh the swagger UI, run the following command from the project's root folder: ./scripts/protoc-swagger-gen.sh Bundle the generate swagger UI as go package: cd ./docs/Reference/swagger statik -f -src=./swagger-ui","title":"Generate the Swagger UI"},{"location":"How-To/general_001_swagger/#enable-swagger-ui","text":"Swagger UI is disabled by default. Use the app.toml file to enable Swagger support. The default location of the app.toml file is the current user home directory: ~/.cosmos-cash/config/app.toml In the API Configuration section, make sure the variables are set to true as shown in the following example: ############################################################################### ### API Configuration ### ############################################################################### [api] # Enable defines if the API server should be enabled. enable = true # <- this must be set to true # Swagger defines if swagger documentation should automatically be registered. swagger = true # <- this must be set to true Finally, restart the node. The swagger UI should be available at the address http://localhost:1317/swagger/","title":"Enable Swagger UI"},{"location":"Networks/node/","text":"Minimum Requirements The minimum recommended specs for running the Elesto node ( elestod ) is as follows: 4-core (2 physical core), x86_64 architecture processor 16 GB RAM (or equivalent swap file set up) 200 GB of storage space Manual installation Hint The example commands in this guide are for Ubuntu Linux. To run these commands on a different operating system, modify the commands as appropriate for your environment. Install prerequisites # update the local package list and install any available upgrades sudo apt update && sudo apt upgrade -y # install toolchain and ensure accurate time synchronization sudo apt install make build-essential git jq ufw curl snapd -y Install Golang # use snap to install the latest stable version of go sudo snap install go --classic Update your execution path to be able to launch the go binaries: echo 'PATH=\"$HOME/go/bin:$PATH\"' >> ~/.profile && source ~/.profile Fetch the code from GitHub cd ~ git clone https://github.com/elesto-dao/elesto cd elesto git checkout v1.0.0-rc2 Build and install the Elesto binary make install The elestod binary is installed in ~/go/bin/elestod . Enable the host firewall [OPTIONAL] For servers that are directly exposed to the internet, it is recommended to install a firewall. ## allow ssh connection to the server sudo ufw allow ssh ## allow port to submit transactions sudo ufw allow 26656 /tcp ## start the firewall sudo ufw enable Network configuration To configure the node to join the Testnet network follow this link .","title":"Install an Elesto Node"},{"location":"Networks/node/#minimum-requirements","text":"The minimum recommended specs for running the Elesto node ( elestod ) is as follows: 4-core (2 physical core), x86_64 architecture processor 16 GB RAM (or equivalent swap file set up) 200 GB of storage space","title":"Minimum Requirements"},{"location":"Networks/node/#manual-installation","text":"Hint The example commands in this guide are for Ubuntu Linux. To run these commands on a different operating system, modify the commands as appropriate for your environment.","title":"Manual installation"},{"location":"Networks/node/#install-prerequisites","text":"# update the local package list and install any available upgrades sudo apt update && sudo apt upgrade -y # install toolchain and ensure accurate time synchronization sudo apt install make build-essential git jq ufw curl snapd -y","title":"Install prerequisites"},{"location":"Networks/node/#install-golang","text":"# use snap to install the latest stable version of go sudo snap install go --classic Update your execution path to be able to launch the go binaries: echo 'PATH=\"$HOME/go/bin:$PATH\"' >> ~/.profile && source ~/.profile","title":"Install Golang"},{"location":"Networks/node/#fetch-the-code-from-github","text":"cd ~ git clone https://github.com/elesto-dao/elesto cd elesto git checkout v1.0.0-rc2","title":"Fetch the code from GitHub"},{"location":"Networks/node/#build-and-install-the-elesto-binary","text":"make install The elestod binary is installed in ~/go/bin/elestod .","title":"Build and install the Elesto binary"},{"location":"Networks/node/#enable-the-host-firewall-optional","text":"For servers that are directly exposed to the internet, it is recommended to install a firewall. ## allow ssh connection to the server sudo ufw allow ssh ## allow port to submit transactions sudo ufw allow 26656 /tcp ## start the firewall sudo ufw enable","title":"Enable the host firewall [OPTIONAL]"},{"location":"Networks/node/#network-configuration","text":"To configure the node to join the Testnet network follow this link .","title":"Network configuration"},{"location":"Networks/testnet/","text":"Joining Testnet Important Before you start, make sure you have installed the Elesto binary . Testnet chain ID The Elesto testnet chain ID is elesto-canary-1 Initialize Your Elesto Node Initialize your node and create the node configurations. Choose a name fo your node. This guide uses elesto-guide-1 . elestod init elesto-guide-1 --chain-id = elesto-canary-1 Update the persistent peers list in the config.toml : sed -i 's/persistent_peers = \"\"/persistent_peers = \"833d9eacfec93c3df2e721d8ce818011418752a0@35.232.91.19:26656\"/g' ~/.elesto/config/config.toml The updated peers configuration looks like this: # Comma separated list of seed nodes to connect to seeds = \"\" # Comma separated list of nodes to keep persistent connections to persistent_peers = \"833d9eacfec93c3df2e721d8ce818011418752a0@35.232.91.19:26656\" Set up Cosmovisor Cosmovisor allows automatic upgrades for the node, and it is the recommended way of running an Elesto node. Install the Cosmovisor binary: go install github.com/cosmos/cosmos-sdk/cosmovisor/cmd/cosmovisor@v1.0.0 Create the required folder structure: mkdir -p ~/.elesto/cosmovisor mkdir -p ~/.elesto/cosmovisor/genesis mkdir -p ~/.elesto/cosmovisor/genesis/bin mkdir -p ~/.elesto/cosmovisor/upgrades Set up the Cosmovisor environment variables: echo \"# Setup Cosmovisor\" >> ~/.profile echo \"export DAEMON_NAME=elestod\" >> ~/.profile echo \"export DAEMON_HOME= $HOME /.elesto\" >> ~/.profile echo \"export DAEMON_ALLOW_DOWNLOAD_BINARIES=false\" >> ~/.profile echo \"export DAEMON_LOG_BUFFER_SIZE=512\" >> ~/.profile echo \"export DAEMON_RESTART_AFTER_UPGRADE=true\" >> ~/.profile echo \"export UNSAFE_SKIP_BACKUP=true\" >> ~/.profile source ~/.profile Download and replace the genesis file: cd ~/.elesto # TODO: the repo is currently private curl -L -O https://github.com/elesto-dao/networks/raw/main/elesto-canary-1/genesis.tar.bz2 tar -xjf genesis.tar.bz2 && rm genesis.tar.bz2 Copy the current elestod binary into the cosmovisor/genesis folder: cp ~/go/bin/elestod ~/.elesto/cosmovisor/genesis/bin The cosmovisor and elestod versions must be the same. To verify the versions, run these commands: cosmovisor version elestod version Reset private validator file to genesis state: elestod unsafe-reset-all Allow Background Run and Auto Restart Set up an Elesto service to allow cosmovisor to run in the background and automatic restarts: cd ~ echo \"[Unit] Description=Cosmovisor daemon After=network-online.target [Service] Environment=\" DAEMON_NAME = elestod \" Environment=\" DAEMON_HOME = ${ HOME } /.elesto \" Environment=\" DAEMON_RESTART_AFTER_UPGRADE = true \" Environment=\" DAEMON_ALLOW_DOWNLOAD_BINARIES = false \" Environment=\" DAEMON_LOG_BUFFER_SIZE = 512 \" Environment=\" UNSAFE_SKIP_BACKUP = true \" User= $USER ExecStart= ${ HOME } /go/bin/cosmovisor start Restart=always RestartSec=3 LimitNOFILE=infinity LimitNPROC=infinity [Install] WantedBy=multi-user.target \" >cosmovisor.service Install the service: sudo mv cosmovisor.service /lib/systemd/system/cosmovisor.service sudo systemctl daemon-reload sudo systemctl restart systemd-journald Operate the Elesto Service Start the service: sudo systemctl start cosmovisor Check the service status: sudo systemctl status cosmovisor Inspect the service logs: journalctl -u cosmovisor -f Sync the Node After starting the elestod daemon, the chain begins to sync to the network. The time to sync to the network varies, depending on your setup, but plan accordingly that the sync process could take a very long time. To query the status of your node: # Query via the RPC (default port: 26657) curl http://localhost:26657/status | jq .result.sync_info.catching_up If this command returns true, then your node is still catching up. Continue to wait. If this command returns false , then your node has caught up to the network's current block. You are safe to proceed with upgrading a validator node. TODO: state-sync and backups Upgrading to validator Keys and Balances To become a validator, your account must have a positive balance. Follow the keys management to learn how to create an account and the faucet how-to to learn how to get tokens for the testnet. To upgrade the node to a be validator node, you must submit a create-validator transaction: elestod tx staking create-validator \\ --chain-id = \"elesto-canary-1\" \\ --pubkey = $( elestod tendermint show-validator ) \\ --amount =[ staking_amount_utsp ] \\ --commission-rate = \"[commission_rate]\" \\ --commission-max-rate = \"[maximum_commission_rate]\" \\ --commission-max-change-rate = \"[maximum_rate_of_change_of_commission]\" \\ --min-self-delegation = \"[min_self_delegation_amount]\" \\ --moniker = \"elesto-guide-1\" \\ --security-contact = \"[security contact email/contact method]\" \\ --website \"wesite of your validator\" \\ --from =[ KEY_NAME ] Example: Create validator for Alice The following example shows a broadcast of the create-validator transaction from Alice's wallet: elestod tx staking create-validator \\ --chain-id = \"elesto-canary-1\" \\ --pubkey = $( elestod tendermint show-validator ) \\ --amount = 9000000utsp \\ --commission-rate = \"0.1\" \\ --commission-max-rate = \"0.2\" \\ --commission-max-change-rate = \"0.1\" \\ --min-self-delegation = \"1\" \\ --moniker = \"elesto-guide-1\" \\ --security-contact = \"security@example-validator.com\" \\ --website \"https://example-validator.com\" \\ --from = alice To see an explanation of the parameter values, use help. You can run this command: elestod tx staking create-validator --help Track Validator Active Set To see the current validator active set: elestod query staking validators --limit 300 -o json | jq -r '.validators[] | [.operator_address, .status, (.tokens|tonumber / pow(10; 6)), .commission.update_time[0:19], .description.moniker] | @csv' | column -t -s\",\" You can search for your specific moniker by adding grep MONIKER at the end: elestod query staking validators --limit 300 -o json | jq -r '.validators[] | [.operator_address, .status, (.tokens|tonumber / pow(10; 6)), .commission.update_time[0:19], .description.moniker] | @csv' | column -t -s\",\" | grep elesto-guide-1 If your bond status is BOND_STATUS_BONDED , your validator is part of the active validator set!","title":"Joining Testnet"},{"location":"Networks/testnet/#joining-testnet","text":"Important Before you start, make sure you have installed the Elesto binary .","title":"Joining Testnet"},{"location":"Networks/testnet/#testnet-chain-id","text":"The Elesto testnet chain ID is elesto-canary-1","title":"Testnet chain ID"},{"location":"Networks/testnet/#initialize-your-elesto-node","text":"Initialize your node and create the node configurations. Choose a name fo your node. This guide uses elesto-guide-1 . elestod init elesto-guide-1 --chain-id = elesto-canary-1 Update the persistent peers list in the config.toml : sed -i 's/persistent_peers = \"\"/persistent_peers = \"833d9eacfec93c3df2e721d8ce818011418752a0@35.232.91.19:26656\"/g' ~/.elesto/config/config.toml The updated peers configuration looks like this: # Comma separated list of seed nodes to connect to seeds = \"\" # Comma separated list of nodes to keep persistent connections to persistent_peers = \"833d9eacfec93c3df2e721d8ce818011418752a0@35.232.91.19:26656\"","title":"Initialize Your Elesto Node"},{"location":"Networks/testnet/#set-up-cosmovisor","text":"Cosmovisor allows automatic upgrades for the node, and it is the recommended way of running an Elesto node. Install the Cosmovisor binary: go install github.com/cosmos/cosmos-sdk/cosmovisor/cmd/cosmovisor@v1.0.0 Create the required folder structure: mkdir -p ~/.elesto/cosmovisor mkdir -p ~/.elesto/cosmovisor/genesis mkdir -p ~/.elesto/cosmovisor/genesis/bin mkdir -p ~/.elesto/cosmovisor/upgrades Set up the Cosmovisor environment variables: echo \"# Setup Cosmovisor\" >> ~/.profile echo \"export DAEMON_NAME=elestod\" >> ~/.profile echo \"export DAEMON_HOME= $HOME /.elesto\" >> ~/.profile echo \"export DAEMON_ALLOW_DOWNLOAD_BINARIES=false\" >> ~/.profile echo \"export DAEMON_LOG_BUFFER_SIZE=512\" >> ~/.profile echo \"export DAEMON_RESTART_AFTER_UPGRADE=true\" >> ~/.profile echo \"export UNSAFE_SKIP_BACKUP=true\" >> ~/.profile source ~/.profile Download and replace the genesis file: cd ~/.elesto # TODO: the repo is currently private curl -L -O https://github.com/elesto-dao/networks/raw/main/elesto-canary-1/genesis.tar.bz2 tar -xjf genesis.tar.bz2 && rm genesis.tar.bz2 Copy the current elestod binary into the cosmovisor/genesis folder: cp ~/go/bin/elestod ~/.elesto/cosmovisor/genesis/bin The cosmovisor and elestod versions must be the same. To verify the versions, run these commands: cosmovisor version elestod version Reset private validator file to genesis state: elestod unsafe-reset-all","title":"Set up Cosmovisor"},{"location":"Networks/testnet/#allow-background-run-and-auto-restart","text":"Set up an Elesto service to allow cosmovisor to run in the background and automatic restarts: cd ~ echo \"[Unit] Description=Cosmovisor daemon After=network-online.target [Service] Environment=\" DAEMON_NAME = elestod \" Environment=\" DAEMON_HOME = ${ HOME } /.elesto \" Environment=\" DAEMON_RESTART_AFTER_UPGRADE = true \" Environment=\" DAEMON_ALLOW_DOWNLOAD_BINARIES = false \" Environment=\" DAEMON_LOG_BUFFER_SIZE = 512 \" Environment=\" UNSAFE_SKIP_BACKUP = true \" User= $USER ExecStart= ${ HOME } /go/bin/cosmovisor start Restart=always RestartSec=3 LimitNOFILE=infinity LimitNPROC=infinity [Install] WantedBy=multi-user.target \" >cosmovisor.service Install the service: sudo mv cosmovisor.service /lib/systemd/system/cosmovisor.service sudo systemctl daemon-reload sudo systemctl restart systemd-journald","title":"Allow Background Run and Auto Restart"},{"location":"Networks/testnet/#operate-the-elesto-service","text":"Start the service: sudo systemctl start cosmovisor Check the service status: sudo systemctl status cosmovisor Inspect the service logs: journalctl -u cosmovisor -f","title":"Operate the Elesto Service"},{"location":"Networks/testnet/#sync-the-node","text":"After starting the elestod daemon, the chain begins to sync to the network. The time to sync to the network varies, depending on your setup, but plan accordingly that the sync process could take a very long time. To query the status of your node: # Query via the RPC (default port: 26657) curl http://localhost:26657/status | jq .result.sync_info.catching_up If this command returns true, then your node is still catching up. Continue to wait. If this command returns false , then your node has caught up to the network's current block. You are safe to proceed with upgrading a validator node. TODO: state-sync and backups","title":"Sync the Node"},{"location":"Networks/testnet/#upgrading-to-validator","text":"Keys and Balances To become a validator, your account must have a positive balance. Follow the keys management to learn how to create an account and the faucet how-to to learn how to get tokens for the testnet. To upgrade the node to a be validator node, you must submit a create-validator transaction: elestod tx staking create-validator \\ --chain-id = \"elesto-canary-1\" \\ --pubkey = $( elestod tendermint show-validator ) \\ --amount =[ staking_amount_utsp ] \\ --commission-rate = \"[commission_rate]\" \\ --commission-max-rate = \"[maximum_commission_rate]\" \\ --commission-max-change-rate = \"[maximum_rate_of_change_of_commission]\" \\ --min-self-delegation = \"[min_self_delegation_amount]\" \\ --moniker = \"elesto-guide-1\" \\ --security-contact = \"[security contact email/contact method]\" \\ --website \"wesite of your validator\" \\ --from =[ KEY_NAME ] Example: Create validator for Alice The following example shows a broadcast of the create-validator transaction from Alice's wallet: elestod tx staking create-validator \\ --chain-id = \"elesto-canary-1\" \\ --pubkey = $( elestod tendermint show-validator ) \\ --amount = 9000000utsp \\ --commission-rate = \"0.1\" \\ --commission-max-rate = \"0.2\" \\ --commission-max-change-rate = \"0.1\" \\ --min-self-delegation = \"1\" \\ --moniker = \"elesto-guide-1\" \\ --security-contact = \"security@example-validator.com\" \\ --website \"https://example-validator.com\" \\ --from = alice To see an explanation of the parameter values, use help. You can run this command: elestod tx staking create-validator --help","title":"Upgrading to validator"},{"location":"Networks/testnet/#track-validator-active-set","text":"To see the current validator active set: elestod query staking validators --limit 300 -o json | jq -r '.validators[] | [.operator_address, .status, (.tokens|tonumber / pow(10; 6)), .commission.update_time[0:19], .description.moniker] | @csv' | column -t -s\",\" You can search for your specific moniker by adding grep MONIKER at the end: elestod query staking validators --limit 300 -o json | jq -r '.validators[] | [.operator_address, .status, (.tokens|tonumber / pow(10; 6)), .commission.update_time[0:19], .description.moniker] | @csv' | column -t -s\",\" | grep elesto-guide-1 If your bond status is BOND_STATUS_BONDED , your validator is part of the active validator set!","title":"Track Validator Active Set"},{"location":"Reference/","text":"Reference Documentation How to use the Elesto Reference Documentation. Reference Documentation Introduction Contributing Layout Reference Introduction This section contains Reference documentation for Elesto. Reference Documentation is intended to be information-oriented . Content must allow the reader to easily navigate the content and use the content in conjunction with the code. This documentation describes the machinery, for example, classes, functions, interfaces, parameters, and so on. For further information please see the ADR relating to the documentation structure . Contributing The content must be dry, clear, and terse in style. All documentation should be written following Google Documentation Best Practice Generate as much documentation as possible from the code. Raise a PR for all documentation changes Layout Reference Documentation will come in various forms: Architecture diagrams - Diagrams must be in SVG format so that the diagrams can remain crisp and clear at any resolution or size, stored in GitHub, and version controlled. Module specifications and designs - By convention, module documentation in the Cosmos SDK is stored with the module itself. However, we propose that the easiest way for a new user to find documentation is to store the documentation at the root docs folder. To accomodate this module, the documentation will follow the existing convention, but the content will be reference from this section. Code-level documentation - The text that is part of the code and is used to auto-generate the documentation from the code. API reference - Including REST and gRPC endpoints. Glossary - a dictionary of domain-relevant terms. This glossary can be used in conjunction with the Cosmos Network Glossary . Reference Google Style Guide for Markdown Write the Docs global community Write the Docs Code of Conduct","title":"Reference Documentation"},{"location":"Reference/#reference-documentation","text":"How to use the Elesto Reference Documentation. Reference Documentation Introduction Contributing Layout Reference","title":"Reference Documentation"},{"location":"Reference/#introduction","text":"This section contains Reference documentation for Elesto. Reference Documentation is intended to be information-oriented . Content must allow the reader to easily navigate the content and use the content in conjunction with the code. This documentation describes the machinery, for example, classes, functions, interfaces, parameters, and so on. For further information please see the ADR relating to the documentation structure .","title":"Introduction"},{"location":"Reference/#contributing","text":"The content must be dry, clear, and terse in style. All documentation should be written following Google Documentation Best Practice Generate as much documentation as possible from the code. Raise a PR for all documentation changes","title":"Contributing"},{"location":"Reference/#layout","text":"Reference Documentation will come in various forms: Architecture diagrams - Diagrams must be in SVG format so that the diagrams can remain crisp and clear at any resolution or size, stored in GitHub, and version controlled. Module specifications and designs - By convention, module documentation in the Cosmos SDK is stored with the module itself. However, we propose that the easiest way for a new user to find documentation is to store the documentation at the root docs folder. To accomodate this module, the documentation will follow the existing convention, but the content will be reference from this section. Code-level documentation - The text that is part of the code and is used to auto-generate the documentation from the code. API reference - Including REST and gRPC endpoints. Glossary - a dictionary of domain-relevant terms. This glossary can be used in conjunction with the Cosmos Network Glossary .","title":"Layout"},{"location":"Reference/#reference","text":"Google Style Guide for Markdown Write the Docs global community Write the Docs Code of Conduct","title":"Reference"},{"location":"Reference/GLOSSARY/","text":"GLOSSARY A asset-referenced tokens (ART) Several fiat currencies, one or several commodities or one or several crypto-assets, or a combination of such assets (the so called \u201creserve assets\u201d) within the MiCA context. B C crypto-asset service provider (CASP) Any person whose occupation or business is the provision of one or more crypto-asset services to third parties on a professional basis. D Decentralized Identifier (DID) A type of identifier that enables verifiable, decentralized digital identity. A globally unique persistent identifier that does not require a centralized registration authority and is often generated and/or registered cryptographically. DIDs are fully conformant Universal Resource Identifiers (URIs) . W3C defines a DID as a portable URL-based identifier ... associated with an entity ... An example of a DID is did:example:123456abcdef\"* . e-money tokens (EMT) A type of crypto asset for one single fiat currency. H holder In the SSI ecosystem, the holder receives identity credentials from an issuer. I identity management (IdM) A framework of policies and technologies to ensure that users have the appropriate access to technology resources. identity provider (IdP) The primary component of an identity management (IdM) system that creates, stores, and manages digital identities to provide services such as signup, authentication, and authorization. issuer In the SSI ecosystem, the issuer generates and issues identity credentials. key management system (KMS) A system for the management of cryptographic keys and their metadata. L legal person Any person or entity that is able to perform legal activities, such as enter into contracts, own property, and so on. M Market in Crypto-assets (MiCA) Legislation that covers crypto assets in the European Union. mediator In the SSI ecosystem, the mediator participates in agent-to-agent message delivery. mediator agent SSI agents, built on the Aries Go Framework, serve as a bridge between agents. R regulator An entity that is established by governments or other organizations to oversee the functioning and fairness of financial markets and the firms that engage in financial activity. S self-sovereign identity (SSI) An approach to digital identity that gives individuals control of their digital identities, this emerging identity model allows any person, organization, or subject to have multiple sovereign, persistent, and portable identities. V verifiable credential (VC) A tamper-evident credential that has authorship that can be cryptographically verified. A standard data model and representation format for cryptographically-verifiable digital credentials is defined by the W3C Verifiable Credentials specification . verifiable data registry (VDR) A system that facilitates the creation, verification, updating, and deactivation of decentralized identifiers and DID documents. A verifiable data registry might also be used for other cryptographically-verifiable data structures such as verifiable credentials (VCs). verifiable presentation (VP) A tamper-evident presentation encoded in such a way that authorship of the data can be trusted after a process of cryptographic verification. verifier In the SSI ecosystem, the verifier receives and validates a holder's credentials. Virtual Asset Service Provider (VASP) FATF defines a virtual asset service provider (VASP) as the following: \u201cAny natural/legal person who ... as a business conducts one or more of the following activities or operations for or on behalf of another natural or legal person: i. exchange between virtual assets and fiat currencies; ii. exchange between one or more forms of virtual assets; iii. transfer of virtual assets; iv. safekeeping and/or administration of virtual assets or instruments enabling control over virtual assets; and v. participation in and provision of financial services related to an issuer\u2019s offer and/or sale of a virtual asset.\u201d FATF guidance to the G20 Z zero-knowledge proof (ZKP) In cryptography, a zero-knowledge proof or zero-knowledge protocol is a method by which one party (the prover) can prove to another party (the verifier) that a given statement is true, without conveying any information apart from the fact that the statement is indeed true. The essence of zero-knowledge proofs is that it is trivial to prove that one possesses knowledge of certain information by simply revealing it; the challenge is to prove such possession without revealing the information itself or any additional information ( Zero-knowledge proof on wikipedia ). a","title":"GLOSSARY"},{"location":"Reference/GLOSSARY/#glossary","text":"","title":"GLOSSARY"},{"location":"Reference/GLOSSARY/#a","text":"","title":"A"},{"location":"Reference/GLOSSARY/#asset-referenced-tokens-art","text":"Several fiat currencies, one or several commodities or one or several crypto-assets, or a combination of such assets (the so called \u201creserve assets\u201d) within the MiCA context.","title":"asset-referenced tokens (ART)"},{"location":"Reference/GLOSSARY/#b","text":"","title":"B"},{"location":"Reference/GLOSSARY/#c","text":"","title":"C"},{"location":"Reference/GLOSSARY/#crypto-asset-service-provider-casp","text":"Any person whose occupation or business is the provision of one or more crypto-asset services to third parties on a professional basis.","title":"crypto-asset service provider (CASP)"},{"location":"Reference/GLOSSARY/#d","text":"","title":"D"},{"location":"Reference/GLOSSARY/#decentralized-identifier-did","text":"A type of identifier that enables verifiable, decentralized digital identity. A globally unique persistent identifier that does not require a centralized registration authority and is often generated and/or registered cryptographically. DIDs are fully conformant Universal Resource Identifiers (URIs) . W3C defines a DID as a portable URL-based identifier ... associated with an entity ... An example of a DID is did:example:123456abcdef\"* .","title":"Decentralized Identifier (DID)"},{"location":"Reference/GLOSSARY/#e-money-tokens-emt","text":"A type of crypto asset for one single fiat currency.","title":"e-money tokens (EMT)"},{"location":"Reference/GLOSSARY/#h","text":"","title":"H"},{"location":"Reference/GLOSSARY/#holder","text":"In the SSI ecosystem, the holder receives identity credentials from an issuer.","title":"holder"},{"location":"Reference/GLOSSARY/#i","text":"","title":"I"},{"location":"Reference/GLOSSARY/#identity-management-idm","text":"A framework of policies and technologies to ensure that users have the appropriate access to technology resources.","title":"identity management (IdM)"},{"location":"Reference/GLOSSARY/#identity-provider-idp","text":"The primary component of an identity management (IdM) system that creates, stores, and manages digital identities to provide services such as signup, authentication, and authorization.","title":"identity provider (IdP)"},{"location":"Reference/GLOSSARY/#issuer","text":"In the SSI ecosystem, the issuer generates and issues identity credentials.","title":"issuer"},{"location":"Reference/GLOSSARY/#key-management-system-kms","text":"A system for the management of cryptographic keys and their metadata.","title":"key management system (KMS)"},{"location":"Reference/GLOSSARY/#l","text":"","title":"L"},{"location":"Reference/GLOSSARY/#legal-person","text":"Any person or entity that is able to perform legal activities, such as enter into contracts, own property, and so on.","title":"legal person"},{"location":"Reference/GLOSSARY/#m","text":"","title":"M"},{"location":"Reference/GLOSSARY/#market-in-crypto-assets-mica","text":"Legislation that covers crypto assets in the European Union.","title":"Market in Crypto-assets (MiCA)"},{"location":"Reference/GLOSSARY/#mediator","text":"In the SSI ecosystem, the mediator participates in agent-to-agent message delivery.","title":"mediator"},{"location":"Reference/GLOSSARY/#mediator-agent","text":"SSI agents, built on the Aries Go Framework, serve as a bridge between agents.","title":"mediator agent"},{"location":"Reference/GLOSSARY/#r","text":"","title":"R"},{"location":"Reference/GLOSSARY/#regulator","text":"An entity that is established by governments or other organizations to oversee the functioning and fairness of financial markets and the firms that engage in financial activity.","title":"regulator"},{"location":"Reference/GLOSSARY/#s","text":"","title":"S"},{"location":"Reference/GLOSSARY/#self-sovereign-identity-ssi","text":"An approach to digital identity that gives individuals control of their digital identities, this emerging identity model allows any person, organization, or subject to have multiple sovereign, persistent, and portable identities.","title":"self-sovereign identity (SSI)"},{"location":"Reference/GLOSSARY/#v","text":"","title":"V"},{"location":"Reference/GLOSSARY/#verifiable-credential-vc","text":"A tamper-evident credential that has authorship that can be cryptographically verified. A standard data model and representation format for cryptographically-verifiable digital credentials is defined by the W3C Verifiable Credentials specification .","title":"verifiable credential (VC)"},{"location":"Reference/GLOSSARY/#verifiable-data-registry-vdr","text":"A system that facilitates the creation, verification, updating, and deactivation of decentralized identifiers and DID documents. A verifiable data registry might also be used for other cryptographically-verifiable data structures such as verifiable credentials (VCs).","title":"verifiable data registry (VDR)"},{"location":"Reference/GLOSSARY/#verifiable-presentation-vp","text":"A tamper-evident presentation encoded in such a way that authorship of the data can be trusted after a process of cryptographic verification.","title":"verifiable presentation (VP)"},{"location":"Reference/GLOSSARY/#verifier","text":"In the SSI ecosystem, the verifier receives and validates a holder's credentials.","title":"verifier"},{"location":"Reference/GLOSSARY/#virtual-asset-service-provider-vasp","text":"FATF defines a virtual asset service provider (VASP) as the following: \u201cAny natural/legal person who ... as a business conducts one or more of the following activities or operations for or on behalf of another natural or legal person: i. exchange between virtual assets and fiat currencies; ii. exchange between one or more forms of virtual assets; iii. transfer of virtual assets; iv. safekeeping and/or administration of virtual assets or instruments enabling control over virtual assets; and v. participation in and provision of financial services related to an issuer\u2019s offer and/or sale of a virtual asset.\u201d FATF guidance to the G20","title":"Virtual Asset Service Provider (VASP)"},{"location":"Reference/GLOSSARY/#z","text":"","title":"Z"},{"location":"Reference/GLOSSARY/#zero-knowledge-proof-zkp","text":"In cryptography, a zero-knowledge proof or zero-knowledge protocol is a method by which one party (the prover) can prove to another party (the verifier) that a given statement is true, without conveying any information apart from the fact that the statement is indeed true. The essence of zero-knowledge proofs is that it is trivial to prove that one possesses knowledge of certain information by simply revealing it; the challenge is to prove such possession without revealing the information itself or any additional information ( Zero-knowledge proof on wikipedia ). a","title":"zero-knowledge proof (ZKP)"},{"location":"Reference/MODULES/","text":"Elesto Modules Elesto Modules DID Module The Elesto project is composed of modules. DID Module The decentralized identifier (DID) module implements the Cosmos DID method and is responsible for all the operations around DIDs. Source Module docs Dependencies: None","title":"Elesto Modules"},{"location":"Reference/MODULES/#elesto-modules","text":"Elesto Modules DID Module The Elesto project is composed of modules.","title":"Elesto Modules"},{"location":"Reference/MODULES/#did-module","text":"The decentralized identifier (DID) module implements the Cosmos DID method and is responsible for all the operations around DIDs. Source Module docs Dependencies: None","title":"DID Module"},{"location":"Reference/architecture/","text":"Architecture Overview Architecture documentation is based on PlantUML , which comes with many documentation and examples. Diagrams are created through text-based documents ( .puml files) that are then rendered into an appropriate format like Pandoc Markdown to generate PDFs and HTML output. PlantUML was chosen as the architecture medium for several reasons, of which the most important are: It supports several different types of diagrams: class, sequence, activity, ERM ... Diagrams can be stored with the codebase and documentation instead in a separate system such as Whimsical and then imported as needed into documentation. To contribute, see CONTRIBUTING .","title":"Architecture"},{"location":"Reference/architecture/#architecture","text":"","title":"Architecture"},{"location":"Reference/architecture/#overview","text":"Architecture documentation is based on PlantUML , which comes with many documentation and examples. Diagrams are created through text-based documents ( .puml files) that are then rendered into an appropriate format like Pandoc Markdown to generate PDFs and HTML output. PlantUML was chosen as the architecture medium for several reasons, of which the most important are: It supports several different types of diagrams: class, sequence, activity, ERM ... Diagrams can be stored with the codebase and documentation instead in a separate system such as Whimsical and then imported as needed into documentation. To contribute, see CONTRIBUTING .","title":"Overview"},{"location":"Reference/architecture/CONTRIBUTING/","text":"CONTRIBUTING Installation Elesto diagrams are based on PlantUML. PlantUML can be installed on your local system through your platforms' package manager: MacOS, through Homebrew > brew install plantuml Windows, through Chocolatey > choco install plantuml Linux-based systems, through your distribution's package manager Contributing diagrams The source code for all diagrams SHOULD be stored in ./src folder AND have the .puml suffix. See the PlanUML documentation for further details. Themes Where possible all diagrams are rendered to have a similar look and feel. To achieve this look and feel, add the following theme to your diagram: @startuml myDiagram !theme tendermint from ../themes/ ... @enduml How to generate diagram images There are many ways to run PlantUML to generate images from the .puml files, but this project prefers the following: PlantUML CLI Embed PlantUML diagrams using PlantUML's proxy service in Markdown Visual Studio Code Plugin - best for development PlantUML CLI The makefile builds all src/*.puml files. To create SVG images, run make (svg|png) as needed. Run make clean to get a clean folder ready for a new build. Using PlantUML and makefile is the preferred and cleanest way to create architecture documentation. Proxy service This method uses PlantUML's proxy service to generate images and embed them into a Markdown page. To use the proxy service integration, use: ![cached image](http://www.plantuml.com/plantuml/proxy?src=https://raw.github.com/plantuml/plantuml-server/master/src/main/webapp/resource/test2diagrams.txt) Or if caching is required: ![uncached image](http://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.github.com/plantuml/plantuml-server/master/src/main/webapp/resource/test2diagrams.txt) Visual Studio Code If you use Visual Studio Code , a PlantUML plugin is available. From here, you can preview diagrams by using the command palette (CTRL+SHIFT+P on Windows/Linux or COMMAND+SHIFT+P on macOS). > PlantUML: Preview Current Diagram Reference Markdown native diagrams with PlantUML PlantUML Cheatsheet PlantUML Theme Documentation Stackoverflow question on embedding PlantUML in Markdown","title":"CONTRIBUTING"},{"location":"Reference/architecture/CONTRIBUTING/#contributing","text":"","title":"CONTRIBUTING"},{"location":"Reference/architecture/CONTRIBUTING/#installation","text":"Elesto diagrams are based on PlantUML. PlantUML can be installed on your local system through your platforms' package manager: MacOS, through Homebrew > brew install plantuml Windows, through Chocolatey > choco install plantuml Linux-based systems, through your distribution's package manager","title":"Installation"},{"location":"Reference/architecture/CONTRIBUTING/#contributing-diagrams","text":"The source code for all diagrams SHOULD be stored in ./src folder AND have the .puml suffix. See the PlanUML documentation for further details.","title":"Contributing diagrams"},{"location":"Reference/architecture/CONTRIBUTING/#themes","text":"Where possible all diagrams are rendered to have a similar look and feel. To achieve this look and feel, add the following theme to your diagram: @startuml myDiagram !theme tendermint from ../themes/ ... @enduml","title":"Themes"},{"location":"Reference/architecture/CONTRIBUTING/#how-to-generate-diagram-images","text":"There are many ways to run PlantUML to generate images from the .puml files, but this project prefers the following: PlantUML CLI Embed PlantUML diagrams using PlantUML's proxy service in Markdown Visual Studio Code Plugin - best for development","title":"How to generate diagram images"},{"location":"Reference/architecture/CONTRIBUTING/#plantuml-cli","text":"The makefile builds all src/*.puml files. To create SVG images, run make (svg|png) as needed. Run make clean to get a clean folder ready for a new build. Using PlantUML and makefile is the preferred and cleanest way to create architecture documentation.","title":"PlantUML CLI"},{"location":"Reference/architecture/CONTRIBUTING/#proxy-service","text":"This method uses PlantUML's proxy service to generate images and embed them into a Markdown page. To use the proxy service integration, use: ![cached image](http://www.plantuml.com/plantuml/proxy?src=https://raw.github.com/plantuml/plantuml-server/master/src/main/webapp/resource/test2diagrams.txt) Or if caching is required: ![uncached image](http://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.github.com/plantuml/plantuml-server/master/src/main/webapp/resource/test2diagrams.txt)","title":"Proxy service"},{"location":"Reference/architecture/CONTRIBUTING/#visual-studio-code","text":"If you use Visual Studio Code , a PlantUML plugin is available. From here, you can preview diagrams by using the command palette (CTRL+SHIFT+P on Windows/Linux or COMMAND+SHIFT+P on macOS). > PlantUML: Preview Current Diagram","title":"Visual Studio Code"},{"location":"Reference/architecture/CONTRIBUTING/#reference","text":"Markdown native diagrams with PlantUML PlantUML Cheatsheet PlantUML Theme Documentation Stackoverflow question on embedding PlantUML in Markdown","title":"Reference"},{"location":"Tutorials/","text":"","title":"Index"}]}